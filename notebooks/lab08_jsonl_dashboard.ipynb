{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "0a7ff0d8",
      "metadata": {},
      "source": [
        "# Lab 08 — JSONL Dashboard \n",
        "\n",
        "Diagnostics & logging hygiene.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad3e119",
      "metadata": {},
      "source": [
        "## 1) Setup (Colab)\n",
        "\n",
        "Minimal installs. Data: `/content/data`. Outputs: `/content/out`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa12143c",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip -q install --upgrade pandas matplotlib nbformat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35d0c13",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "BASE = Path('/content')\n",
        "DATA = BASE/'data'\n",
        "OUT = BASE/'out'\n",
        "DATA.mkdir(parents=True, exist_ok=True)\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "print('DATA=', DATA)\n",
        "print('OUT=', OUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "731a84e2",
      "metadata": {},
      "source": [
        "## 2) Task 1 — Load & Peek (code)\n",
        "\n",
        "Load `.jsonl` files and quick-check structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11985bd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json, pandas as pd\n",
        "\n",
        "DATA = Path('/content/data')\n",
        "JSONL_FILES = []  # e.g., ['sample1.jsonl', 'sample2.jsonl']\n",
        "\n",
        "def read_jsonl(path: Path):\n",
        "    \"\"\"Load JSON Lines without enforcing a schema.\"\"\"\n",
        "    rows = []\n",
        "    with path.open('r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                rows.append(json.loads(line))\n",
        "            except Exception:\n",
        "                # TODO: append the raw line to a quarantine list / file for later review\n",
        "                pass\n",
        "    return rows\n",
        "\n",
        "def load_many_jsonl(files):\n",
        "    \"\"\"Concatenate many JSONL files into a single DataFrame.\"\"\"\n",
        "    all_rows = []\n",
        "    for name in files:\n",
        "        p = DATA / name\n",
        "        if not p.exists():\n",
        "            print(f\"[skip] {p}\")\n",
        "            continue\n",
        "        all_rows.extend(read_jsonl(p))\n",
        "    return pd.DataFrame(all_rows) if all_rows else pd.DataFrame()\n",
        "\n",
        "df = load_many_jsonl(JSONL_FILES)\n",
        "\n",
        "# Optional: keep only AskSage models if present\n",
        "if not df.empty and 'model' in df.columns:\n",
        "    df = df[df['model'].isin(['gpt-5', 'gpt-5-mini'])].copy()\n",
        "\n",
        "print('rows =', len(df), 'cols =', len(df.columns))\n",
        "print('cols  =', list(df.columns))\n",
        "display(df.head(5))\n",
        "\n",
        "# TODOs:\n",
        "# - TODO: add an assertion only after you find the schema\n",
        "# - TODO: list any rows missing key fields and decide whether to drop or fix them\n",
        "# - TODO: persist a small \"quarantine\" .jsonl of malformed lines\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d178a3d",
      "metadata": {},
      "source": [
        "## 3) Task 2 — Metrics (code)\n",
        "\n",
        "Compute latency stats, token counts, and cost.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fc8b02c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "if df.empty:\n",
        "    print('No data. Load files in Task 1.')\n",
        "else:\n",
        "    def p95(s):\n",
        "        return float(s.quantile(0.95)) if len(s) else float('nan')\n",
        "\n",
        "    # Ensure numeric\n",
        "    for col in ['latency_ms','input_tokens','output_tokens','cost_usd']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Fill cost if missing\n",
        "    if 'cost_usd' not in df.columns or df['cost_usd'].isna().all():\n",
        "        df['cost_usd'] = 0.0\n",
        "        # TODO: compute cost from AskSage pricing (gpt-5, gpt-5-mini)\n",
        "\n",
        "    # Latency stats\n",
        "    if 'latency_ms' in df.columns:\n",
        "        lat_stats = df['latency_ms'].describe(percentiles=[0.5, 0.95])\n",
        "        print('Latency:')\n",
        "        display(lat_stats)\n",
        "\n",
        "    # By model\n",
        "    if 'model' in df.columns and {'latency_ms','cost_usd'}.issubset(df.columns):\n",
        "        by_model = df.groupby('model').agg(\n",
        "            n=('model','size'),\n",
        "            lat_med=('latency_ms','median'),\n",
        "            lat_p95=('latency_ms', p95),\n",
        "            cost_sum=('cost_usd','sum')\n",
        "        )\n",
        "        print('By model:')\n",
        "        display(by_model)\n",
        "\n",
        "    # Approx cost per 1K interactions\n",
        "    if 'cost_usd' in df.columns and len(df)>0:\n",
        "        total_cost = float(df['cost_usd'].sum())\n",
        "        per_1k = (total_cost / max(1, len(df))) * 1000.0\n",
        "        print('Cost per 1K interactions:', round(per_1k, 6))\n",
        "\n",
        "    # TODO: add error_rate if error column exists\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bff43749",
      "metadata": {},
      "source": [
        "## 4) Task 3 — Tiny Dashboard (code)\n",
        "\n",
        "Make 1 table + 1 chart. Save PNG to `/content/out`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bb8a133",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd, matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "OUT = Path('/content/out'); OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if df.empty:\n",
        "    print('No data.')\n",
        "else:\n",
        "    # TODO: build compact summary table\n",
        "\n",
        "    # TODO: make 1 chart and save PNG\n",
        "    # Example:\n",
        "    # if 'latency_ms' in df.columns:\n",
        "    #     plt.figure()\n",
        "    #     df['latency_ms'].dropna().plot(kind='hist', bins=30, title='Latency (ms)')\n",
        "    #     plt.xlabel('latency_ms'); plt.ylabel('count')\n",
        "    #     plt.tight_layout()\n",
        "    #     p = OUT/'latency_hist.png'\n",
        "    #     plt.savefig(p); plt.show(); print('Saved:', p)\n",
        "\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5da4af2",
      "metadata": {},
      "source": [
        "## 5) Task 4 — Ongoing Hygiene TODOs\n",
        "\n",
        "Long-term TODOs to add into your codebase.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "156a888b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODOs — Logging & Diagnostics (AskSage: gpt-5, gpt-5-mini)\n",
        "\n",
        "# Logging\n",
        "# - TODO: add correlation_id per request\n",
        "# - TODO: log p95 latency per model/hour\n",
        "# - TODO: record tokens consistently\n",
        "# - TODO: capture error_code + retries\n",
        "# - TODO: enforce UTC ISO 8601 timestamps\n",
        "\n",
        "# Cost\n",
        "# - TODO: compute cost_usd per call using AskSage pricing\n",
        "# - TODO: weekly rollup per model\n",
        "\n",
        "# Dashboards\n",
        "# - TODO: daily PNG export\n",
        "# - TODO: alerts for high p95 latency / error_rate\n",
        "\n",
        "# Validation\n",
        "# - TODO: schema checks; quarantine bad rows\n",
        "# - TODO: dedupe by (correlation_id, timestamp)\n",
        "\n",
        "# Docs\n",
        "# - TODO: README for fields + logging process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72a4f0e2",
      "metadata": {},
      "source": [
        "## Deliverables\n",
        "\n",
        "- One PNG dashboard image in `/content/out/`  \n",
        "- Notebook with completed code cells for Tasks 1–3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3f16cfb",
      "metadata": {},
      "source": [
        "## Exit Ticket\n",
        "\n",
        "Final markdown cell, answer:\n",
        "1) One key metric you computed  \n",
        "2) One dashboard insight  \n",
        "3) First hygiene TODO you'll implement\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Lab 08 — JSONL Dashboard (AskSage, code-only, regenerated)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}