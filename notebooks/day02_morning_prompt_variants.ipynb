{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt Variants Demo\n",
        "\n",
        "## Learning Objectives\n",
        "- See multiple prompt approaches for the same task\n",
        "- Compare effectiveness of different prompt strategies\n",
        "- Understand when to use each variant type\n",
        "- Learn systematic prompt variation techniques\n",
        "\n",
        "## The Demo: One Task, Many Approaches\n",
        "\n",
        "We'll demonstrate:\n",
        "1. **Single Task Definition** - Email prioritization\n",
        "2. **Multiple Variants** - Different prompt strategies\n",
        "3. **Performance Comparison** - Which works best when\n",
        "4. **Context Sensitivity** - How variants perform in different scenarios\n",
        "5. **Selection Strategy** - Choosing the right variant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "!pip install asksageclient pip_system_certs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import tiktoken\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# Import our AskSage client\n",
        "from asksageclient import AskSageClient\n",
        "\n",
        "# Get API credentials from Google Colab secrets\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('ASKSAGE_API_KEY')\n",
        "email = userdata.get('ASKSAGE_EMAIL')\n",
        "\n",
        "# Initialize client and tokenizer\n",
        "client = AskSageClient(api_key=api_key, email=email)\n",
        "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "print(\"AskSage client initialized successfully\")\n",
        "print(\"Ready to showcase AI capabilities...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task: Email Prioritization\n",
        "\n",
        "We'll use email prioritization as our test case with multiple sample emails:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test emails for variant comparison\n",
        "test_emails = [\n",
        "    {\n",
        "        \"subject\": \"URGENT: Production server down\",\n",
        "        \"content\": \"Our main production server crashed at 2 PM. All customer transactions are failing. Revenue impact is $50K per hour. Need immediate attention.\",\n",
        "        \"sender\": \"ops-team@company.com\",\n",
        "        \"expected_priority\": \"Critical\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Weekly team meeting reminder\",\n",
        "        \"content\": \"Just a reminder that our weekly team meeting is tomorrow at 10 AM in conference room B. Please bring your status updates.\",\n",
        "        \"sender\": \"manager@company.com\",\n",
        "        \"expected_priority\": \"Low\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Client contract needs review\",\n",
        "        \"content\": \"The Johnson Industries contract is ready for legal review. They need it back by Friday for the board meeting. It's a $2M deal.\",\n",
        "        \"sender\": \"sales@company.com\",\n",
        "        \"expected_priority\": \"High\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"New employee onboarding\",\n",
        "        \"content\": \"Sarah Johnson starts Monday. Please prepare her workspace and send her the onboarding checklist. IT needs to set up her accounts.\",\n",
        "        \"sender\": \"hr@company.com\",\n",
        "        \"expected_priority\": \"Medium\"\n",
        "    },\n",
        "    {\n",
        "        \"subject\": \"Security vulnerability detected\",\n",
        "        \"content\": \"Our security scan found a critical vulnerability in the payment processing module. CVE-2024-1234. Patch available but requires downtime.\",\n",
        "        \"sender\": \"security@company.com\",\n",
        "        \"expected_priority\": \"Critical\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"Test dataset loaded: {len(test_emails)} emails\")\n",
        "print(\"Expected priorities defined for comparison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variant 1: Direct Classification\n",
        "\n",
        "Simple, straightforward approach:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variant 1: Direct classification\n",
        "def variant_1_direct(email):\n",
        "    return f\"\"\"\n",
        "Classify this email's priority as Critical, High, Medium, or Low.\n",
        "\n",
        "Subject: {email['subject']}\n",
        "From: {email['sender']}\n",
        "Content: {email['content']}\n",
        "\n",
        "Priority:\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== VARIANT 1: DIRECT CLASSIFICATION ===\")\n",
        "variant_1_results = []\n",
        "\n",
        "for i, email in enumerate(test_emails):\n",
        "    prompt = variant_1_direct(email)\n",
        "    \n",
        "# Test GPT-5-mini\n",
        "print(\"=== TESTING GPT-5-mini ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "response = client.query(\n",
        "    message=prompt,\n",
        "    system_prompt=\"You are concise.\",\n",
        "    temperature=0.1,\n",
        "    model=\"gpt-5-mini\",\n",
        "    live=0,\n",
        "    limit_references=0,\n",
        ")\n",
        "\n",
        "    \n",
        "result = response.get(\"message\").strip()\n",
        "    variant_1_results.append({\n",
        "        'email_id': i,\n",
        "        'subject': email['subject'],\n",
        "        'expected': email['expected_priority'],\n",
        "        'actual': result,\n",
        "        'variant': 'direct'\n",
        "    })\n",
        "    \n",
        "    print(f\"Email {i+1}: {email['subject'][:40]}...\")\n",
        "    print(f\"Expected: {email['expected_priority']} | Got: {result}\")\n",
        "    print()\n",
        "\n",
        "print(f\"Variant 1 tested on {len(variant_1_results)} emails\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variant 2: Criteria-Based Classification\n",
        "\n",
        "Provide explicit criteria for decision making:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variant 2: Criteria-based classification\n",
        "def variant_2_criteria(email):\n",
        "    return f\"\"\"\n",
        "Classify this email's priority using these criteria:\n",
        "\n",
        "CRITICAL: System outages, security breaches, immediate revenue impact\n",
        "HIGH: Important deadlines, large deals, executive requests\n",
        "MEDIUM: Regular business operations, planning, coordination\n",
        "LOW: FYI, routine updates, non-urgent reminders\n",
        "\n",
        "Email to classify:\n",
        "Subject: {email['subject']}\n",
        "From: {email['sender']}\n",
        "Content: {email['content']}\n",
        "\n",
        "Analysis: [Explain which criteria apply]\n",
        "Priority: [Critical/High/Medium/Low]\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== VARIANT 2: CRITERIA-BASED CLASSIFICATION ===\")\n",
        "variant_2_results = []\n",
        "\n",
        "for i, email in enumerate(test_emails):\n",
        "    prompt = variant_2_criteria(email)\n",
        "    \n",
        "# Test GPT-5-mini\n",
        "print(\"=== TESTING GPT-5-mini ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "response = client.query(\n",
        "    message=prompt,\n",
        "    system_prompt=\"You are concise.\",\n",
        "    temperature=0.1,\n",
        "    model=\"gpt-5-mini\",\n",
        "    live=0,\n",
        "    limit_references=0,\n",
        ")\n",
        "\n",
        "    \n",
        "result = response.get(\"message\").strip()\n",
        "result = len(tokenizer.encode(result))\n",
        "\n",
        "    # Extract just the priority\n",
        "    priority_line = [line for line in result.split('\\n') if 'Priority:' in line]\n",
        "    priority = priority_line[0].split('Priority:')[-1].strip() if priority_line else result\n",
        "    \n",
        "    variant_2_results.append({\n",
        "        'email_id': i,\n",
        "        'subject': email['subject'],\n",
        "        'expected': email['expected_priority'],\n",
        "        'actual': priority,\n",
        "        'full_response': result,\n",
        "        'variant': 'criteria'\n",
        "    })\n",
        "    \n",
        "    print(f\"Email {i+1}: {email['subject'][:40]}...\")\n",
        "    print(f\"Expected: {email['expected_priority']} | Got: {priority}\")\n",
        "    print(f\"Analysis: {result.split('Analysis:')[-1].split('Priority:')[0].strip()[:100]}...\")\n",
        "    print()\n",
        "\n",
        "print(f\"Variant 2 tested on {len(variant_2_results)} emails\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variant 3: Scoring-Based Classification\n",
        "\n",
        "Use numerical scoring for more precise classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variant 3: Scoring-based classification\n",
        "def variant_3_scoring(email):\n",
        "    return f\"\"\"\n",
        "Score this email on multiple dimensions (1-10 scale) and determine priority:\n",
        "\n",
        "Email:\n",
        "Subject: {email['subject']}\n",
        "From: {email['sender']}\n",
        "Content: {email['content']}\n",
        "\n",
        "Score each dimension:\n",
        "Urgency (1-10): [How time-sensitive is this?]\n",
        "Impact (1-10): [What's the business impact?]\n",
        "Effort (1-10): [How much work is required?]\n",
        "Sender Authority (1-10): [How important is the sender?]\n",
        "\n",
        "Total Score: [Sum of scores]\n",
        "Priority Mapping: 35-40=Critical, 25-34=High, 15-24=Medium, 4-14=Low\n",
        "Final Priority: [Based on total score]\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== VARIANT 3: SCORING-BASED CLASSIFICATION ===\")\n",
        "variant_3_results = []\n",
        "\n",
        "for i, email in enumerate(test_emails):\n",
        "    prompt = variant_3_scoring(email)\n",
        "    \n",
        "# Test GPT-5-mini\n",
        "print(\"=== TESTING GPT-5-mini ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "response = client.query(\n",
        "    message=prompt,\n",
        "    system_prompt=\"You are concise.\",\n",
        "    temperature=0.1,\n",
        "    model=\"gpt-5-mini\",\n",
        "    live=0,\n",
        "    limit_references=0,\n",
        ")\n",
        "\n",
        "    \n",
        "result = response.get(\"message\").strip()\n",
        "result = len(tokenizer.encode(result))\n",
        "\n",
        "    # Extract priority\n",
        "    priority_line = [line for line in result.split('\\n') if 'Final Priority:' in line]\n",
        "    priority = priority_line[0].split('Final Priority:')[-1].strip() if priority_line else \"Unknown\"\n",
        "    \n",
        "    # Extract total score\n",
        "    score_line = [line for line in result.split('\\n') if 'Total Score:' in line]\n",
        "    score = score_line[0].split('Total Score:')[-1].strip() if score_line else \"Unknown\"\n",
        "    \n",
        "    variant_3_results.append({\n",
        "        'email_id': i,\n",
        "        'subject': email['subject'],\n",
        "        'expected': email['expected_priority'],\n",
        "        'actual': priority,\n",
        "        'score': score,\n",
        "        'full_response': result,\n",
        "        'variant': 'scoring'\n",
        "    })\n",
        "    \n",
        "    print(f\"Email {i+1}: {email['subject'][:40]}...\")\n",
        "    print(f\"Expected: {email['expected_priority']} | Got: {priority} (Score: {score})\")\n",
        "    print()\n",
        "\n",
        "print(f\"Variant 3 tested on {len(variant_3_results)} emails\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variant 4: Role-Playing Classification\n",
        "\n",
        "Give AI a specific role and context:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variant 4: Role-playing classification\n",
        "def variant_4_roleplay(email):\n",
        "    return f\"\"\"\n",
        "You are Alex Chen, a Senior Executive Assistant with 8 years of experience managing C-level executives' communications. You're known for your excellent judgment in prioritizing emails and protecting your executive's time while ensuring critical issues get immediate attention.\n",
        "\n",
        "Your executive is currently in back-to-back meetings until 5 PM and has asked you to prioritize their inbox. They trust your judgment completely.\n",
        "\n",
        "Classify this email:\n",
        "Subject: {email['subject']}\n",
        "From: {email['sender']}\n",
        "Content: {email['content']}\n",
        "\n",
        "Your assessment: [Brief explanation of your reasoning]\n",
        "Priority: [Critical/High/Medium/Low]\n",
        "Recommended action: [What should the executive do?]\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== VARIANT 4: ROLE-PLAYING CLASSIFICATION ===\")\n",
        "variant_4_results = []\n",
        "\n",
        "for i, email in enumerate(test_emails):\n",
        "    prompt = variant_4_roleplay(email)\n",
        "    \n",
        "# Test GPT-5-mini\n",
        "print(\"=== TESTING GPT-5-mini ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "response = client.query(\n",
        "    message=prompt,\n",
        "    system_prompt=\"You are concise.\",\n",
        "    temperature=0.2,\n",
        "    model=\"gpt-5-mini\",\n",
        "    live=0,\n",
        "    limit_references=0,\n",
        ")\n",
        "\n",
        "    \n",
        "result = response.get(\"message\").strip()\n",
        "result = len(tokenizer.encode(result))\n",
        "\n",
        "    # Extract priority\n",
        "    priority_line = [line for line in result.split('\\n') if 'Priority:' in line]\n",
        "    priority = priority_line[0].split('Priority:')[-1].strip() if priority_line else \"Unknown\"\n",
        "    \n",
        "    variant_4_results.append({\n",
        "        'email_id': i,\n",
        "        'subject': email['subject'],\n",
        "        'expected': email['expected_priority'],\n",
        "        'actual': priority,\n",
        "        'full_response': result,\n",
        "        'variant': 'roleplay'\n",
        "    })\n",
        "    \n",
        "    print(f\"Email {i+1}: {email['subject'][:40]}...\")\n",
        "    print(f\"Expected: {email['expected_priority']} | Got: {priority}\")\n",
        "    print()\n",
        "\n",
        "print(f\"Variant 4 tested on {len(variant_4_results)} emails\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variant 5: JSON-Structured Classification\n",
        "\n",
        "Force structured output with detailed reasoning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variant 5: JSON-structured classification\n",
        "def variant_5_json(email):\n",
        "    return f\"\"\"\n",
        "Analyze this email and provide classification in the exact JSON format below:\n",
        "\n",
        "Email:\n",
        "Subject: {email['subject']}\n",
        "From: {email['sender']}\n",
        "Content: {email['content']}\n",
        "\n",
        "Respond with valid JSON only:\n",
        "{{\n",
        "  \"priority\": \"Critical|High|Medium|Low\",\n",
        "  \"urgency_score\": \"number 1-10\",\n",
        "  \"impact_score\": \"number 1-10\",\n",
        "  \"key_factors\": [\"list of factors that influenced the decision\"],\n",
        "  \"reasoning\": \"brief explanation\",\n",
        "  \"recommended_response_time\": \"immediate|within 1 hour|within 4 hours|within 24 hours|when convenient\",\n",
        "  \"confidence\": \"number 1-10\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== VARIANT 5: JSON-STRUCTURED CLASSIFICATION ===\")\n",
        "variant_5_results = []\n",
        "\n",
        "for i, email in enumerate(test_emails):\n",
        "    prompt = variant_5_json(email)\n",
        "    \n",
        "# Test GPT-5-mini\n",
        "print(\"=== TESTING GPT-5-mini ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "response = client.query(\n",
        "    message=prompt,\n",
        "    system_prompt=\"You are concise.\",\n",
        "    temperature=0.1,\n",
        "    model=\"gpt-5-mini\",\n",
        "    live=0,\n",
        "    limit_references=0,\n",
        ")\n",
        "\n",
        "    \n",
        "result = response.get(\"message\").strip()\n",
        "result = len(tokenizer.encode(result))\n",
        "\n",
        "    \n",
        "    # Try to parse JSON\n",
        "    try:\n",
        "        import re\n",
        "        json_match = re.search(r'\\{.*\\}', result, re.DOTALL)\n",
        "        if json_match:\n",
        "            json_data = json.loads(json_match.group())\n",
        "            priority = json_data.get('priority', 'Unknown')\n",
        "            confidence = json_data.get('confidence', 'Unknown')\n",
        "            reasoning = json_data.get('reasoning', 'No reasoning provided')\n",
        "        else:\n",
        "            priority = \"Parse Error\"\n",
        "            confidence = \"Unknown\"\n",
        "            reasoning = \"Could not parse JSON\"\n",
        "    except json.JSONDecodeError:\n",
        "        priority = \"JSON Error\"\n",
        "        confidence = \"Unknown\"\n",
        "        reasoning = \"Invalid JSON format\"\n",
        "    \n",
        "    variant_5_results.append({\n",
        "        'email_id': i,\n",
        "        'subject': email['subject'],\n",
        "        'expected': email['expected_priority'],\n",
        "        'actual': priority,\n",
        "        'confidence': confidence,\n",
        "        'reasoning': reasoning,\n",
        "        'full_response': result,\n",
        "        'variant': 'json'\n",
        "    })\n",
        "    \n",
        "    print(f\"Email {i+1}: {email['subject'][:40]}...\")\n",
        "    print(f\"Expected: {email['expected_priority']} | Got: {priority} (Confidence: {confidence})\")\n",
        "    print(f\"Reasoning: {reasoning[:80]}...\")\n",
        "    print()\n",
        "\n",
        "print(f\"Variant 5 tested on {len(variant_5_results)} emails\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variant Performance Analysis\n",
        "\n",
        "Let AI analyze which variants performed best:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile all results for analysis\n",
        "all_results = {\n",
        "    \"variant_1_direct\": variant_1_results,\n",
        "    \"variant_2_criteria\": variant_2_results,\n",
        "    \"variant_3_scoring\": variant_3_results,\n",
        "    \"variant_4_roleplay\": variant_4_results,\n",
        "    \"variant_5_json\": variant_5_results\n",
        "}\n",
        "\n",
        "# AI analyzes variant performance\n",
        "analysis_prompt = f\"\"\"\n",
        "Analyze the performance of these 5 prompt variants for email prioritization:\n",
        "\n",
        "TEST RESULTS:\n",
        "{json.dumps(all_results, indent=2)}\n",
        "\n",
        "Provide comprehensive analysis:\n",
        "{{\n",
        "  \"accuracy_comparison\": {{\n",
        "    \"variant_1_direct\": \"accuracy percentage\",\n",
        "    \"variant_2_criteria\": \"accuracy percentage\",\n",
        "    \"variant_3_scoring\": \"accuracy percentage\",\n",
        "    \"variant_4_roleplay\": \"accuracy percentage\",\n",
        "    \"variant_5_json\": \"accuracy percentage\"\n",
        "  }},\n",
        "  \"best_performing_variant\": \"variant name\",\n",
        "  \"variant_strengths\": {{\n",
        "    \"variant_1_direct\": [\"list of strengths\"],\n",
        "    \"variant_2_criteria\": [\"list of strengths\"],\n",
        "    \"variant_3_scoring\": [\"list of strengths\"],\n",
        "    \"variant_4_roleplay\": [\"list of strengths\"],\n",
        "    \"variant_5_json\": [\"list of strengths\"]\n",
        "  }},\n",
        "  \"use_case_recommendations\": [\n",
        "    {{\n",
        "      \"scenario\": \"string\",\n",
        "      \"recommended_variant\": \"string\",\n",
        "      \"rationale\": \"string\"\n",
        "    }}\n",
        "  ],\n",
        "  \"key_insights\": [\"list of insights about prompt variants\"]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== VARIANT PERFORMANCE ANALYSIS ===\")\n",
        "# Test GPT-5-mini\n",
        "print(\"=== TESTING GPT-5-mini ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "analysis_response = client.query(\n",
        "    message=analysis_prompt,\n",
        "    system_prompt=\"You are concise.\",\n",
        "    temperature=0.1,\n",
        "    model=\"gpt-5-mini\",\n",
        "    live=0,\n",
        "    limit_references=0,\n",
        ")\n",
        "\n",
        "\n",
        "analysis_result = analysis_response.get(\"message\").strip()\n",
        "print(analysis_result)\n",
        "\n",
        "# Parse analysis results\n",
        "import re\n",
        "json_match = re.search(r'\\{.*\\}', analysis_result, re.DOTALL)\n",
        "if json_match:\n",
        "    analysis_data = json.loads(json_match.group())\n",
        "    \n",
        "    accuracy = analysis_data.get('accuracy_comparison', {})\n",
        "    best_variant = analysis_data.get('best_performing_variant', 'Unknown')\n",
        "    recommendations = analysis_data.get('use_case_recommendations', [])\n",
        "    \n",
        "    print(f\"\\n✓ Best performing variant: {best_variant}\")\n",
        "    print(f\"✓ Use case recommendations: {len(recommendations)}\")\n",
        "    \n",
        "    print(\"\\nAccuracy Comparison:\")\n",
        "    for variant, acc in accuracy.items():\n",
        "        print(f\"  {variant}: {acc}\")\n",
        "    \n",
        "    print(\"\\nUse Case Recommendations:\")\n",
        "    for rec in recommendations:\n",
        "        print(f\"  {rec.get('scenario', 'Unknown scenario')}: Use {rec.get('recommended_variant', 'Unknown')}\")\n",
        "        print(f\"    Rationale: {rec.get('rationale', 'No rationale provided')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prompt Variants Summary\n",
        "\n",
        "### What We Demonstrated:\n",
        "\n",
        "**1. Multiple Approaches, Same Task**\n",
        "- Direct classification: Simple and fast\n",
        "- Criteria-based: Explicit decision framework\n",
        "- Scoring-based: Quantitative assessment\n",
        "- Role-playing: Context and personality\n",
        "- JSON-structured: Consistent, parseable output\n",
        "\n",
        "**2. Performance Comparison**\n",
        "- Accuracy varies by approach\n",
        "- Different variants excel in different scenarios\n",
        "- Trade-offs between speed, accuracy, and detail\n",
        "\n",
        "**3. Context Sensitivity**\n",
        "- Some variants better for complex decisions\n",
        "- Others better for high-volume processing\n",
        "- Role-playing adds human-like reasoning\n",
        "\n",
        "### Key Insights:\n",
        "\n",
        "**Variant Selection Strategy**\n",
        "- **Speed Priority**: Use direct classification\n",
        "- **Accuracy Priority**: Use criteria-based or scoring\n",
        "- **Consistency Priority**: Use JSON-structured\n",
        "- **Human-like Reasoning**: Use role-playing\n",
        "- **Complex Decisions**: Use scoring-based\n",
        "\n",
        "**When to Use Each Variant:**\n",
        "- **High Volume**: Direct or JSON variants\n",
        "- **Critical Decisions**: Criteria or scoring variants\n",
        "- **User-Facing**: Role-playing variant\n",
        "- **System Integration**: JSON variant\n",
        "- **Training/Learning**: Criteria variant\n",
        "\n",
        "### Best Practices:\n",
        "- **Test Multiple Variants**: Don't assume one approach fits all\n",
        "- **Measure Performance**: Use objective metrics\n",
        "- **Consider Context**: Match variant to use case\n",
        "- **Iterate and Improve**: Refine based on results\n",
        "- **Document Decisions**: Track what works when\n",
        "\n",
        "This demonstrates that prompt engineering is not one-size-fits-all - different approaches work better for different scenarios, and systematic testing helps identify the optimal strategy."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}