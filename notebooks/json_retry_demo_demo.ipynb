{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# JSON Schema & Retry Demo\n",
        "\n",
        "## Learning Objectives\n",
        "- Master structured output with JSON Schema\n",
        "- Implement robust retry logic for API failures\n",
        "- Handle malformed JSON responses gracefully\n",
        "- Build production-ready error handling patterns\n",
        "\n",
        "## The Challenge: Reliable Structured Output\n",
        "\n",
        "Getting consistent, valid JSON from LLMs is crucial for building reliable applications. This demo shows how to enforce structure and recover from failures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install asksageclient pip_system_certs pydantic jsonschema rich tenacity tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 🔐 Cell 1 — Load secrets (Colab) + pricing + token utils\n",
        "# ================================\n",
        "import os, time, csv\n",
        "from typing import Optional, Dict\n",
        "import tiktoken\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "ASKSAGE_API_KEY = userdata.get(\"ASKSAGE_API_KEY\")\n",
        "ASKSAGE_BASE_URL = userdata.get(\"ASKSAGE_BASE_URL\")\n",
        "ASKSAGE_EMAIL = userdata.get(\"ASKSAGE_EMAIL\")\n",
        "\n",
        "assert ASKSAGE_API_KEY, \"ASKSAGE_API_KEY not provided.\"\n",
        "assert ASKSAGE_EMAIL, \"ASKSAGE_EMAIL not provided.\"\n",
        "\n",
        "print(\"✓ Secrets loaded\")\n",
        "print(\"  • EMAIL:\", ASKSAGE_EMAIL)\n",
        "print(\"  • BASE URL:\", ASKSAGE_BASE_URL or \"(default)\")\n",
        "\n",
        "# Pricing (USD per 1,000,000 tokens)\n",
        "PRICES_PER_M = {\n",
        "    \"gpt-5\": {\"input_per_m\": 1.25, \"output_per_m\": 10.00},\n",
        "    \"gpt-5-mini\": {\"input_per_m\": 0.25, \"output_per_m\": 2.00},\n",
        "}\n",
        "\n",
        "# Tokenizer\n",
        "enc = tiktoken.get_encoding(\"o200k_base\")\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(enc.encode(text or \"\"))\n",
        "\n",
        "def cost_usd(model: str, input_tokens: int, output_tokens: int) -> float:\n",
        "    if model not in PRICES_PER_M:\n",
        "        raise ValueError(f\"Unknown model: {model}\")\n",
        "    r = PRICES_PER_M[model]\n",
        "    return (input_tokens / 1_000_000) * r[\"input_per_m\"] + (output_tokens / 1_000_000) * r[\"output_per_m\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 🔧 Cell 2 — Import bootcamp_common and setup AskSage client\n",
        "# ================================\n",
        "import sys\n",
        "sys.path.append('../../../')  # Adjust path to reach bootcamp_common\n",
        "\n",
        "from bootcamp_common.ask_sage import AskSageClient\n",
        "\n",
        "# Initialize AskSage client\n",
        "client = AskSageClient(\n",
        "    api_key=ASKSAGE_API_KEY,\n",
        "    base_url=ASKSAGE_BASE_URL\n",
        ")\n",
        "\n",
        "print(\"✓ AskSage client initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "from typing import Dict, List, Optional, Any, Union\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "\n",
        "import openai\n",
        "import anthropic\n",
        "from pydantic import BaseModel, ValidationError\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "from rich.json import JSON\n",
        "\n",
        "console = Console()\n",
        "print(\"✅ Libraries loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Structured Output Schema\n",
        "\n",
        "We'll use Pydantic models to define our expected JSON structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SentimentAnalysis(BaseModel):\n",
        "    \"\"\"Structured sentiment analysis result\"\"\"\n",
        "    text: str\n",
        "    sentiment: str  # positive, negative, neutral\n",
        "    confidence: float  # 0.0 to 1.0\n",
        "    key_phrases: List[str]\n",
        "    emotions: Dict[str, float]  # emotion -> intensity\n",
        "    summary: str\n",
        "\n",
        "class ProductReview(BaseModel):\n",
        "    \"\"\"Structured product review analysis\"\"\"\n",
        "    overall_rating: int  # 1-5 stars\n",
        "    aspects: Dict[str, int]  # aspect -> rating\n",
        "    pros: List[str]\n",
        "    cons: List[str]\n",
        "    would_recommend: bool\n",
        "    target_audience: str\n",
        "\n",
        "@dataclass\n",
        "class RetryStats:\n",
        "    \"\"\"Track retry statistics\"\"\"\n",
        "    total_attempts: int = 0\n",
        "    successful_attempts: int = 0\n",
        "    json_parse_errors: int = 0\n",
        "    validation_errors: int = 0\n",
        "    api_errors: int = 0\n",
        "    total_time: float = 0.0\n",
        "\n",
        "# Test data\n",
        "sample_reviews = [\n",
        "    \"This laptop is amazing! Super fast processor, beautiful display, and the battery lasts all day. Perfect for coding and gaming. Only downside is it gets a bit warm during heavy use.\",\n",
        "    \"Terrible phone. Crashes constantly, camera quality is poor, and battery dies in 2 hours. Customer service was unhelpful. Would not recommend to anyone.\",\n",
        "    \"Decent headphones for the price. Sound quality is good, comfortable to wear. Noise cancellation could be better. Good for casual listening but not for audiophiles.\"\n",
        "]\n",
        "\n",
        "print(\"📋 Schemas and test data ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Robust JSON Parser with Retry Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StructuredOutputClient:\n",
        "    \"\"\"Client for getting structured JSON output with retry logic\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.setup_clients()\n",
        "        self.stats = RetryStats()\n",
        "    \n",
        "    def setup_clients(self):\n",
        "        \"\"\"Setup API clients with fallback to mock\"\"\"\n",
        "        if os.getenv('OPENAI_API_KEY'):\n",
        "            try:\n",
        "                self.openai_client = openai.OpenAI()\n",
        "                self.has_openai = True\n",
        "                console.print(\"✅ OpenAI client configured\")\n",
        "            except Exception as e:\n",
        "                self.has_openai = False\n",
        "                console.print(f\"⚠️ OpenAI setup failed: {e}\")\n",
        "        else:\n",
        "            self.has_openai = False\n",
        "            console.print(\"💡 No OpenAI API key, using mock responses\")\n",
        "    \n",
        "    def extract_json_from_response(self, response_text: str) -> str:\n",
        "        \"\"\"Extract JSON from response that might have extra text\"\"\"\n",
        "        # Try to find JSON block\n",
        "        import re\n",
        "        \n",
        "        # Look for JSON in code blocks\n",
        "        json_match = re.search(r'```(?:json)?\\s*({.*?})\\s*```', response_text, re.DOTALL)\n",
        "        if json_match:\n",
        "            return json_match.group(1)\n",
        "        \n",
        "        # Look for JSON object directly\n",
        "        json_match = re.search(r'{.*}', response_text, re.DOTALL)\n",
        "        if json_match:\n",
        "            return json_match.group(0)\n",
        "        \n",
        "        # Return as-is if no extraction patterns match\n",
        "        return response_text.strip()\n",
        "    \n",
        "    @retry(\n",
        "        stop=stop_after_attempt(3),\n",
        "        wait=wait_exponential(multiplier=1, min=1, max=10),\n",
        "        retry=retry_if_exception_type((json.JSONDecodeError, ValidationError, openai.APIError))\n",
        "    )\n",
        "    def get_structured_output(self, prompt: str, schema: BaseModel, provider: str = \"openai\") -> Dict:\n",
        "        \"\"\"Get structured output with automatic retry on failures\"\"\"\n",
        "        \n",
        "        start_time = time.time()\n",
        "        self.stats.total_attempts += 1\n",
        "        \n",
        "        try:\n",
        "            # Generate schema description\n",
        "            schema_json = schema.model_json_schema()\n",
        "            schema_example = json.dumps(schema_json, indent=2)\n",
        "            \n",
        "            # Build structured prompt\n",
        "            structured_prompt = f\"\"\"{prompt}\n",
        "\n",
        "You must respond with valid JSON that follows this exact schema:\n",
        "\n",
        "```json\n",
        "{schema_example}\n",
        "```\n",
        "\n",
        "Important:\n",
        "- Return ONLY valid JSON, no extra text\n",
        "- Follow the schema exactly\n",
        "- Use appropriate data types\n",
        "- Include all required fields\n",
        "\"\"\"\n",
        "            \n",
        "            # Get response from API or mock\n",
        "            if self.has_openai and provider == \"openai\":\n",
        "                response = self.openai_client.chat.completions.create(\n",
        "                    model=\"gpt-3.5-turbo\",\n",
        "                    messages=[{\"role\": \"user\", \"content\": structured_prompt}],\n",
        "                    max_tokens=500,\n",
        "                    temperature=0.3\n",
        "                )\n",
        "                response_text = response.choices[0].message.content\n",
        "            else:\n",
        "                # Mock response with occasional \"failures\" for demo\n",
        "                import random\n",
        "                if random.random() < 0.3 and self.stats.total_attempts == 1:  # 30% failure on first try\n",
        "                    if random.choice([True, False]):\n",
        "                        # Malformed JSON\n",
        "                        response_text = \"{'sentiment': 'positive', 'confidence': 0.8,}\"  # Extra comma\n",
        "                    else:\n",
        "                        # Missing required field\n",
        "                        response_text = '{\"sentiment\": \"positive\", \"confidence\": 0.8}'\n",
        "                else:\n",
        "                    # Good response\n",
        "                    if \"sentiment\" in prompt.lower():\n",
        "                        response_text = '''{\n",
        "  \"text\": \"Sample review text\",\n",
        "  \"sentiment\": \"positive\",\n",
        "  \"confidence\": 0.85,\n",
        "  \"key_phrases\": [\"amazing\", \"fast processor\", \"beautiful display\"],\n",
        "  \"emotions\": {\"joy\": 0.8, \"satisfaction\": 0.9},\n",
        "  \"summary\": \"Highly positive review praising performance and design\"\n",
        "}'''\n",
        "                    else:\n",
        "                        response_text = '''{\n",
        "  \"overall_rating\": 4,\n",
        "  \"aspects\": {\"performance\": 5, \"design\": 4, \"battery\": 3},\n",
        "  \"pros\": [\"Fast\", \"Beautiful display\", \"Good for work\"],\n",
        "  \"cons\": [\"Gets warm\", \"Price\"],\n",
        "  \"would_recommend\": true,\n",
        "  \"target_audience\": \"Professionals and gamers\"\n",
        "}'''\n",
        "            \n",
        "            # Extract and parse JSON\n",
        "            json_text = self.extract_json_from_response(response_text)\n",
        "            \n",
        "            try:\n",
        "                parsed_json = json.loads(json_text)\n",
        "            except json.JSONDecodeError as e:\n",
        "                self.stats.json_parse_errors += 1\n",
        "                console.print(f\"[red]JSON Parse Error:[/red] {e}\")\n",
        "                console.print(f\"[yellow]Raw response:[/yellow] {json_text[:200]}...\")\n",
        "                raise\n",
        "            \n",
        "            # Validate against schema\n",
        "            try:\n",
        "                validated_data = schema(**parsed_json)\n",
        "                self.stats.successful_attempts += 1\n",
        "                self.stats.total_time += time.time() - start_time\n",
        "                return validated_data.dict()\n",
        "            except ValidationError as e:\n",
        "                self.stats.validation_errors += 1\n",
        "                console.print(f\"[red]Validation Error:[/red] {e}\")\n",
        "                raise\n",
        "        \n",
        "        except Exception as e:\n",
        "            if \"API\" in str(type(e)):\n",
        "                self.stats.api_errors += 1\n",
        "            self.stats.total_time += time.time() - start_time\n",
        "            raise\n",
        "    \n",
        "    def get_stats_summary(self) -> Table:\n",
        "        \"\"\"Get retry statistics summary\"\"\"\n",
        "        table = Table(title=\"Retry Statistics\")\n",
        "        table.add_column(\"Metric\")\n",
        "        table.add_column(\"Count\")\n",
        "        table.add_column(\"Rate\")\n",
        "        \n",
        "        total = self.stats.total_attempts\n",
        "        if total > 0:\n",
        "            table.add_row(\"Total Attempts\", str(total), \"100%\")\n",
        "            table.add_row(\"Successful\", str(self.stats.successful_attempts), \n",
        "                         f\"{self.stats.successful_attempts/total*100:.1f}%\")\n",
        "            table.add_row(\"JSON Parse Errors\", str(self.stats.json_parse_errors),\n",
        "                         f\"{self.stats.json_parse_errors/total*100:.1f}%\")\n",
        "            table.add_row(\"Validation Errors\", str(self.stats.validation_errors),\n",
        "                         f\"{self.stats.validation_errors/total*100:.1f}%\")\n",
        "            table.add_row(\"API Errors\", str(self.stats.api_errors),\n",
        "                         f\"{self.stats.api_errors/total*100:.1f}%\")\n",
        "            table.add_row(\"Total Time\", f\"{self.stats.total_time:.2f}s\", \n",
        "                         f\"{self.stats.total_time/total:.2f}s/attempt\")\n",
        "        \n",
        "        return table\n",
        "\n",
        "# Initialize client\n",
        "client = StructuredOutputClient()\n",
        "print(\"🔧 Structured output client ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo: Sentiment Analysis with Retry Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test sentiment analysis with retry logic\n",
        "console.print(\"\\n🧪 [bold blue]Testing Sentiment Analysis with Retry Logic[/bold blue]\\n\")\n",
        "\n",
        "for i, review in enumerate(sample_reviews[:2], 1):\n",
        "    console.print(f\"[yellow]Review {i}:[/yellow] {review[:100]}...\")\n",
        "    \n",
        "    prompt = f\"Analyze the sentiment of this product review: '{review}'\"\n",
        "    \n",
        "    try:\n",
        "        result = client.get_structured_output(prompt, SentimentAnalysis)\n",
        "        \n",
        "        console.print(\"[green]✅ Success![/green]\")\n",
        "        console.print(Panel(JSON.from_data(result), title=\"Structured Result\", border_style=\"green\"))\n",
        "        \n",
        "    except Exception as e:\n",
        "        console.print(f\"[red]❌ Final failure after retries: {e}[/red]\")\n",
        "    \n",
        "    console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Show retry statistics\n",
        "console.print(client.get_stats_summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo: Product Review Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset stats for clean demo\n",
        "client.stats = RetryStats()\n",
        "\n",
        "console.print(\"\\n🛍️ [bold blue]Testing Product Review Analysis[/bold blue]\\n\")\n",
        "\n",
        "review = sample_reviews[0]  # The positive laptop review\n",
        "prompt = f\"\"\"Analyze this product review and extract structured information:\n",
        "\n",
        "Review: \"{review}\"\n",
        "\n",
        "Extract:\n",
        "- Overall rating (1-5 stars)\n",
        "- Aspect ratings (performance, design, battery, etc.)\n",
        "- Pros and cons lists\n",
        "- Recommendation status\n",
        "- Target audience\"\"\"\n",
        "\n",
        "try:\n",
        "    result = client.get_structured_output(prompt, ProductReview)\n",
        "    \n",
        "    console.print(\"[green]✅ Product analysis complete![/green]\")\n",
        "    console.print(Panel(JSON.from_data(result), title=\"Product Review Analysis\", border_style=\"green\"))\n",
        "    \n",
        "    # Show stats\n",
        "    console.print(\"\\n\")\n",
        "    console.print(client.get_stats_summary())\n",
        "    \n",
        "except Exception as e:\n",
        "    console.print(f\"[red]❌ Analysis failed: {e}[/red]\")\n",
        "\n",
        "print(\"\\n🎯 Product review analysis complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways: Reliable Structured Output\n",
        "\n",
        "### 🔧 **Production-Ready Patterns**\n",
        "\n",
        "1. **Schema Definition**: Use Pydantic models for type safety and validation\n",
        "2. **Retry Logic**: Implement exponential backoff for transient failures\n",
        "3. **JSON Extraction**: Handle responses with extra text or formatting\n",
        "4. **Error Classification**: Track different types of failures separately\n",
        "5. **Monitoring**: Collect metrics on retry rates and success patterns\n",
        "\n",
        "### 📊 **Common Failure Patterns**\n",
        "\n",
        "| **Failure Type** | **Cause** | **Solution** |\n",
        "|------------------|-----------|---------------|\n",
        "| **Malformed JSON** | Extra commas, missing quotes | JSON extraction + parsing |\n",
        "| **Schema Violations** | Missing fields, wrong types | Pydantic validation + retry |\n",
        "| **API Errors** | Rate limits, timeouts | Exponential backoff |\n",
        "| **Context Limits** | Response truncation | Shorter prompts, streaming |\n",
        "\n",
        "### 🚀 **Best Practices**\n",
        "\n",
        "- **Always validate** against schema before using data\n",
        "- **Log failures** with context for debugging\n",
        "- **Set reasonable retry limits** to avoid infinite loops\n",
        "- **Use mock responses** for testing and development\n",
        "- **Monitor success rates** in production\n",
        "\n",
        "## Next: Plan-Do-Check Demo\n",
        "\n",
        "Next we'll see how to build systematic workflows with validation loops!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}