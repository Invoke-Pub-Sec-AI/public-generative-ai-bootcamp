{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Package Refactor Demo\n",
        "\n",
        "## Learning Objectives\n",
        "- Use AI to analyze and improve existing code structure\n",
        "- Implement systematic refactoring with AI assistance\n",
        "- Create maintainable package architectures\n",
        "- Build automated code quality assessment tools\n",
        "\n",
        "## The Challenge: Legacy Code Modernization\n",
        "\n",
        "This demo shows how to use AI to refactor messy, monolithic code into clean, modular packages. We'll transform a single-file script into a well-structured Python package with:\n",
        "1. **Architecture Analysis** - Understanding current structure\n",
        "2. **Modular Design** - Breaking code into logical components\n",
        "3. **Quality Improvement** - Enhancing readability and maintainability\n",
        "4. **Testing Strategy** - Adding comprehensive test coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install asksageclient pip_system_certs rich ast-decompiler tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# üîê Cell 1 ‚Äî Load secrets (Colab) + pricing + token utils\n",
        "# ================================\n",
        "import os, time, csv\n",
        "from typing import Optional, Dict\n",
        "import tiktoken\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "ASKSAGE_API_KEY = userdata.get(\"ASKSAGE_API_KEY\")\n",
        "ASKSAGE_BASE_URL = userdata.get(\"ASKSAGE_BASE_URL\")\n",
        "ASKSAGE_EMAIL = userdata.get(\"ASKSAGE_EMAIL\")\n",
        "\n",
        "assert ASKSAGE_API_KEY, \"ASKSAGE_API_KEY not provided.\"\n",
        "assert ASKSAGE_EMAIL, \"ASKSAGE_EMAIL not provided.\"\n",
        "\n",
        "print(\"‚úì Secrets loaded\")\n",
        "print(\"  ‚Ä¢ EMAIL:\", ASKSAGE_EMAIL)\n",
        "print(\"  ‚Ä¢ BASE URL:\", ASKSAGE_BASE_URL or \"(default)\")\n",
        "\n",
        "# Pricing (USD per 1,000,000 tokens)\n",
        "PRICES_PER_M = {\n",
        "    \"gpt-5\": {\"input_per_m\": 1.25, \"output_per_m\": 10.00},\n",
        "    \"gpt-5-mini\": {\"input_per_m\": 0.25, \"output_per_m\": 2.00},\n",
        "}\n",
        "\n",
        "# Tokenizer\n",
        "enc = tiktoken.get_encoding(\"o200k_base\")\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(enc.encode(text or \"\"))\n",
        "\n",
        "def cost_usd(model: str, input_tokens: int, output_tokens: int) -> float:\n",
        "    if model not in PRICES_PER_M:\n",
        "        raise ValueError(f\"Unknown model: {model}\")\n",
        "    r = PRICES_PER_M[model]\n",
        "    return (input_tokens / 1_000_000) * r[\"input_per_m\"] + (output_tokens / 1_000_000) * r[\"output_per_m\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# üîß Cell 2 ‚Äî Import bootcamp_common and setup AskSage client\n",
        "# ================================\n",
        "import sys\n",
        "sys.path.append('../../../')  # Adjust path to reach bootcamp_common\n",
        "\n",
        "from bootcamp_common.ask_sage import AskSageClient\n",
        "\n",
        "# Initialize AskSage client\n",
        "client = AskSageClient(\n",
        "    api_key=ASKSAGE_API_KEY,\n",
        "    base_url=ASKSAGE_BASE_URL\n",
        ")\n",
        "\n",
        "print(\"‚úì AskSage client initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import ast\n",
        "import inspect\n",
        "from typing import Dict, List, Optional, Any, Tuple\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import openai\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.syntax import Syntax\n",
        "from rich.tree import Tree\n",
        "from rich.table import Table\n",
        "\n",
        "console = Console()\n",
        "print(\"üîÑ Package refactor system loading...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Legacy Code Example: Monolithic Data Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of legacy code that needs refactoring\n",
        "legacy_code = '''\n",
        "import json\n",
        "import csv\n",
        "import requests\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "def process_data_files():\n",
        "    # Configuration - should be in config file\n",
        "    API_URL = \"https://api.example.com/data\"\n",
        "    DB_PATH = \"data.db\"\n",
        "    \n",
        "    # Initialize database - mixed concerns\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS processed_data \n",
        "                     (id INTEGER PRIMARY KEY, data TEXT, timestamp TEXT)\"\"\")\n",
        "    \n",
        "    # Fetch data from API - no error handling\n",
        "    response = requests.get(API_URL)\n",
        "    api_data = response.json()\n",
        "    \n",
        "    # Process CSV files - hardcoded paths\n",
        "    csv_files = [\"data1.csv\", \"data2.csv\", \"data3.csv\"]\n",
        "    all_data = []\n",
        "    \n",
        "    for file in csv_files:\n",
        "        try:\n",
        "            df = pd.read_csv(file)\n",
        "            # Data cleaning - should be separate function\n",
        "            df = df.dropna()\n",
        "            df['processed_date'] = datetime.now().isoformat()\n",
        "            \n",
        "            # Transform data - business logic mixed with I/O\n",
        "            for _, row in df.iterrows():\n",
        "                processed_row = {\n",
        "                    'id': row.get('id', 0),\n",
        "                    'value': float(row.get('value', 0)) * 1.1,  # Magic number\n",
        "                    'category': row.get('category', 'unknown').upper(),\n",
        "                    'timestamp': row['processed_date']\n",
        "                }\n",
        "                all_data.append(processed_row)\n",
        "                \n",
        "                # Save to database - inefficient\n",
        "                cursor.execute(\"INSERT INTO processed_data VALUES (?, ?, ?)\",\n",
        "                             (processed_row['id'], \n",
        "                              json.dumps(processed_row), \n",
        "                              processed_row['timestamp']))\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file}: {e}\")  # Poor error handling\n",
        "    \n",
        "    # Generate report - should be separate module\n",
        "    report = {\n",
        "        'total_records': len(all_data),\n",
        "        'categories': list(set([d['category'] for d in all_data])),\n",
        "        'avg_value': sum([d['value'] for d in all_data]) / len(all_data),\n",
        "        'generated_at': datetime.now().isoformat()\n",
        "    }\n",
        "    \n",
        "    # Save report - hardcoded filename\n",
        "    with open('report.json', 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    \n",
        "    return report\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    result = process_data_files()\n",
        "    print(f\"Processed {result['total_records']} records\")\n",
        "'''\n",
        "\n",
        "console.print(\"üìÑ [bold red]Legacy Code Example Loaded[/bold red]\")\n",
        "syntax = Syntax(legacy_code, \"python\", theme=\"monokai\", line_numbers=True)\n",
        "console.print(Panel(syntax, title=\"Legacy: monolithic_processor.py\", border_style=\"red\"))\n",
        "print(\"\\nüîç This code has multiple issues that need refactoring!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AI-Powered Code Analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class CodeAnalysis:\n",
        "    \"\"\"Results of code analysis\"\"\"\n",
        "    issues: List[str]\n",
        "    complexity_score: float\n",
        "    suggested_modules: List[str]\n",
        "    refactor_priority: str\n",
        "    architectural_recommendations: List[str]\n",
        "\n",
        "class CodeRefactorAgent:\n",
        "    \"\"\"AI-powered code analysis and refactoring agent\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.setup_client()\n",
        "        self.refactor_history = []\n",
        "    \n",
        "    def setup_client(self):\n",
        "        \"\"\"Setup API client\"\"\"\n",
        "        if os.getenv('OPENAI_API_KEY'):\n",
        "            try:\n",
        "                self.client = openai.OpenAI()\n",
        "                self.has_api = True\n",
        "                console.print(\"‚úÖ OpenAI client configured\")\n",
        "            except Exception as e:\n",
        "                self.has_api = False\n",
        "                console.print(f\"‚ö†Ô∏è Using mock responses: {e}\")\n",
        "        else:\n",
        "            self.has_api = False\n",
        "            console.print(\"üí° No API key found, using mock responses\")\n",
        "    \n",
        "    def analyze_code_structure(self, code: str) -> CodeAnalysis:\n",
        "        \"\"\"Analyze code and identify refactoring opportunities\"\"\"\n",
        "        \n",
        "        analysis_prompt = f\"\"\"Analyze this Python code and identify refactoring opportunities:\n",
        "\n",
        "{code}\n",
        "\n",
        "Provide analysis for:\n",
        "1. Code quality issues (mixing concerns, hardcoded values, poor error handling)\n",
        "2. Suggested module breakdown\n",
        "3. Architectural improvements\n",
        "4. Complexity assessment (1-10 scale)\n",
        "5. Refactoring priority (high/medium/low)\n",
        "\n",
        "Focus on practical, implementable suggestions.\"\"\"\n",
        "        \n",
        "        if self.has_api:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": analysis_prompt}],\n",
        "                max_tokens=800,\n",
        "                temperature=0.3\n",
        "            )\n",
        "            analysis_text = response.choices[0].message.content\n",
        "        else:\n",
        "            # Mock analysis\n",
        "            analysis_text = \"\"\"Code Quality Issues:\n",
        "1. Mixed concerns - database, API, file processing in one function\n",
        "2. Hardcoded configuration values\n",
        "3. Poor error handling with generic exception catching\n",
        "4. Magic numbers (1.1 multiplier)\n",
        "5. Inefficient database operations\n",
        "\n",
        "Suggested Modules:\n",
        "- config: Configuration management\n",
        "- data_sources: API and file readers\n",
        "- processors: Data transformation logic\n",
        "- storage: Database operations\n",
        "- reports: Report generation\n",
        "\n",
        "Complexity Score: 8/10 (high)\n",
        "Priority: High - monolithic function doing too much\"\"\"\n",
        "        \n",
        "        # Parse analysis (simplified)\n",
        "        return CodeAnalysis(\n",
        "            issues=[\n",
        "                \"Mixed concerns in single function\",\n",
        "                \"Hardcoded configuration values\",\n",
        "                \"Poor error handling\",\n",
        "                \"Magic numbers\",\n",
        "                \"Inefficient database operations\"\n",
        "            ],\n",
        "            complexity_score=8.0,\n",
        "            suggested_modules=[\"config\", \"data_sources\", \"processors\", \"storage\", \"reports\"],\n",
        "            refactor_priority=\"high\",\n",
        "            architectural_recommendations=[\n",
        "                \"Separate concerns into distinct modules\",\n",
        "                \"Use dependency injection for configuration\",\n",
        "                \"Implement proper error handling with custom exceptions\",\n",
        "                \"Add data validation layer\",\n",
        "                \"Create batch database operations\"\n",
        "            ]\n",
        "        )\n",
        "    \n",
        "    def generate_refactored_module(self, module_name: str, original_code: str, requirements: str) -> str:\n",
        "        \"\"\"Generate a specific refactored module\"\"\"\n",
        "        \n",
        "        refactor_prompt = f\"\"\"Create a clean, well-structured Python module named '{module_name}' \n",
        "by extracting relevant functionality from this code:\n",
        "\n",
        "{original_code[:1000]}...\n",
        "\n",
        "Requirements for {module_name} module:\n",
        "{requirements}\n",
        "\n",
        "Generate code that:\n",
        "1. Follows single responsibility principle\n",
        "2. Has proper error handling\n",
        "3. Includes type hints\n",
        "4. Has clear documentation\n",
        "5. Is testable and modular\n",
        "\n",
        "Return only the Python module code.\"\"\"\n",
        "        \n",
        "        if self.has_api:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": refactor_prompt}],\n",
        "                max_tokens=1000,\n",
        "                temperature=0.2\n",
        "            )\n",
        "            module_code = response.choices[0].message.content\n",
        "        else:\n",
        "            # Mock module code based on module name\n",
        "            if module_name == \"config\":\n",
        "                module_code = '''\"\"\"Configuration management module.\"\"\"\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any\n",
        "import yaml\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Application configuration handler.\"\"\"\n",
        "    \n",
        "    def __init__(self, config_path: Path = None):\n",
        "        self.config_path = config_path or Path(\"config.yaml\")\n",
        "        self._config = self._load_config()\n",
        "    \n",
        "    def _load_config(self) -> Dict[str, Any]:\n",
        "        \"\"\"Load configuration from file.\"\"\"\n",
        "        if self.config_path.exists():\n",
        "            with open(self.config_path) as f:\n",
        "                return yaml.safe_load(f)\n",
        "        return self._default_config()\n",
        "    \n",
        "    def _default_config(self) -> Dict[str, Any]:\n",
        "        return {\n",
        "            \"api_url\": \"https://api.example.com/data\",\n",
        "            \"db_path\": \"data.db\", \n",
        "            \"csv_files\": [\"data1.csv\", \"data2.csv\"],\n",
        "            \"multiplier\": 1.1\n",
        "        }\n",
        "    \n",
        "    def get(self, key: str, default=None):\n",
        "        return self._config.get(key, default)'''\n",
        "            elif module_name == \"processors\":\n",
        "                module_code = '''\"\"\"Data processing module.\"\"\"\n",
        "from typing import List, Dict, Any\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Handle data transformation and cleaning.\"\"\"\n",
        "    \n",
        "    def __init__(self, multiplier: float = 1.1):\n",
        "        self.multiplier = multiplier\n",
        "    \n",
        "    def clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Clean and prepare DataFrame.\"\"\"\n",
        "        df = df.dropna()\n",
        "        df['processed_date'] = datetime.now().isoformat()\n",
        "        return df\n",
        "    \n",
        "    def transform_row(self, row: pd.Series) -> Dict[str, Any]:\n",
        "        \"\"\"Transform a single row of data.\"\"\"\n",
        "        return {\n",
        "            'id': row.get('id', 0),\n",
        "            'value': float(row.get('value', 0)) * self.multiplier,\n",
        "            'category': row.get('category', 'unknown').upper(),\n",
        "            'timestamp': row['processed_date']\n",
        "        }'''\n",
        "            else:\n",
        "                module_code = f'\"\"\"Generated {module_name} module.\"\"\"\\n# Implementation for {module_name}'\n",
        "        \n",
        "        return module_code\n",
        "    \n",
        "    def create_package_structure(self, analysis: CodeAnalysis) -> Dict[str, str]:\n",
        "        \"\"\"Generate complete refactored package structure\"\"\"\n",
        "        \n",
        "        package_structure = {}\n",
        "        \n",
        "        # Module requirements\n",
        "        module_requirements = {\n",
        "            \"config\": \"Configuration management and settings\",\n",
        "            \"data_sources\": \"API clients and file readers\", \n",
        "            \"processors\": \"Data transformation and cleaning logic\",\n",
        "            \"storage\": \"Database operations and persistence\",\n",
        "            \"reports\": \"Report generation and formatting\"\n",
        "        }\n",
        "        \n",
        "        console.print(\"\\nüîß [bold blue]Generating Refactored Package Structure[/bold blue]\")\n",
        "        \n",
        "        for module in analysis.suggested_modules:\n",
        "            if module in module_requirements:\n",
        "                console.print(f\"[yellow]Generating {module} module...[/yellow]\")\n",
        "                requirements = module_requirements[module]\n",
        "                module_code = self.generate_refactored_module(module, legacy_code, requirements)\n",
        "                package_structure[f\"{module}.py\"] = module_code\n",
        "        \n",
        "        # Generate main orchestrator\n",
        "        package_structure[\"main.py\"] = self._generate_main_module(analysis)\n",
        "        package_structure[\"__init__.py\"] = '\"\"\"Data processing package.\"\"\"\\n__version__ = \"1.0.0\"'\n",
        "        \n",
        "        return package_structure\n",
        "    \n",
        "    def _generate_main_module(self, analysis: CodeAnalysis) -> str:\n",
        "        \"\"\"Generate main orchestrator module\"\"\"\n",
        "        return '''\"\"\"Main application orchestrator.\"\"\"\n",
        "from pathlib import Path\n",
        "from .config import Config\n",
        "from .processors import DataProcessor\n",
        "from .data_sources import CSVReader, APIClient\n",
        "from .storage import DatabaseManager\n",
        "from .reports import ReportGenerator\n",
        "\n",
        "class DataProcessingOrchestrator:\n",
        "    \"\"\"Orchestrate the data processing workflow.\"\"\"\n",
        "    \n",
        "    def __init__(self, config_path: Path = None):\n",
        "        self.config = Config(config_path)\n",
        "        self.processor = DataProcessor(self.config.get(\"multiplier\"))\n",
        "        self.db = DatabaseManager(self.config.get(\"db_path\"))\n",
        "        self.report_gen = ReportGenerator()\n",
        "    \n",
        "    def run(self):\n",
        "        \"\"\"Execute the complete data processing pipeline.\"\"\"\n",
        "        # Implementation would orchestrate all modules\n",
        "        pass'''\n",
        "\n",
        "# Initialize refactor agent\n",
        "refactor_agent = CodeRefactorAgent()\n",
        "print(\"ü§ñ Code refactor agent ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo: Refactor Legacy Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze and refactor the legacy code\n",
        "console.print(\"\\nüîç [bold blue]Analyzing Legacy Code Structure[/bold blue]\")\n",
        "\n",
        "# Step 1: Analyze current code\n",
        "analysis = refactor_agent.analyze_code_structure(legacy_code)\n",
        "\n",
        "# Display analysis results\n",
        "console.print(\"\\n[red]Issues Identified:[/red]\")\n",
        "for issue in analysis.issues:\n",
        "    console.print(f\"  ‚Ä¢ {issue}\")\n",
        "\n",
        "console.print(f\"\\n[yellow]Complexity Score:[/yellow] {analysis.complexity_score}/10\")\n",
        "console.print(f\"[yellow]Refactor Priority:[/yellow] {analysis.refactor_priority.upper()}\")\n",
        "\n",
        "console.print(\"\\n[green]Suggested Module Structure:[/green]\")\n",
        "for module in analysis.suggested_modules:\n",
        "    console.print(f\"  üì¶ {module}.py\")\n",
        "\n",
        "console.print(\"\\n[cyan]Architectural Recommendations:[/cyan]\")\n",
        "for rec in analysis.architectural_recommendations:\n",
        "    console.print(f\"  ‚Üí {rec}\")\n",
        "\n",
        "# Step 2: Generate refactored package\n",
        "console.print(\"\\nüèóÔ∏è [bold blue]Generating Refactored Package[/bold blue]\")\n",
        "refactored_package = refactor_agent.create_package_structure(analysis)\n",
        "\n",
        "# Display refactored structure\n",
        "console.print(\"\\nüìÅ [bold green]Refactored Package Structure:[/bold green]\")\n",
        "tree = Tree(\"üì¶ data_processor/\")\n",
        "for filename in sorted(refactored_package.keys()):\n",
        "    tree.add(f\"üìÑ {filename}\")\n",
        "console.print(tree)\n",
        "\n",
        "# Show sample refactored module\n",
        "if \"config.py\" in refactored_package:\n",
        "    console.print(\"\\n[yellow]Sample Refactored Module:[/yellow]\")\n",
        "    config_syntax = Syntax(refactored_package[\"config.py\"], \"python\", theme=\"monokai\", line_numbers=True)\n",
        "    console.print(Panel(config_syntax, title=\"config.py\", border_style=\"green\"))\n",
        "\n",
        "print(\"\\n‚ú® Package refactoring complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways: AI-Powered Refactoring\n",
        "\n",
        "### üéØ **Systematic Refactoring Process**\n",
        "\n",
        "1. **Analysis First**: Understand current structure and identify issues\n",
        "2. **Modular Design**: Break monoliths into single-responsibility modules\n",
        "3. **Dependency Management**: Design clear interfaces between components\n",
        "4. **Quality Gates**: Maintain or improve code quality during refactoring\n",
        "5. **Incremental Changes**: Refactor in manageable, testable chunks\n",
        "\n",
        "### üîß **Benefits of AI-Assisted Refactoring**\n",
        "\n",
        "- **Objective Analysis**: AI identifies issues humans might miss\n",
        "- **Consistent Patterns**: Applies architectural patterns uniformly\n",
        "- **Speed**: Rapidly generates structured alternatives\n",
        "- **Best Practices**: Incorporates modern coding standards\n",
        "- **Documentation**: Auto-generates documentation and comments\n",
        "\n",
        "### ‚ö†Ô∏è **Important Considerations**\n",
        "\n",
        "- **Human Review Required**: AI suggestions need expert validation\n",
        "- **Test Coverage**: Ensure refactored code maintains functionality\n",
        "- **Gradual Migration**: Plan incremental rollout strategy\n",
        "- **Performance Impact**: Validate that refactoring doesn't hurt performance\n",
        "- **Team Alignment**: Ensure architectural decisions align with team standards\n",
        "\n",
        "## Next: Golden Test Demo\n",
        "\n",
        "Ready to see how AI can help create comprehensive test suites for legacy code?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}