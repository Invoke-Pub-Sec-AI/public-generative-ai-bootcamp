{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangChain Essentials - Lab\n",
        "\n",
        "**Hands-on**: \"Knowledge Snippet Agent\" answers one grounded query with citations.\n",
        "**Deliverable**: grounded Q&A.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "In this lab, you will build a Knowledge Snippet Agent using LangChain components. The agent should:\n",
        "\n",
        "1. Load and process documents\n",
        "2. Create embeddings and a vector store\n",
        "3. Build a retrieval system\n",
        "4. Answer a question with proper citations\n",
        "\n",
        "## Success Criteria\n",
        "- Agent retrieves relevant document chunks\n",
        "- Answer is grounded in the retrieved content\n",
        "- Citations are provided for source documents\n",
        "- Output includes confidence/relevance metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Install required packages\n",
        "# Install langchain, langchain-openai, langchain-community, faiss-cpu, tiktoken\n",
        "# Use pip install command"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Import necessary modules\n",
        "# Import document loaders, text splitters, embeddings, vector stores, chains\n",
        "# Import OpenAI components for LLM and embeddings\n",
        "# Set up your OpenAI API key (use environment variable or direct assignment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Prepare Documents\n",
        "\n",
        "Create or load documents that will serve as your knowledge base."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create sample documents or load from files\n",
        "# Create at least 5-10 documents about a topic of your choice\n",
        "# Convert them to LangChain Document objects with proper metadata\n",
        "# Include source information in metadata for citation purposes\n",
        "# Print the number of documents loaded and preview the first document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Split Documents\n",
        "\n",
        "Split your documents into appropriate chunks for processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Initialize a RecursiveCharacterTextSplitter\n",
        "# Set appropriate chunk_size (300-500 characters recommended)\n",
        "# Set chunk_overlap (20-50 characters recommended)\n",
        "# Split your documents and print statistics about the splitting process\n",
        "# Show example of original vs split content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Embeddings and Vector Store\n",
        "\n",
        "Convert your document chunks into embeddings and store them in a vector database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Initialize OpenAI embeddings\n",
        "# Create a FAISS vector store from your split documents\n",
        "# Print confirmation of vector store creation with number of vectors\n",
        "# Test similarity search with a sample query"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Build the Retriever\n",
        "\n",
        "Create a retriever that will find the most relevant documents for a query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create a retriever from your vector store\n",
        "# Configure it to return top 3-5 most similar documents\n",
        "# Test the retriever with a sample query\n",
        "# Display retrieved documents with their sources and similarity scores if available"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create the Knowledge Snippet Agent\n",
        "\n",
        "Build a RetrievalQA chain that combines retrieval with answer generation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Initialize ChatOpenAI model with temperature=0 for consistency\n",
        "# Create a RetrievalQA chain using chain_type=\"stuff\"\n",
        "# Enable return_source_documents=True for citations\n",
        "# Set verbose=True to see the chain's internal processing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Test Your Knowledge Snippet Agent\n",
        "\n",
        "Ask your agent a question and analyze the grounded response with citations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Define a specific question related to your documents\n",
        "# Run the question through your RetrievalQA chain\n",
        "# Display the answer clearly\n",
        "# Show all source documents that were used\n",
        "# Include metadata about each source (document ID, relevance, etc.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Format the Final Output\n",
        "\n",
        "Create a properly formatted response with citations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create a function to format the Q&A output\n",
        "# Include:\n",
        "# - The original question\n",
        "# - The agent's answer\n",
        "# - Numbered citations with source information\n",
        "# - Confidence indicators (number of sources, relevance scores)\n",
        "# Display the formatted output for your deliverable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bonus Challenges (Optional)\n",
        "\n",
        "If you finish early, try these additional tasks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO BONUS 1: Implement a custom prompt template\n",
        "# Create a prompt that explicitly requests citations in a specific format\n",
        "# Test how this changes the output quality"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO BONUS 2: Add relevance scoring\n",
        "# Use similarity_search_with_score to get relevance scores\n",
        "# Filter out documents below a certain relevance threshold\n",
        "# Display confidence metrics based on retrieval scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO BONUS 3: Handle multiple questions\n",
        "# Create a list of 3-5 questions\n",
        "# Process them all and compare the quality of answers\n",
        "# Identify which types of questions work best with your agent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deliverable Checklist\n",
        "\n",
        "Before submitting, ensure your Knowledge Snippet Agent:\n",
        "\n",
        "- [ ] Successfully processes and chunks documents\n",
        "- [ ] Creates embeddings and stores them in a vector database\n",
        "- [ ] Retrieves relevant documents for queries\n",
        "- [ ] Generates grounded answers based on retrieved content\n",
        "- [ ] Provides clear citations with source information\n",
        "- [ ] Includes confidence/relevance indicators\n",
        "- [ ] Formats output professionally for presentation\n",
        "\n",
        "**Final Deliverable**: A working Knowledge Snippet Agent that answers one grounded query with proper citations and source attribution."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}