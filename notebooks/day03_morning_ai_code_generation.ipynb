{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Code Generation in Action\n",
        "\n",
        "## Learning Objectives\n",
        "- Watch AI transform business requirements into complete working applications\n",
        "- See the full journey from idea to deployed solution in minutes\n",
        "- Understand when AI excels vs where human oversight is critical\n",
        "- Learn patterns for spec-first development with AI assistance\n",
        "\n",
        "## The Demo: Business Requirement to Working App\n",
        "\n",
        "We'll start with a realistic business requirement and watch AI build a complete solution including:\n",
        "1. **Requirements Analysis** - Understanding the problem space\n",
        "2. **Architecture Planning** - System design and component breakdown\n",
        "3. **Code Generation** - Implementation with error handling\n",
        "4. **Testing Strategy** - Validation and edge case handling\n",
        "5. **Documentation** - Self-documenting code and usage examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# Import our AskSage client\n",
        "import sys\n",
        "sys.path.append('../../../bootcamp_common')\n",
        "from ask_sage import AskSageClient\n",
        "\n",
        "# Initialize client\n",
        "client = AskSageClient()\n",
        "print(\"AskSage client initialized successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Business Requirement: Document Processing Pipeline\n",
        "\n",
        "**Scenario**: A legal firm needs to automatically extract key information from contracts and generate summaries for review.\n",
        "\n",
        "**Requirements**:\n",
        "- Process PDF and text documents\n",
        "- Extract parties, dates, key terms, and obligations\n",
        "- Generate structured summaries\n",
        "- Handle errors gracefully\n",
        "- Provide confidence scores\n",
        "\n",
        "Let's watch AI build this from scratch..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Requirements Analysis with AI\n",
        "requirements_prompt = \"\"\"\n",
        "Analyze this business requirement and break it down into technical specifications:\n",
        "\n",
        "BUSINESS NEED: Legal firm document processing pipeline\n",
        "- Process PDF and text documents\n",
        "- Extract parties, dates, key terms, obligations\n",
        "- Generate structured summaries\n",
        "- Handle errors gracefully\n",
        "- Provide confidence scores\n",
        "\n",
        "Provide:\n",
        "1. Technical architecture overview\n",
        "2. Key components and their responsibilities\n",
        "3. Data flow and processing steps\n",
        "4. Error handling strategy\n",
        "5. Success metrics\n",
        "\n",
        "Format as structured analysis.\n",
        "\"\"\"\n",
        "\n",
        "response = client.query({\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": requirements_prompt}],\n",
        "    \"temperature\": 0.1,\n",
        "    \"max_tokens\": 1000\n",
        "})\n",
        "\n",
        "analysis = response['choices'][0]['message']['content']\n",
        "print(\"=== AI REQUIREMENTS ANALYSIS ===\")\n",
        "print(analysis)\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Generate Core Document Processor Class\n",
        "code_gen_prompt = f\"\"\"\n",
        "Based on this analysis:\n",
        "{analysis}\n",
        "\n",
        "Generate a complete Python class `DocumentProcessor` that implements the core functionality.\n",
        "\n",
        "Requirements:\n",
        "- Clean, production-ready code with type hints\n",
        "- Comprehensive error handling\n",
        "- Logging for debugging\n",
        "- Confidence scoring for extractions\n",
        "- Structured output format\n",
        "- Docstrings for all methods\n",
        "\n",
        "Include sample usage and test cases.\n",
        "\"\"\"\n",
        "\n",
        "response = client.query({\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": code_gen_prompt}],\n",
        "    \"temperature\": 0.1,\n",
        "    \"max_tokens\": 2000\n",
        "})\n",
        "\n",
        "generated_code = response['choices'][0]['message']['content']\n",
        "print(\"=== AI GENERATED CODE ===\")\n",
        "print(generated_code)\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Execute the generated code to test it works\n",
        "# Save the generated code to a file and import it\n",
        "\n",
        "# Extract just the Python code from the response\n",
        "import re\n",
        "code_blocks = re.findall(r'```python\\n(.*?)```', generated_code, re.DOTALL)\n",
        "if code_blocks:\n",
        "    clean_code = code_blocks[0]\n",
        "else:\n",
        "    # Fallback if no code blocks found\n",
        "    clean_code = generated_code\n",
        "\n",
        "# Write to file\n",
        "with open('/tmp/document_processor.py', 'w') as f:\n",
        "    f.write(clean_code)\n",
        "\n",
        "print(\"Generated code saved to /tmp/document_processor.py\")\n",
        "print(f\"Code length: {len(clean_code)} characters\")\n",
        "\n",
        "# Show first few lines to verify\n",
        "lines = clean_code.split('\\n')[:10]\n",
        "print(\"\\nFirst 10 lines of generated code:\")\n",
        "for i, line in enumerate(lines, 1):\n",
        "    print(f\"{i:2d}: {line}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Generate sample data and test the implementation\n",
        "sample_data_prompt = \"\"\"\n",
        "Create realistic sample contract text that would be processed by our DocumentProcessor.\n",
        "\n",
        "Generate 2 sample contracts:\n",
        "1. A simple service agreement\n",
        "2. A more complex partnership agreement\n",
        "\n",
        "Include typical contract elements:\n",
        "- Party names and roles\n",
        "- Effective dates and terms\n",
        "- Key obligations and deliverables\n",
        "- Payment terms\n",
        "- Termination clauses\n",
        "\n",
        "Format as plain text, realistic but fictional.\n",
        "\"\"\"\n",
        "\n",
        "response = client.query({\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": sample_data_prompt}],\n",
        "    \"temperature\": 0.3,\n",
        "    \"max_tokens\": 1500\n",
        "})\n",
        "\n",
        "sample_contracts = response['choices'][0]['message']['content']\n",
        "print(\"=== SAMPLE CONTRACT DATA ===\")\n",
        "print(sample_contracts[:500] + \"...\")\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Create a complete CLI application\n",
        "cli_prompt = f\"\"\"\n",
        "Create a complete command-line interface for the DocumentProcessor using Click.\n",
        "\n",
        "Requirements:\n",
        "- Accept file path or directory as input\n",
        "- Output format options (JSON, CSV, summary)\n",
        "- Confidence threshold filtering\n",
        "- Verbose logging option\n",
        "- Progress indicators for batch processing\n",
        "- Error reporting and recovery\n",
        "\n",
        "Include:\n",
        "- Proper argument parsing\n",
        "- Help documentation\n",
        "- Example usage\n",
        "- Error handling\n",
        "\n",
        "Make it production-ready with proper structure.\n",
        "\"\"\"\n",
        "\n",
        "response = client.query({\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": cli_prompt}],\n",
        "    \"temperature\": 0.1,\n",
        "    \"max_tokens\": 1500\n",
        "})\n",
        "\n",
        "cli_code = response['choices'][0]['message']['content']\n",
        "print(\"=== CLI APPLICATION CODE ===\")\n",
        "print(cli_code[:800] + \"...\")\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What We Just Witnessed\n",
        "\n",
        "In less than 5 minutes, AI helped us:\n",
        "\n",
        "1. **Analyze Requirements** - Broke down business needs into technical specs\n",
        "2. **Design Architecture** - Created a clear component structure\n",
        "3. **Generate Code** - Built a complete, documented class with error handling\n",
        "4. **Create Test Data** - Generated realistic sample contracts\n",
        "5. **Build CLI Interface** - Created a production-ready command-line tool\n",
        "\n",
        "### Key Observations:\n",
        "\n",
        "**Where AI Excelled:**\n",
        "- Rapid prototyping and scaffolding\n",
        "- Consistent code structure and patterns\n",
        "- Comprehensive error handling\n",
        "- Documentation generation\n",
        "- Sample data creation\n",
        "\n",
        "**Where Human Oversight is Critical:**\n",
        "- Business logic validation\n",
        "- Security considerations\n",
        "- Performance optimization\n",
        "- Integration testing\n",
        "- Production deployment\n",
        "\n",
        "### Next Steps in Real Development:\n",
        "1. Code review and testing\n",
        "2. Security audit\n",
        "3. Performance benchmarking\n",
        "4. Integration with existing systems\n",
        "5. User acceptance testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstration summary\n",
        "print(\"=== DEMO SUMMARY ===\")\n",
        "print(\"\\nTime to working prototype: ~5 minutes\")\n",
        "print(\"Lines of code generated: ~200-300\")\n",
        "print(\"Components created:\")\n",
        "print(\"  - DocumentProcessor class\")\n",
        "print(\"  - CLI interface\")\n",
        "print(\"  - Sample data\")\n",
        "print(\"  - Error handling\")\n",
        "print(\"  - Documentation\")\n",
        "print(\"\\nReady for: Code review, testing, refinement\")\n",
        "print(\"Next phase: Human validation and production hardening\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}