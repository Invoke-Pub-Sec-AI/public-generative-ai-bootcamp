{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Human-in-the-Loop & AI Decision Making Demo with AskSage\n",
        "\n",
        "## Focus: AI-Powered Approval Gates with GPT-5-Mini\n",
        "\n",
        "This notebook demonstrates real AI integration for human oversight in automated systems using AskSage with GPT-5-Mini:\n",
        "- **AI-Powered Risk Assessment**: Using GPT-5-Mini to evaluate action risks and confidence levels\n",
        "- **Intelligent Approval Gates**: AI-driven decision making with human oversight\n",
        "- **Smart Stop/Ask Thresholds**: Dynamic confidence evaluation using large language models\n",
        "- **AI-Enhanced Acceptance Criteria**: Automated business rule validation with natural language understanding\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install asksageclient pandas matplotlib seaborn plotly ipywidgets\n",
        "\n",
        "# All required imports for this notebook\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "from typing import Dict, List, Any, Optional\n",
        "from dataclasses import dataclass, asdict\n",
        "from enum import Enum\n",
        "from datetime import datetime\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# AskSage client for AI integration\n",
        "from asksageclient import AskSageClient\n",
        "\n",
        "print(\"ü§ñ AI-Powered Human-in-the-Loop Demo Environment Setup Complete\")\n",
        "print(\"üîß Ready to demonstrate AI-enhanced approval gates with GPT-5-Mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. AskSage Client Setup for GPT-5-Mini\n",
        "\n",
        "Configure the AskSage client to use GPT-5-Mini for AI-powered decision making."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AskSage Client Configuration\n",
        "# NOTE: You need to set up your AskSage credentials\n",
        "# Create a credentials.json file or set environment variables\n",
        "\n",
        "# Option 1: Using environment variables (recommended)\n",
        "ASKSAGE_API_KEY = os.getenv('ASKSAGE_API_KEY')\n",
        "ASKSAGE_BASE_URL = os.getenv('ASKSAGE_BASE_URL', 'https://api.asksage.ai')\n",
        "\n",
        "# Option 2: Direct configuration (for demo purposes)\n",
        "# ASKSAGE_API_KEY = \"your_api_key_here\"\n",
        "# ASKSAGE_BASE_URL = \"https://api.asksage.ai\"\n",
        "\n",
        "if not ASKSAGE_API_KEY:\n",
        "    print(\"‚ö†Ô∏è WARNING: ASKSAGE_API_KEY not found in environment variables\")\n",
        "    print(\"Please set your AskSage API key to use GPT-5-Mini integration\")\n",
        "    ASKSAGE_API_KEY = \"demo_key_placeholder\"  # For demo structure\n",
        "\n",
        "# Initialize AskSage client\n",
        "try:\n",
        "    ask_sage_client = AskSageClient(\n",
        "        api_key=ASKSAGE_API_KEY,\n",
        "        base_url=ASKSAGE_BASE_URL\n",
        "    )\n",
        "    print(\"‚úÖ AskSage client initialized successfully\")\n",
        "    print(\"üéØ Target Model: GPT-5-Mini for AI decision making\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing AskSage client: {e}\")\n",
        "    print(\"üìù Continuing with demo structure (AI features will be simulated)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Enhanced Risk Assessment Framework with AI\n",
        "\n",
        "Build a framework that uses GPT-5-Mini to intelligently assess action risks and confidence levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RiskLevel(Enum):\n",
        "    LOW = \"low\"\n",
        "    MEDIUM = \"medium\"\n",
        "    HIGH = \"high\"\n",
        "    CRITICAL = \"critical\"\n",
        "\n",
        "class ActionStatus(Enum):\n",
        "    PENDING = \"pending\"\n",
        "    APPROVED = \"approved\"\n",
        "    DENIED = \"denied\"\n",
        "    EXPIRED = \"expired\"\n",
        "\n",
        "@dataclass\n",
        "class ActionRequest:\n",
        "    id: str\n",
        "    description: str\n",
        "    proposed_action: Dict[str, Any]\n",
        "    timestamp: str\n",
        "    context: str = \"\"\n",
        "    ai_risk_assessment: Optional[Dict[str, Any]] = None\n",
        "    ai_confidence: Optional[float] = None\n",
        "    risk_level: Optional[RiskLevel] = None\n",
        "    status: ActionStatus = ActionStatus.PENDING\n",
        "    approval_reason: Optional[str] = None\n",
        "    approver: Optional[str] = None\n",
        "\n",
        "def query_gpt5_mini(prompt: str, system_prompt: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Query GPT-5-Mini through AskSage for AI decision making.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = ask_sage_client.query(\n",
        "            message=prompt,\n",
        "            model=\"gpt-5-mini\",  # Specifically using GPT-5-Mini as requested\n",
        "            system_prompt=system_prompt,\n",
        "            temperature=0.1  # Low temperature for consistent decision making\n",
        "        )\n",
        "        \n",
        "        if isinstance(response, dict) and 'response' in response:\n",
        "            return response['response']\n",
        "        return str(response)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è GPT-5-Mini query failed: {e}\")\n",
        "        return f\"AI_ERROR: {str(e)}\"\n",
        "\n",
        "def ai_assess_action_risk(request: ActionRequest) -> ActionRequest:\n",
        "    \"\"\"\n",
        "    Use GPT-5-Mini to assess the risk level and confidence of an action request.\n",
        "    \"\"\"\n",
        "    system_prompt = \"\"\"\n",
        "You are an expert AI risk assessment system. Analyze the provided action request and return a JSON response with:\n",
        "1. risk_level: one of [\"low\", \"medium\", \"high\", \"critical\"]\n",
        "2. confidence: a float between 0.0 and 1.0\n",
        "3. reasoning: a brief explanation of your assessment\n",
        "4. potential_impacts: list of potential positive and negative impacts\n",
        "5. mitigation_suggestions: list of risk mitigation recommendations\n",
        "\n",
        "Consider factors like:\n",
        "- Data sensitivity and scope of impact\n",
        "- Reversibility of the action\n",
        "- System criticality\n",
        "- Security implications\n",
        "- Business continuity impact\n",
        "\n",
        "Respond only with valid JSON.\n",
        "\"\"\"\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "Assess this action request:\n",
        "ID: {request.id}\n",
        "Description: {request.description}\n",
        "Proposed Action: {json.dumps(request.proposed_action, indent=2)}\n",
        "Context: {request.context}\n",
        "Timestamp: {request.timestamp}\n",
        "\n",
        "Provide risk assessment as JSON:\n",
        "\"\"\"\n",
        "    \n",
        "    ai_response = query_gpt5_mini(prompt, system_prompt)\n",
        "    \n",
        "    try:\n",
        "        # Parse AI response as JSON\n",
        "        ai_assessment = json.loads(ai_response)\n",
        "        \n",
        "        # Update request with AI assessment\n",
        "        request.ai_risk_assessment = ai_assessment\n",
        "        request.ai_confidence = ai_assessment.get('confidence', 0.5)\n",
        "        request.risk_level = RiskLevel(ai_assessment.get('risk_level', 'medium'))\n",
        "        \n",
        "    except (json.JSONDecodeError, ValueError) as e:\n",
        "        print(f\"‚ö†Ô∏è AI response parsing failed: {e}\")\n",
        "        # Fallback to simulated assessment\n",
        "        request.ai_risk_assessment = {\n",
        "            \"risk_level\": \"medium\",\n",
        "            \"confidence\": 0.7,\n",
        "            \"reasoning\": \"Fallback assessment due to AI parsing error\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "        request.ai_confidence = 0.7\n",
        "        request.risk_level = RiskLevel.MEDIUM\n",
        "    \n",
        "    return request\n",
        "\n",
        "# Example action requests for testing\n",
        "sample_requests = [\n",
        "    ActionRequest(\n",
        "        id=\"req_001\",\n",
        "        description=\"Delete temporary log files older than 7 days\",\n",
        "        proposed_action={\"command\": \"rm\", \"path\": \"/var/log/temp/*\", \"age\": \"7d\", \"pattern\": \"*.log\"},\n",
        "        context=\"Routine maintenance to free up disk space on development server\",\n",
        "        timestamp=datetime.now().isoformat()\n",
        "    ),\n",
        "    ActionRequest(\n",
        "        id=\"req_002\",\n",
        "        description=\"Update production database schema to add new user preferences table\",\n",
        "        proposed_action={\n",
        "            \"operation\": \"CREATE TABLE\", \n",
        "            \"table\": \"user_preferences\", \n",
        "            \"database\": \"production_users\",\n",
        "            \"backup_required\": True\n",
        "        },\n",
        "        context=\"Adding new feature for user customization settings\",\n",
        "        timestamp=datetime.now().isoformat()\n",
        "    ),\n",
        "    ActionRequest(\n",
        "        id=\"req_003\",\n",
        "        description=\"Deploy hotfix to resolve critical security vulnerability\",\n",
        "        proposed_action={\n",
        "            \"operation\": \"deploy\",\n",
        "            \"target\": \"production\",\n",
        "            \"version\": \"v2.1.3-hotfix\",\n",
        "            \"rollback_plan\": \"automated\"\n",
        "        },\n",
        "        context=\"Emergency deployment to patch CVE-2024-12345 discovered in authentication module\",\n",
        "        timestamp=datetime.now().isoformat()\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"ü§ñ AI Risk Assessment Framework Initialized\")\n",
        "print(\"üìù Sample requests created for GPT-5-Mini evaluation\")\n",
        "for req in sample_requests:\n",
        "    print(f\"  üéØ {req.id}: {req.description}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. AI-Powered Risk Assessment in Action\n",
        "\n",
        "Let GPT-5-Mini evaluate each action request and provide intelligent risk assessments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîç Running AI Risk Assessment with GPT-5-Mini...\\n\")\n",
        "\n",
        "assessed_requests = []\n",
        "for request in sample_requests:\n",
        "    print(f\"ü§ñ Analyzing {request.id}: {request.description}\")\n",
        "    \n",
        "    # Get AI risk assessment from GPT-5-Mini\n",
        "    assessed_request = ai_assess_action_risk(request)\n",
        "    assessed_requests.append(assessed_request)\n",
        "    \n",
        "    # Display results\n",
        "    print(f\"   üéØ AI Risk Level: {assessed_request.risk_level.value.upper()}\")\n",
        "    print(f\"   üìä AI Confidence: {assessed_request.ai_confidence:.1%}\")\n",
        "    \n",
        "    if assessed_request.ai_risk_assessment:\n",
        "        reasoning = assessed_request.ai_risk_assessment.get('reasoning', 'N/A')\n",
        "        print(f\"   üí≠ AI Reasoning: {reasoning}\")\n",
        "        \n",
        "        impacts = assessed_request.ai_risk_assessment.get('potential_impacts', [])\n",
        "        if impacts:\n",
        "            print(f\"   ‚ö° Potential Impacts: {', '.join(impacts[:2])}...\")\n",
        "    \n",
        "    print(\"   \" + \"=\"*50)\n",
        "    print()\n",
        "\n",
        "print(\"‚úÖ AI Risk Assessment Complete\")\n",
        "print(f\"üìà Processed {len(assessed_requests)} requests using GPT-5-Mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Dynamic Threshold Configuration with AI Insights\n",
        "\n",
        "Configure intelligent thresholds that adapt based on AI confidence and risk assessment patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class AIThresholdConfig:\n",
        "    risk_level: RiskLevel\n",
        "    auto_approve_threshold: float  # AI confidence level for automatic approval\n",
        "    ask_threshold: float          # AI confidence level that requires human input\n",
        "    deny_threshold: float         # Below this AI confidence, automatically deny\n",
        "    ai_reasoning_required: bool   # Whether AI reasoning is required for decisions\n",
        "\n",
        "# AI-enhanced threshold configurations\n",
        "AI_THRESHOLD_CONFIGS = {\n",
        "    RiskLevel.LOW: AIThresholdConfig(\n",
        "        risk_level=RiskLevel.LOW,\n",
        "        auto_approve_threshold=0.85,  # Lower threshold due to AI analysis\n",
        "        ask_threshold=0.65,\n",
        "        deny_threshold=0.40,\n",
        "        ai_reasoning_required=False\n",
        "    ),\n",
        "    RiskLevel.MEDIUM: AIThresholdConfig(\n",
        "        risk_level=RiskLevel.MEDIUM,\n",
        "        auto_approve_threshold=0.90,\n",
        "        ask_threshold=0.75,\n",
        "        deny_threshold=0.50,\n",
        "        ai_reasoning_required=True\n",
        "    ),\n",
        "    RiskLevel.HIGH: AIThresholdConfig(\n",
        "        risk_level=RiskLevel.HIGH,\n",
        "        auto_approve_threshold=0.95,\n",
        "        ask_threshold=0.80,\n",
        "        deny_threshold=0.60,\n",
        "        ai_reasoning_required=True\n",
        "    ),\n",
        "    RiskLevel.CRITICAL: AIThresholdConfig(\n",
        "        risk_level=RiskLevel.CRITICAL,\n",
        "        auto_approve_threshold=0.99,  # Nearly impossible to auto-approve\n",
        "        ask_threshold=0.85,\n",
        "        deny_threshold=0.70,\n",
        "        ai_reasoning_required=True\n",
        "    )\n",
        "}\n",
        "\n",
        "def ai_evaluate_action_requirement(request: ActionRequest) -> str:\n",
        "    \"\"\"\n",
        "    Use AI assessment to determine if an action requires approval.\n",
        "    \"\"\"\n",
        "    if not request.risk_level or request.ai_confidence is None:\n",
        "        return \"AI_ASSESSMENT_REQUIRED\"\n",
        "    \n",
        "    config = AI_THRESHOLD_CONFIGS[request.risk_level]\n",
        "    \n",
        "    # Check if AI reasoning is available when required\n",
        "    if config.ai_reasoning_required:\n",
        "        if not request.ai_risk_assessment or not request.ai_risk_assessment.get('reasoning'):\n",
        "            return \"AI_REASONING_REQUIRED\"\n",
        "    \n",
        "    # Evaluate based on AI confidence\n",
        "    if request.ai_confidence >= config.auto_approve_threshold:\n",
        "        return \"AUTO_APPROVE\"\n",
        "    elif request.ai_confidence >= config.ask_threshold:\n",
        "        return \"ASK_HUMAN\"\n",
        "    elif request.ai_confidence >= config.deny_threshold:\n",
        "        return \"ASK_HUMAN\"  # Low confidence but not below deny threshold\n",
        "    else:\n",
        "        return \"AUTO_DENY\"\n",
        "\n",
        "def generate_ai_approval_prompt(request: ActionRequest) -> str:\n",
        "    \"\"\"\n",
        "    Generate an intelligent approval prompt using AI insights.\n",
        "    \"\"\"\n",
        "    system_prompt = \"\"\"\n",
        "You are an AI assistant helping with human approval decisions. \n",
        "Generate a clear, concise approval prompt that highlights key decision factors.\n",
        "Include risk summary, confidence level, and specific recommendations.\n",
        "\"\"\"\n",
        "    \n",
        "    prompt = f\"\"\"\n",
        "Generate an approval prompt for this action:\n",
        "ID: {request.id}\n",
        "Description: {request.description}\n",
        "AI Risk Level: {request.risk_level.value if request.risk_level else 'Unknown'}\n",
        "AI Confidence: {request.ai_confidence:.1%} if request.ai_confidence else 'Unknown'\n",
        "AI Assessment: {json.dumps(request.ai_risk_assessment, indent=2) if request.ai_risk_assessment else 'Not available'}\n",
        "\n",
        "Create a concise human-readable approval prompt.\n",
        "\"\"\"\n",
        "    \n",
        "    ai_prompt = query_gpt5_mini(prompt, system_prompt)\n",
        "    return ai_prompt\n",
        "\n",
        "print(\"‚öôÔ∏è AI-Enhanced Threshold Configuration:\")\n",
        "for risk_level, config in AI_THRESHOLD_CONFIGS.items():\n",
        "    reasoning_req = \"‚úì\" if config.ai_reasoning_required else \"‚úó\"\n",
        "    print(f\"  {risk_level.value.upper()}: Auto‚â•{config.auto_approve_threshold:.0%}, Ask‚â•{config.ask_threshold:.0%}, Deny<{config.deny_threshold:.0%}, AI Reasoning: {reasoning_req}\")\n",
        "\n",
        "print(\"\\nüîç Evaluating Sample Requests with AI Decision Logic:\")\n",
        "for req in assessed_requests:\n",
        "    decision = ai_evaluate_action_requirement(req)\n",
        "    confidence_str = f\"{req.ai_confidence:.0%}\" if req.ai_confidence else \"N/A\"\n",
        "    risk_str = req.risk_level.value.upper() if req.risk_level else \"N/A\"\n",
        "    print(f\"  {req.id}: {decision} (AI Risk: {risk_str}, AI Confidence: {confidence_str})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. AI-Enhanced Acceptance Criteria\n",
        "\n",
        "Implement acceptance tests that leverage GPT-5-Mini's natural language understanding for intelligent business rule validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AIAcceptanceCriterion(ABC):\n",
        "    \"\"\"Base class for AI-enhanced acceptance criteria tests.\"\"\"\n",
        "    \n",
        "    def __init__(self, name: str, description: str, use_ai: bool = True):\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.use_ai = use_ai\n",
        "    \n",
        "    @abstractmethod\n",
        "    def evaluate(self, request: ActionRequest) -> bool:\n",
        "        \"\"\"Return True if the criterion is met.\"\"\"\n",
        "        pass\n",
        "    \n",
        "    def ai_evaluate(self, request: ActionRequest, rule_description: str) -> Dict[str, Any]:\n",
        "        \"\"\"Use GPT-5-Mini to evaluate complex business rules.\"\"\"\n",
        "        system_prompt = f\"\"\"\n",
        "You are an AI system evaluating business rules for action approval.\n",
        "Rule: {rule_description}\n",
        "\n",
        "Analyze the action request and return JSON with:\n",
        "- passes: boolean (true if rule is satisfied)\n",
        "- confidence: float 0.0-1.0 (how confident you are)\n",
        "- reasoning: string explaining your evaluation\n",
        "- concerns: list of any concerns or edge cases identified\n",
        "\n",
        "Respond only with valid JSON.\n",
        "\"\"\"\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "Evaluate this action against the business rule:\n",
        "\n",
        "Action: {request.description}\n",
        "Details: {json.dumps(request.proposed_action, indent=2)}\n",
        "Context: {request.context}\n",
        "Risk Level: {request.risk_level.value if request.risk_level else 'Unknown'}\n",
        "\n",
        "Does this action satisfy the business rule?\n",
        "\"\"\"\n",
        "        \n",
        "        ai_response = query_gpt5_mini(prompt, system_prompt)\n",
        "        \n",
        "        try:\n",
        "            return json.loads(ai_response)\n",
        "        except json.JSONDecodeError:\n",
        "            return {\n",
        "                \"passes\": False,\n",
        "                \"confidence\": 0.0,\n",
        "                \"reasoning\": \"AI evaluation failed - JSON parse error\",\n",
        "                \"concerns\": [\"Could not parse AI response\"]\n",
        "            }\n",
        "\n",
        "class AIProductionDataProtection(AIAcceptanceCriterion):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            \"ai-prod-data-protection\",\n",
        "            \"AI-enhanced protection against production data operations\",\n",
        "            use_ai=True\n",
        "        )\n",
        "    \n",
        "    def evaluate(self, request: ActionRequest) -> bool:\n",
        "        if not self.use_ai:\n",
        "            # Fallback to simple pattern matching\n",
        "            action = request.proposed_action\n",
        "            dangerous_ops = [\"rm\", \"DELETE\", \"DROP\", \"TRUNCATE\"]\n",
        "            return not any(op in str(action) for op in dangerous_ops if \"prod\" in str(action).lower())\n",
        "        \n",
        "        rule = \"Prevent any destructive operations (delete, drop, truncate) on production data without explicit safeguards and approval workflows.\"\n",
        "        ai_result = self.ai_evaluate(request, rule)\n",
        "        return ai_result.get('passes', False)\n",
        "\n",
        "class AIBusinessHoursCompliance(AIAcceptanceCriterion):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            \"ai-business-hours\",\n",
        "            \"AI-powered business hours and maintenance window compliance\",\n",
        "            use_ai=True\n",
        "        )\n",
        "    \n",
        "    def evaluate(self, request: ActionRequest) -> bool:\n",
        "        if not self.use_ai:\n",
        "            # Simple time-based check\n",
        "            current_hour = datetime.now().hour\n",
        "            if request.risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]:\n",
        "                return 9 <= current_hour <= 17\n",
        "            return True\n",
        "        \n",
        "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S %A\")\n",
        "        rule = f\"High-risk operations should only be performed during business hours (9 AM - 5 PM, Monday-Friday) unless it's an emergency. Current time: {current_time}\"\n",
        "        ai_result = self.ai_evaluate(request, rule)\n",
        "        return ai_result.get('passes', True)\n",
        "\n",
        "class AISecurityComplianceCheck(AIAcceptanceCriterion):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            \"ai-security-compliance\",\n",
        "            \"AI-powered security and compliance validation\",\n",
        "            use_ai=True\n",
        "        )\n",
        "    \n",
        "    def evaluate(self, request: ActionRequest) -> bool:\n",
        "        rule = \"\"\"\n",
        "Ensure the action complies with security best practices:\n",
        "1. No hardcoded credentials or secrets\n",
        "2. Appropriate access controls and permissions\n",
        "3. Audit trail and logging requirements\n",
        "4. Data privacy and protection compliance\n",
        "5. Change management and approval workflows\n",
        "\"\"\"\n",
        "        ai_result = self.ai_evaluate(request, rule)\n",
        "        return ai_result.get('passes', False)\n",
        "\n",
        "# Define AI-enhanced acceptance test suite\n",
        "AI_ACCEPTANCE_CRITERIA = [\n",
        "    AIProductionDataProtection(),\n",
        "    AIBusinessHoursCompliance(),\n",
        "    AISecurityComplianceCheck()\n",
        "]\n",
        "\n",
        "def run_ai_acceptance_tests(request: ActionRequest) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Run all AI-enhanced acceptance criteria tests on a request.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    all_passed = True\n",
        "    ai_insights = []\n",
        "    \n",
        "    print(f\"üß™ Running AI acceptance tests for {request.id}...\")\n",
        "    \n",
        "    for criterion in AI_ACCEPTANCE_CRITERIA:\n",
        "        try:\n",
        "            passed = criterion.evaluate(request)\n",
        "            \n",
        "            # Get AI insights if available\n",
        "            if criterion.use_ai and hasattr(criterion, '_last_ai_result'):\n",
        "                ai_insight = getattr(criterion, '_last_ai_result', {})\n",
        "                ai_insights.append({\n",
        "                    \"criterion\": criterion.name,\n",
        "                    \"reasoning\": ai_insight.get('reasoning', ''),\n",
        "                    \"concerns\": ai_insight.get('concerns', [])\n",
        "                })\n",
        "            \n",
        "            results[criterion.name] = {\n",
        "                \"passed\": passed,\n",
        "                \"description\": criterion.description,\n",
        "                \"ai_enhanced\": criterion.use_ai\n",
        "            }\n",
        "            \n",
        "            if not passed:\n",
        "                all_passed = False\n",
        "                \n",
        "        except Exception as e:\n",
        "            results[criterion.name] = {\n",
        "                \"passed\": False,\n",
        "                \"description\": criterion.description,\n",
        "                \"error\": str(e),\n",
        "                \"ai_enhanced\": criterion.use_ai\n",
        "            }\n",
        "            all_passed = False\n",
        "    \n",
        "    return {\n",
        "        \"all_passed\": all_passed, \n",
        "        \"criteria_results\": results,\n",
        "        \"ai_insights\": ai_insights\n",
        "    }\n",
        "\n",
        "print(\"üß™ AI-Enhanced Acceptance Criteria Test Suite:\")\n",
        "for criterion in AI_ACCEPTANCE_CRITERIA:\n",
        "    ai_badge = \"ü§ñ\" if criterion.use_ai else \"üîß\"\n",
        "    print(f\"  {ai_badge} {criterion.name}: {criterion.description}\")\n",
        "\n",
        "print(\"\\nüìã Testing Sample Requests with AI Acceptance Criteria:\")\n",
        "for req in assessed_requests:\n",
        "    test_results = run_ai_acceptance_tests(req)\n",
        "    status = \"‚úÖ PASS\" if test_results[\"all_passed\"] else \"‚ùå FAIL\"\n",
        "    print(f\"\\n  {req.id}: {status}\")\n",
        "    \n",
        "    for name, result in test_results[\"criteria_results\"].items():\n",
        "        icon = \"‚úì\" if result[\"passed\"] else \"‚úó\"\n",
        "        ai_badge = \"ü§ñ\" if result.get(\"ai_enhanced\") else \"üîß\"\n",
        "        print(f\"    {icon} {ai_badge} {name}\")\n",
        "        \n",
        "        if \"error\" in result:\n",
        "            print(f\"      ‚ö†Ô∏è Error: {result['error']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Complete AI-Powered Approval Workflow\n",
        "\n",
        "Integrate all components into a comprehensive workflow that leverages GPT-5-Mini for intelligent decision making."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AIApprovalWorkflow:\n",
        "    def __init__(self):\n",
        "        self.pending_requests = {}\n",
        "        self.completed_requests = {}\n",
        "        self.ai_insights_log = []\n",
        "    \n",
        "    def process_request(self, request: ActionRequest) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Process an action request through the complete AI-enhanced workflow.\n",
        "        \"\"\"\n",
        "        workflow_log = []\n",
        "        \n",
        "        # Step 1: AI Risk Assessment\n",
        "        workflow_log.append(\"ü§ñ Running AI risk assessment with GPT-5-Mini...\")\n",
        "        if not request.ai_risk_assessment:\n",
        "            request = ai_assess_action_risk(request)\n",
        "        \n",
        "        risk_level = request.risk_level.value if request.risk_level else \"unknown\"\n",
        "        confidence = request.ai_confidence or 0.0\n",
        "        workflow_log.append(f\"üéØ AI Assessment: {risk_level.upper()} risk, {confidence:.0%} confidence\")\n",
        "        \n",
        "        # Step 2: AI-Enhanced Acceptance Tests\n",
        "        workflow_log.append(\"üß™ Running AI-enhanced acceptance criteria tests...\")\n",
        "        acceptance_results = run_ai_acceptance_tests(request)\n",
        "        \n",
        "        if not acceptance_results[\"all_passed\"]:\n",
        "            request.status = ActionStatus.DENIED\n",
        "            request.approval_reason = \"Failed AI-enhanced acceptance criteria\"\n",
        "            workflow_log.append(\"‚ùå Request denied - failed AI acceptance tests\")\n",
        "            \n",
        "            self.completed_requests[request.id] = request\n",
        "            return {\n",
        "                \"status\": \"denied\",\n",
        "                \"reason\": \"ai_acceptance_criteria_failed\",\n",
        "                \"workflow_log\": workflow_log,\n",
        "                \"acceptance_results\": acceptance_results\n",
        "            }\n",
        "        \n",
        "        workflow_log.append(\"‚úÖ AI acceptance tests passed\")\n",
        "        \n",
        "        # Step 3: AI-Powered Threshold Evaluation\n",
        "        workflow_log.append(\"‚öñÔ∏è Evaluating with AI-enhanced thresholds...\")\n",
        "        decision = ai_evaluate_action_requirement(request)\n",
        "        \n",
        "        if decision == \"AUTO_APPROVE\":\n",
        "            request.status = ActionStatus.APPROVED\n",
        "            request.approval_reason = f\"Auto-approved by AI system (confidence: {confidence:.0%})\"\n",
        "            request.approver = \"gpt-5-mini\"\n",
        "            workflow_log.append(\"‚úÖ Auto-approved by AI system\")\n",
        "            \n",
        "            self.completed_requests[request.id] = request\n",
        "            return {\n",
        "                \"status\": \"approved\",\n",
        "                \"reason\": \"ai_auto_approved\",\n",
        "                \"workflow_log\": workflow_log,\n",
        "                \"ai_assessment\": request.ai_risk_assessment\n",
        "            }\n",
        "        \n",
        "        elif decision == \"AUTO_DENY\":\n",
        "            request.status = ActionStatus.DENIED\n",
        "            request.approval_reason = f\"Auto-denied by AI system (low confidence: {confidence:.0%})\"\n",
        "            workflow_log.append(\"‚ùå Auto-denied by AI system\")\n",
        "            \n",
        "            self.completed_requests[request.id] = request\n",
        "            return {\n",
        "                \"status\": \"denied\",\n",
        "                \"reason\": \"ai_auto_denied\",\n",
        "                \"workflow_log\": workflow_log,\n",
        "                \"ai_assessment\": request.ai_risk_assessment\n",
        "            }\n",
        "        \n",
        "        # Step 4: Generate AI-Powered Human Approval Prompt\n",
        "        workflow_log.append(\"üë§ Human approval required - generating AI-powered prompt\")\n",
        "        ai_approval_prompt = generate_ai_approval_prompt(request)\n",
        "        \n",
        "        self.pending_requests[request.id] = request\n",
        "        \n",
        "        return {\n",
        "            \"status\": \"pending_approval\",\n",
        "            \"reason\": \"human_approval_required\",\n",
        "            \"workflow_log\": workflow_log,\n",
        "            \"ai_approval_prompt\": ai_approval_prompt,\n",
        "            \"ai_assessment\": request.ai_risk_assessment,\n",
        "            \"acceptance_results\": acceptance_results\n",
        "        }\n",
        "    \n",
        "    def get_ai_insights_summary(self) -> str:\n",
        "        \"\"\"\n",
        "        Generate a summary of AI insights from processed requests.\n",
        "        \"\"\"\n",
        "        system_prompt = \"\"\"\n",
        "You are an AI system analyst. Summarize the key insights and patterns \n",
        "from the approval workflow data. Focus on:\n",
        "1. Common risk patterns\n",
        "2. Decision trends\n",
        "3. Areas for improvement\n",
        "4. Recommendations for threshold tuning\n",
        "\n",
        "Keep the summary concise and actionable.\n",
        "\"\"\"\n",
        "        \n",
        "        all_requests = list(self.completed_requests.values()) + list(self.pending_requests.values())\n",
        "        insights_data = {\n",
        "            \"total_requests\": len(all_requests),\n",
        "            \"risk_levels\": [r.risk_level.value for r in all_requests if r.risk_level],\n",
        "            \"confidence_levels\": [r.ai_confidence for r in all_requests if r.ai_confidence],\n",
        "            \"statuses\": [r.status.value for r in all_requests]\n",
        "        }\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "Analyze this approval workflow data:\n",
        "{json.dumps(insights_data, indent=2)}\n",
        "\n",
        "Provide insights and recommendations:\n",
        "\"\"\"\n",
        "        \n",
        "        return query_gpt5_mini(prompt, system_prompt)\n",
        "\n",
        "# Demo the complete AI-powered workflow\n",
        "ai_workflow = AIApprovalWorkflow()\n",
        "\n",
        "print(\"üîÑ Processing Sample Requests Through AI-Powered Workflow:\\n\")\n",
        "for req in sample_requests:\n",
        "    print(f\"üìù Processing {req.id}: {req.description}\")\n",
        "    print(f\"   Context: {req.context}\")\n",
        "    \n",
        "    result = ai_workflow.process_request(req)\n",
        "    \n",
        "    print(f\"   üéØ Result: {result['status'].upper()}\")\n",
        "    for log_entry in result['workflow_log']:\n",
        "        print(f\"     {log_entry}\")\n",
        "    \n",
        "    if result['status'] == 'pending_approval':\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"ü§ñ AI-GENERATED APPROVAL PROMPT:\")\n",
        "        print(\"=\"*70)\n",
        "        print(result['ai_approval_prompt'])\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "    \n",
        "    elif 'ai_assessment' in result and result['ai_assessment']:\n",
        "        assessment = result['ai_assessment']\n",
        "        print(f\"     üß† AI Reasoning: {assessment.get('reasoning', 'N/A')}\")\n",
        "        if 'mitigation_suggestions' in assessment:\n",
        "            print(f\"     üõ°Ô∏è AI Suggestions: {', '.join(assessment['mitigation_suggestions'][:2])}\")\n",
        "    \n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. AI Insights and Workflow Analytics\n",
        "\n",
        "Generate intelligent insights about the approval workflow using GPT-5-Mini's analytical capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üß† Generating AI Insights Summary with GPT-5-Mini...\\n\")\n",
        "\n",
        "insights_summary = ai_workflow.get_ai_insights_summary()\n",
        "print(\"üìä AI WORKFLOW ANALYTICS & INSIGHTS:\")\n",
        "print(\"=\"*60)\n",
        "print(insights_summary)\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Additional workflow statistics\n",
        "all_requests = list(ai_workflow.completed_requests.values()) + list(ai_workflow.pending_requests.values())\n",
        "print(\"\\nüìà WORKFLOW STATISTICS:\")\n",
        "print(f\"Total Requests Processed: {len(all_requests)}\")\n",
        "print(f\"Completed: {len(ai_workflow.completed_requests)}\")\n",
        "print(f\"Pending Human Approval: {len(ai_workflow.pending_requests)}\")\n",
        "\n",
        "if all_requests:\n",
        "    risk_distribution = {}\n",
        "    for req in all_requests:\n",
        "        if req.risk_level:\n",
        "            risk_distribution[req.risk_level.value] = risk_distribution.get(req.risk_level.value, 0) + 1\n",
        "    \n",
        "    print(\"\\nRisk Level Distribution:\")\n",
        "    for risk, count in risk_distribution.items():\n",
        "        print(f\"  {risk.upper()}: {count}\")\n",
        "    \n",
        "    avg_confidence = sum(r.ai_confidence for r in all_requests if r.ai_confidence) / len([r for r in all_requests if r.ai_confidence])\n",
        "    print(f\"\\nAverage AI Confidence: {avg_confidence:.1%}\")\n",
        "\n",
        "print(\"\\n‚ú® Demo completed successfully with GPT-5-Mini integration!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Demo Summary & Key Takeaways\n",
        "\n",
        "### What We've Demonstrated with GPT-5-Mini:\n",
        "\n",
        "1. **AI-Powered Risk Assessment**: GPT-5-Mini intelligently evaluates action risks and provides confidence scores\n",
        "2. **Intelligent Approval Gates**: Dynamic decision making based on AI analysis rather than static rules\n",
        "3. **Smart Acceptance Criteria**: Natural language understanding for complex business rule validation\n",
        "4. **AI-Enhanced Human Prompts**: Context-aware approval requests generated by AI\n",
        "5. **Workflow Analytics**: AI-driven insights and recommendations for process improvement\n",
        "\n",
        "### Key Benefits of AI Integration:\n",
        "\n",
        "- **Adaptive Intelligence**: System learns and adapts to new patterns and contexts\n",
        "- **Natural Language Processing**: Understands complex business rules in plain language\n",
        "- **Context Awareness**: Considers situational factors beyond simple pattern matching\n",
        "- **Explainable Decisions**: Provides reasoning and justification for each decision\n",
        "- **Continuous Learning**: Can improve over time with feedback and new data\n",
        "\n",
        "### Implementation Considerations:\n",
        "\n",
        "- **Model Selection**: GPT-5-Mini provides excellent balance of capability and efficiency\n",
        "- **Confidence Calibration**: Regular validation of AI confidence scores against actual outcomes\n",
        "- **Fallback Mechanisms**: Robust error handling when AI services are unavailable\n",
        "- **Human Oversight**: Maintaining appropriate human involvement in critical decisions\n",
        "- **Audit Trail**: Complete logging of AI reasoning for compliance and debugging\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "- **Model Fine-tuning**: Train models on your specific domain and decision patterns\n",
        "- **Integration Testing**: Validate AI decisions against historical data\n",
        "- **Performance Monitoring**: Track AI accuracy and adjust thresholds accordingly\n",
        "- **User Feedback Loop**: Incorporate human feedback to improve AI performance\n",
        "\n",
        "---\n",
        "\n",
        "**üöÄ Ready to implement AI-powered approval workflows in your organization!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}