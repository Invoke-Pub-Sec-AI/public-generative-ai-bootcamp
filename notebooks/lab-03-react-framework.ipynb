{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e236538023194780b7348190fdddeb44",
      "metadata": {},
      "source": [
        "# Lab 03: The ReAct Framework (Reason + Act)\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand the ReAct framework for combining reasoning and acting\n",
        "- Implement a loop where an LLM generates both thoughts and actions\n",
        "- Use tools to gather information and update the LLM's context\n",
        "- Build a simple agent that can solve a multi-step problem\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b3d8dc9bfca42878b669a0e0fcaa190",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Dict, Any, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126d2d6a963443e3a0c6bf434348429c",
      "metadata": {},
      "source": [
        "## Part 1: The ReAct Prompting Style\n",
        "\n",
        "The ReAct framework instructs an LLM to follow a specific format:\n",
        "\n",
        "1.  **Thought**: The LLM first thinks about what it needs to do to solve the problem.\n",
        "2.  **Action**: Based on the thought, the LLM chooses an action to take, usually a tool to use.\n",
        "3.  **Observation**: The result from the action is fed back into the prompt.\n",
        "4.  **Repeat**: The LLM repeats this process until it has enough information to answer the final question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a3e1c539f9c478392c9088b01c74fda",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Mock Tools ---\n",
        "def search(query: str) -> str:\n",
        "    \"\"\"A mock search engine.\"\"\"\n",
        "    if 'capital of france' in query.lower():\n",
        "        return 'The capital of France is Paris.'\n",
        "    if 'population of paris' in query.lower():\n",
        "        return 'The population of Paris is approximately 2.1 million.'\n",
        "    return 'Information not found.'\n",
        "\n",
        "available_tools = {\n",
        "    'search': search\n",
        "}\n",
        "\n",
        "# --- Mock LLM for ReAct ---\n",
        "class ReActLLM:\n",
        "    def __init__(self):\n",
        "        self.context_history = []\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        self.context_history.append(prompt)\n",
        "        full_context = ''.join(self.context_history)\n",
        "\n",
        "        if 'what is the capital of france' in full_context.lower() and 'population' not in full_context.lower():\n",
        "            return (\n",
        "                'Thought: I need to find the capital of France. I can use the search tool for this.\n",
        "'\n",
        "                'Action: search[capital of France]'\n",
        "            )\n",
        "        elif 'capital of france is paris' in full_context.lower():\n",
        "            return (\n",
        "                'Thought: Now I know the capital is Paris. I need to find its population. I will use the search tool again.\n",
        "'\n",
        "                'Action: search[population of Paris]'\n",
        "            )\n",
        "        elif 'population of paris is approximately 2.1 million' in full_context.lower():\n",
        "            return (\n",
        "                'Thought: I have all the information I need. The capital is Paris and its population is 2.1 million. I can now provide the final answer.\n",
        "'\n",
        "                'Final Answer: The capital of France is Paris, which has a population of about 2.1 million.'\n",
        "            )\n",
        "        return 'Thought: I am unsure how to proceed. Action: finish'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8004395f761c4124865952a7302e8521",
      "metadata": {},
      "source": [
        "## Part 2: The ReAct Agent Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8def48918654283a74c1af9c402fdc8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_action(response: str) -> Tuple[str, str]:\n",
        "    \"\"\"Parses the action and its argument from the LLM's response.\"\"\"\n",
        "    match = re.search(r'Action: (\\w+)\\[(.*)\\]', response)\n",
        "    if match:\n",
        "        return match.group(1), match.group(2) # action_name, action_input\n",
        "    return None, None\n",
        "\n",
        "def run_react_agent(question: str, llm: ReActLLM, tools: Dict, max_steps: int = 5):\n",
        "    prompt = f'Question: {question}\\n'\n",
        "    \n",
        "    for i in range(max_steps):\n",
        "        print(f'--- Step {i+1} ---')\n",
        "        response = llm.generate(prompt)\n",
        "        print(f'LLM Output:\n",
        "{response}')\n",
        "        \n",
        "        if 'Final Answer:' in response:\n",
        "            final_answer = response.split('Final Answer:')[-1].strip()\n",
        "            print(f'\\nFinal Answer Found: {final_answer}')\n",
        "            return\n",
        "            \n",
        "        action_name, action_input = parse_action(response)\n",
        "        if action_name and action_name in tools:\n",
        "            tool_function = tools[action_name]\n",
        "            observation = tool_function(action_input)\n",
        "            print(f'Observation: {observation}')\n",
        "            prompt = f'\\nObservation: {observation}\\n' # Next prompt is just the new info\n",
        "        else:\n",
        "            print('No valid action found or action finished.')\n",
        "            break\n",
        "\n",
        "# --- Run the Agent ---\n",
        "question = 'What is the capital of France and what is its population?'\n",
        "react_llm = ReActLLM()\n",
        "\n",
        "run_react_agent(question, react_llm, available_tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc79c98aca8d4de0890f0019be65138d",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "1. **Add a New Tool**: Create a new tool called `get_current_date()` that returns today's date as a string. Add it to the `available_tools` dictionary. Then, modify the `ReActLLM` to handle a question like, \"What is the date today?\".\n",
        "2. **Handle Tool Errors**: Modify the `run_react_agent` loop. What if a tool fails and raises an exception? The loop should catch the error and feed an observation back to the LLM like `Observation: Error executing tool: [error message]`.\n",
        "3. **Improve the Prompt**: The initial prompt is very simple. A better prompt would include a description of the available tools and a few examples of the Thought-Action-Observation format (a few-shot prompt). Write a more detailed initial prompt for the agent.\n",
        "\n",
        "## Summary\n",
        "\n",
        "You learned:\n",
        "- The **ReAct framework**, which synergistically combines reasoning (Thought) and tool use (Action) in an iterative loop.\n",
        "- How to create an **agent loop** that parses LLM output, executes tools, and feeds the results back to the model.\n",
        "- That by breaking down a complex question into smaller, tool-assisted steps, an LLM can solve problems it couldn't answer in a single pass."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}