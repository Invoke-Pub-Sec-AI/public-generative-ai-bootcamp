{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "ab990786",
      "metadata": {},
      "source": [
        "**Task 1 â€” Send a prompt to AskSage**  \n",
        "Load your AskSage secrets from Colab's **secrets** (or environment variables as a fallback), initialize the client, and send your first prompt.\n",
        "\n",
        "**Task 2 â€” Log usage to JSON**  \n",
        "Enhance the code to log the *input*, *output*, and *token counts* (prompt, response, and total) to a local JSONL log file.\n",
        "\n",
        "> This notebook is designed for Google Colab. It will look for secrets via `google.colab.userdata` keys:\n",
        "> - `ASKSAGE_API_KEY`\n",
        "> - `ASKSAGE_BASE_URL` (optional)\n",
        "> - `ASKSAGE_EMAIL`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d046bbfd",
      "metadata": {},
      "source": [
        "\n",
        "## âœ… Task 1 â€” Send a prompt to AskSage\n",
        "\n",
        "1. Initialize the AskSage client using the secrets loaded.  \n",
        "2. Send a simple prompt to the model (default here: `gpt-5-mini`).  \n",
        "3. Print the response text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10745ab5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "!pip install asksageclient pip_system_certs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import tiktoken\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# Import our AskSage client\n",
        "from asksageclient import AskSageClient\n",
        "\n",
        "# Get API credentials from Google Colab secrets\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('ASKSAGE_API_KEY')\n",
        "email = userdata.get('ASKSAGE_EMAIL')\n",
        "\n",
        "# Initialize client and tokenizer\n",
        "client = AskSageClient(api_key=api_key, email=email)\n",
        "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "print(\"AskSage client initialized successfully\")\n",
        "print(\"Ready to showcase AI capabilities...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75a830f7",
      "metadata": {},
      "source": [
        "\n",
        "## ðŸ§¾ Task 2 â€” Log input/output + token counts to JSONL\n",
        "\n",
        "Now extend your code to:\n",
        "- Count prompt tokens and response tokens\n",
        "- Compute total tokens\n",
        "- Log a JSON record to `asksage_logs.jsonl` with:\n",
        "  - input, output prompt, input and output tokens\n",
        "  - model and timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9729bbf6",
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title ðŸ“ Token counting + JSON logger utilities\n",
        "import json\n",
        "from datetime import datetime\n",
        "import tiktoken\n",
        "from pathlib import Path\n",
        "\n",
        "# TODO: Pick the right encoding for your backend.\n",
        "# For GPT-5-mini/5 encodings; o200k_base works well for modern OpenAI-style models.\n",
        "_DEFAULT_ENCODING = \"o200k_base\"\n",
        "\n",
        "def count_tokens(text: str, encoding_name: str = _DEFAULT_ENCODING) -> int:\n",
        "    \"\"\"TODO: implement token counting.\"\"\"\n",
        "\n",
        "# TODO: Change the log filename/location if your environment needs it.\n",
        "LOG_PATH = Path(\"lab_3_asksage_logs.jsonl\")  # JSON Lines file\n",
        "\n",
        "def log_interaction_jsonl(payload: dict, path: Path = LOG_PATH) -> None:\n",
        "    \"\"\"TODO:Save input, output prompt and input, output token amounts.\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "047436a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model suggestion: change if your org defaults differ\n",
        "MODEL = \"gpt-5-mini\"  # @param [\"gpt-5-mini\", \"gpt-5\"] {allow-input: true}\n",
        "SYSTEM_PROMPT = \"You are a concise assistant.\"  # @param {type:\"string\"}\n",
        "USER_PROMPT = \"Say hello and list three cool uses of AskSage in a bootcamp.\"  # @param {type:\"string\"}\n",
        "\n",
        "# TODO: Build the full prompt string for input-token counting.\n",
        "full_prompt = f\"System Prompt: {SYSTEM_PROMPT}\\nMessage: {USER_PROMPT}\"\n",
        "\n",
        "# TODO: Count tokens on INPUT first, then OUTPUT.\n",
        "prompt_tokens = count_tokens(full_prompt)\n",
        "response_tokens = count_tokens(response_text)\n",
        "total_tokens = prompt_tokens + response_tokens\n",
        "\n",
        "# TODO: Create the record you want to persist.\n",
        "record = {\n",
        "    \"model\": MODEL,\n",
        "    \"system_prompt\": SYSTEM_PROMPT,\n",
        "    \"user_prompt\": USER_PROMPT,\n",
        "    \"response_text\": response_text,\n",
        "    \"prompt_tokens\": prompt_tokens,\n",
        "    \"response_tokens\": response_tokens,\n",
        "    \"total_tokens\": total_tokens,\n",
        "}\n",
        "\n",
        "# TODO: Persist to JSONL (or swap for DB/CSV/service).\n",
        "log_interaction_jsonl(record)\n",
        "print(\"âœ“ Logged one interaction to\", str(LOG_PATH))\n",
        "print(json.dumps(record, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c6f8119",
      "metadata": {},
      "source": [
        "\n",
        "### ðŸ”Ž (Optional) Inspect your JSONL logs\n",
        "This will read the JSON Lines file and show the latest few rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed9caa7",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "if LOG_PATH.exists():\n",
        "    df = pd.read_json(LOG_PATH, lines=True)\n",
        "    display(df.tail(10))\n",
        "else:\n",
        "    print(\"No log file yet. Run Task 2 first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}