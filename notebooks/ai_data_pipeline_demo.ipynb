{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Data Pipeline Demo\n",
        "\n",
        "## Learning Objectives\n",
        "- See AI extract structured data from messy documents\n",
        "- Watch pipeline break and self-heal\n",
        "- Understand production data processing patterns\n",
        "- Learn error recovery and validation strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "!pip install asksageclient pip_system_certs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import tiktoken\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# Import our AskSage client\n",
        "from asksageclient import AskSageClient\n",
        "\n",
        "# Get API credentials from Google Colab secrets\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('ASKSAGE_API_KEY')\n",
        "email = userdata.get('ASKSAGE_EMAIL')\n",
        "\n",
        "# Initialize client and tokenizer\n",
        "client = AskSageClient(api_key=api_key, email=email)\n",
        "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "print(\"AskSage client initialized successfully\")\n",
        "print(\"Ready to showcase AI capabilities...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Messy input documents\n",
        "messy_docs = [\n",
        "    \"Invoice #INV-2024-001 from ACME Corp dated March 15, 2024. Total: $12,450.00. Items: Office supplies (qty: 50, $8,200), Software licenses (qty: 3, $4,250). Payment due: April 15, 2024.\",\n",
        "    \"Receipt - TechStore Inc. Date: 03/20/2024 Amount $3,299.99 Description: Laptop computer model XPS-15 Serial: ABC123XYZ Customer: John Smith Phone: (555) 123-4567\",\n",
        "    \"Purchase Order PO-2024-0089 | Vendor: Office Depot | Date: March 22nd 2024 | Line items: Printer paper 10 reams @ $45 each = $450, Ink cartridges 5 units @ $89 each = $445 | Subtotal $895 | Tax $71.60 | Total $966.60\"\n",
        "]\n",
        "\n",
        "print(f\"Processing {len(messy_docs)} messy documents...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AI extraction with structured output\n",
        "def extract_document_data(doc_text):\n",
        "    prompt = f\"\"\"\n",
        "    Extract structured data from this document:\n",
        "    \n",
        "    {doc_text}\n",
        "    \n",
        "    Return JSON:\n",
        "    {{\n",
        "      \"document_type\": \"invoice|receipt|purchase_order\",\n",
        "      \"document_id\": \"string\",\n",
        "      \"date\": \"YYYY-MM-DD\",\n",
        "      \"vendor\": \"string\",\n",
        "      \"total_amount\": \"number\",\n",
        "      \"line_items\": [\n",
        "        {{\n",
        "          \"description\": \"string\",\n",
        "          \"quantity\": \"number\",\n",
        "          \"unit_price\": \"number\",\n",
        "          \"total\": \"number\"\n",
        "        }}\n",
        "      ],\n",
        "      \"customer_info\": {{\n",
        "        \"name\": \"string or null\",\n",
        "        \"contact\": \"string or null\"\n",
        "      }}\n",
        "    }}\n",
        "    \"\"\"\n",
        "        \n",
        "    # Test GPT-5-mini\n",
        "    print(\"=== TESTING GPT-5-mini ===\")\n",
        "\n",
        "    response = client.query(\n",
        "        message=prompt,\n",
        "        system_prompt=\"You are an expert data engineer and pipeline architect. Design robust, scalable data processing systems.\",\n",
        "        temperature=0.2,\n",
        "        model=\"gpt-5-mini\",\n",
        "        live=0,\n",
        "        limit_references=0,\n",
        "    )\n",
        "\n",
        "    \n",
        "    return response.get(\"message\").strip()\n",
        "\n",
        "# Process documents\n",
        "extracted_data = []\n",
        "for i, doc in enumerate(messy_docs):\n",
        "    print(f\"\\nProcessing document {i+1}...\")\n",
        "    result = extract_document_data(doc)\n",
        "    print(result[:200] + \"...\")\n",
        "    extracted_data.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pipeline validation and error recovery\n",
        "def validate_and_fix_json(json_text):\n",
        "    try:\n",
        "        # Try to parse JSON\n",
        "        data = json.loads(json_text)\n",
        "        return data, None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON parsing failed: {e}\")\n",
        "        \n",
        "        # AI fixes the JSON\n",
        "        fix_prompt = f\"\"\"\n",
        "        Fix this malformed JSON:\n",
        "        \n",
        "        {json_text}\n",
        "        \n",
        "        Return only valid JSON with proper structure.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Test GPT-5-mini\n",
        "        print(\"=== TESTING GPT-5-mini ===\")\n",
        "\n",
        "        response = client.query(\n",
        "            message=fix_prompt,\n",
        "            system_prompt=\"You are an expert data engineer and pipeline architect. Design robust, scalable data processing systems.\",\n",
        "            temperature=0.2,\n",
        "            model=\"gpt-5-mini\",\n",
        "            live=0,\n",
        "            limit_references=0,\n",
        "        )\n",
        "\n",
        "                \n",
        "        fixed_json = response.get(\"message\").strip()\n",
        "\n",
        "        try:\n",
        "            data = json.loads(fixed_json)\n",
        "            return data, \"fixed\"\n",
        "        except:\n",
        "            return None, \"failed\"\n",
        "\n",
        "# Validate all extracted data\n",
        "validated_data = []\n",
        "for i, raw_json in enumerate(extracted_data):\n",
        "    print(f\"\\nValidating document {i+1}...\")\n",
        "    data, status = validate_and_fix_json(raw_json)\n",
        "    \n",
        "    if data:\n",
        "        validated_data.append(data)\n",
        "        print(f\"‚úÖ Success ({status or 'valid'})\")\n",
        "    else:\n",
        "        print(\"‚ùå Failed validation\")\n",
        "\n",
        "print(f\"\\nPipeline processed {len(validated_data)}/{len(messy_docs)} documents successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Business intelligence generation\n",
        "if validated_data:\n",
        "    analysis_prompt = f\"\"\"\n",
        "    Analyze this processed business data and generate insights:\n",
        "    \n",
        "    {json.dumps(validated_data, indent=2)}\n",
        "    \n",
        "    Provide business intelligence summary:\n",
        "    {{\n",
        "      \"total_revenue\": \"number\",\n",
        "      \"document_breakdown\": {{}},\n",
        "      \"top_vendors\": [],\n",
        "      \"spending_patterns\": [],\n",
        "      \"key_insights\": [],\n",
        "      \"recommendations\": []\n",
        "    }}\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"\\n=== GENERATING BUSINESS INTELLIGENCE ===\")\n",
        "    \n",
        "# Test GPT-5-mini\n",
        "print(\"=== TESTING GPT-5-mini ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "response = client.query(\n",
        "    message=prompt,\n",
        "    system_prompt=\"You are an expert data engineer and pipeline architect. Design robust, scalable data processing systems.\",\n",
        "    temperature=0.2,\n",
        "    model=\"gpt-5-mini\",\n",
        "    live=0,\n",
        "    limit_references=0,\n",
        ")\n",
        "\n",
        "    \n",
        "intelligence = response.get(\"message\").strip()\n",
        "print(intelligence)\n",
        "\n",
        "print(\"\\n‚úÖ AI Data Pipeline completed successfully!\")\n",
        "print(\"üìä Messy documents ‚Üí Structured data ‚Üí Business insights\")\n",
        "print(\"‚ùå Pipeline failed - no valid data extracted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "**Pipeline Resilience**\n",
        "- Automatic error detection and recovery\n",
        "- JSON validation and repair\n",
        "- Graceful handling of malformed data\n",
        "\n",
        "**Production Patterns**\n",
        "- Structured output schemas\n",
        "- Multi-stage processing\n",
        "- Quality gates and validation\n",
        "\n",
        "**Business Value**\n",
        "- Automated document processing\n",
        "- Real-time business intelligence\n",
        "- Scalable data extraction"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
