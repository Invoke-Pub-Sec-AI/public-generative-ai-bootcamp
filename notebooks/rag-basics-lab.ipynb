{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Basics & First Retrieval - Hands-On Lab\n",
        "\n",
        "**Hands-on**: build a small index on provided docs; answer with top-k cites\n",
        "\n",
        "**Deliverable**: answer text with cited chunks\n",
        "\n",
        "## Lab Objectives\n",
        "By the end of this lab, you will:\n",
        "- Build a searchable index from provided documents\n",
        "- Implement retrieval to find top-k relevant chunks\n",
        "- Generate answers that include proper source citations\n",
        "- Validate that your citations are accurate and traceable\n",
        "\n",
        "## Setup Instructions\n",
        "1. Run the installation cell below to install required packages\n",
        "2. Set your OpenAI API key in the environment\n",
        "3. Work through each section step by step\n",
        "4. Test your implementation with the provided queries\n",
        "\n",
        "## Provided Documents\n",
        "You will work with a small knowledge base about sustainable energy topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install required packages for Google Colab compatibility\n",
        "!pip install langchain langchain-openai langchain-community faiss-cpu tiktoken python-dotenv\n",
        "\n",
        "# TODO: Import all necessary modules for RAG implementation\n",
        "# You will need:\n",
        "# - Document handling: Document from langchain.schema\n",
        "# - Text processing: RecursiveCharacterTextSplitter from langchain.text_splitter\n",
        "# - Embeddings: OpenAIEmbeddings from langchain_openai\n",
        "# - Vector store: FAISS from langchain.vectorstores\n",
        "# - Language model: ChatOpenAI from langchain_openai\n",
        "# - Chain: RetrievalQA from langchain.chains\n",
        "# - Prompts: PromptTemplate from langchain.prompts\n",
        "# - Standard libraries: os, json, sys\n",
        "\n",
        "print(\"✅ Installation complete - now add your imports!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Set your OpenAI API key\n",
        "# Option 1: Set directly (not recommended for production)\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
        "\n",
        "# Option 2: Load from environment file (recommended)\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "\n",
        "# TODO: Add a check to verify the API key is set\n",
        "# Print a success message if found, warning if not found"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Document Loading and Preparation\n",
        "\n",
        "Load the provided documents about sustainable energy and convert them to LangChain Document objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PROVIDED: Document data about sustainable energy\n",
        "energy_documents = [\n",
        "    {\n",
        "        \"content\": \"Solar power harnesses energy from the sun using photovoltaic cells or solar thermal collectors. Modern solar panels can convert about 15-22% of sunlight into electricity. Solar farms can generate utility-scale power, while rooftop installations serve individual buildings. The technology has become increasingly cost-effective, with prices dropping over 80% in the last decade. Solar power is intermittent, requiring energy storage or grid integration for consistent power supply.\",\n",
        "        \"metadata\": {\"source\": \"solar_energy_overview.pdf\", \"topic\": \"Solar Power\", \"date\": \"2024\"}\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"Wind energy captures kinetic energy from moving air using wind turbines. Modern turbines can reach heights of 150+ meters with rotor diameters exceeding 100 meters. Wind farms are typically located in areas with consistent wind patterns - either onshore in plains and hills, or offshore where winds are stronger and more consistent. Wind power has low operating costs once installed but faces challenges with intermittency and visual/noise impacts on communities.\",\n",
        "        \"metadata\": {\"source\": \"wind_power_guide.pdf\", \"topic\": \"Wind Energy\", \"date\": \"2024\"}\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"Energy storage systems are crucial for renewable energy integration. Battery technologies like lithium-ion provide short-term storage for homes and grids. Pumped hydro storage uses excess energy to pump water uphill, then generates power as water flows down. Other solutions include compressed air storage, flywheels, and emerging technologies like hydrogen fuel cells. Storage helps balance supply and demand when renewable sources are intermittent.\",\n",
        "        \"metadata\": {\"source\": \"energy_storage.pdf\", \"topic\": \"Energy Storage\", \"date\": \"2024\"}\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"Smart grids use digital technology to manage electricity flow efficiently. They enable two-way communication between utilities and consumers, allowing for real-time monitoring and optimization. Smart grids can automatically reroute power during outages, integrate renewable sources more effectively, and enable demand response programs. Advanced metering infrastructure provides detailed energy usage data to both utilities and consumers for better energy management.\",\n",
        "        \"metadata\": {\"source\": \"smart_grid_tech.pdf\", \"topic\": \"Smart Grids\", \"date\": \"2024\"}\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"Electric vehicles (EVs) are becoming a key part of sustainable transportation. Modern EVs can travel 200-400 miles per charge, with charging infrastructure expanding rapidly. EVs can serve as mobile energy storage, potentially feeding power back to the grid during peak demand. The transition to EVs reduces greenhouse gas emissions, especially when powered by renewable electricity. Challenges include charging time, battery costs, and the need for widespread charging infrastructure.\",\n",
        "        \"metadata\": {\"source\": \"electric_vehicles.pdf\", \"topic\": \"Electric Vehicles\", \"date\": \"2024\"}\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"Geothermal energy taps into Earth's internal heat for power generation and heating. Geothermal power plants can provide consistent baseload power, unlike intermittent solar and wind. Enhanced geothermal systems (EGS) can expand geothermal potential to areas without natural hot springs. Geothermal has a small environmental footprint and can operate 24/7. However, it requires specific geological conditions and has high upfront costs for drilling and plant construction.\",\n",
        "        \"metadata\": {\"source\": \"geothermal_energy.pdf\", \"topic\": \"Geothermal\", \"date\": \"2024\"}\n",
        "    }\n",
        "]\n",
        "\n",
        "# TODO: Convert the energy_documents list to LangChain Document objects\n",
        "# Use the Document class with page_content and metadata parameters\n",
        "# Store the result in a variable called 'documents'\n",
        "\n",
        "# TODO: Print summary statistics about your loaded documents:\n",
        "# - Total number of documents\n",
        "# - Total character count across all documents\n",
        "# - List of document sources and topics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Text Chunking Strategy\n",
        "\n",
        "Implement intelligent text chunking to prepare documents for optimal retrieval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Initialize a RecursiveCharacterTextSplitter with these parameters:\n",
        "# - chunk_size: 250 (good size for detailed retrieval)\n",
        "# - chunk_overlap: 40 (preserve context across boundaries)\n",
        "# - length_function: len\n",
        "# - separators: [\". \", \"\\n\", \" \", \"\"] (try sentence boundaries first)\n",
        "\n",
        "# TODO: Use the text splitter to split your documents into chunks\n",
        "# Store the result in a variable called 'chunks'\n",
        "\n",
        "# TODO: Print analysis of your chunking:\n",
        "# - Number of original documents vs. number of chunks\n",
        "# - Average chunk size in characters\n",
        "# - Show the first 2 chunks as examples with their metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Create Searchable Index\n",
        "\n",
        "Build a vector index using embeddings that will enable semantic search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Initialize OpenAI embeddings\n",
        "# Use the text-embedding-ada-002 model\n",
        "# Set chunk_size=1000 for batch processing\n",
        "\n",
        "# TODO: Create a FAISS vector store from your chunks and embeddings\n",
        "# Use FAISS.from_documents() method\n",
        "# Store the result in a variable called 'vectorstore'\n",
        "# Add error handling in case the API call fails\n",
        "\n",
        "# TODO: Print confirmation of successful index creation:\n",
        "# - Number of vectors in the index\n",
        "# - Embedding dimension size\n",
        "# - Success message"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4: Implement Retrieval with Top-K Results\n",
        "\n",
        "Test your index by retrieving the most relevant chunks for different queries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PROVIDED: Test queries for your retrieval system\n",
        "test_queries = [\n",
        "    \"How efficient are solar panels at converting sunlight?\",\n",
        "    \"What are the challenges with wind energy?\",\n",
        "    \"How do smart grids help manage electricity?\",\n",
        "    \"What energy storage options are available?\",\n",
        "    \"What makes electric vehicles sustainable?\"\n",
        "]\n",
        "\n",
        "# TODO: For each query in test_queries:\n",
        "# 1. Use vectorstore.similarity_search_with_score() to get top 2 results\n",
        "# 2. Print the query\n",
        "# 3. For each result, print:\n",
        "#    - Similarity score (lower is better)\n",
        "#    - Source document name\n",
        "#    - Topic from metadata  \n",
        "#    - First 60 characters of content\n",
        "# 4. Add a separator line between queries\n",
        "\n",
        "# HINT: The similarity_search_with_score returns tuples of (Document, score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 5: Build RAG Chain with Citation Support\n",
        "\n",
        "Create a complete RAG system that generates answers with proper source citations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create a custom prompt template for RAG with citations\n",
        "# Your template should:\n",
        "# - Accept {context} and {question} as input variables\n",
        "# - Instruct the model to answer based only on provided context\n",
        "# - Require citations by mentioning source document names\n",
        "# - Tell model to say if information is insufficient\n",
        "# - Emphasize not making up information\n",
        "# Use PromptTemplate class with template and input_variables parameters\n",
        "\n",
        "# Example template structure (customize as needed):\n",
        "# \"\"\"\n",
        "# You are an expert on sustainable energy helping users with questions.\n",
        "# \n",
        "# Relevant context:\n",
        "# {context}\n",
        "# \n",
        "# Question: {question}\n",
        "# \n",
        "# Instructions:\n",
        "# [Add your instructions here]\n",
        "# \n",
        "# Answer:\n",
        "# \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Initialize the language model and create RAG chain\n",
        "# 1. Create ChatOpenAI with:\n",
        "#    - temperature=0 (for consistency)\n",
        "#    - model=\"gpt-3.5-turbo\"\n",
        "#    - max_tokens=400\n",
        "# \n",
        "# 2. Create a retriever from your vectorstore:\n",
        "#    - Use vectorstore.as_retriever()\n",
        "#    - Set search_type=\"similarity\"\n",
        "#    - Set search_kwargs={\"k\": 3} for top 3 chunks\n",
        "#\n",
        "# 3. Create RetrievalQA chain:\n",
        "#    - Use RetrievalQA.from_chain_type()\n",
        "#    - Set chain_type=\"stuff\"\n",
        "#    - Use your retriever and LLM\n",
        "#    - Set return_source_documents=True\n",
        "#    - Pass your custom prompt in chain_type_kwargs\n",
        "# \n",
        "# Add error handling for API issues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 6: Test Complete RAG Pipeline\n",
        "\n",
        "Generate answers with citations and validate the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PROVIDED: Final test questions\n",
        "final_questions = [\n",
        "    \"What are the main advantages and challenges of solar power?\",\n",
        "    \"How do energy storage systems support renewable energy?\",\n",
        "    \"What role do electric vehicles play in sustainable transportation?\"\n",
        "]\n",
        "\n",
        "# TODO: For each question in final_questions:\n",
        "# 1. Use your qa_chain to get an answer: qa_chain({\"query\": question})\n",
        "# 2. Display the question clearly\n",
        "# 3. Display the generated answer\n",
        "# 4. List all source documents that were consulted:\n",
        "#    - Show source filename\n",
        "#    - Show topic from metadata\n",
        "#    - Show first 80 characters of each source chunk\n",
        "# 5. Add clear separators between questions\n",
        "# 6. Handle any errors gracefully\n",
        "\n",
        "# DELIVERABLE: Your output should show answer text with cited chunks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 7: Validate Citations\n",
        "\n",
        "Verify that your system is providing accurate citations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create a function to validate citations\n",
        "# The function should:\n",
        "# 1. Take an answer and source documents as parameters\n",
        "# 2. Check if document names mentioned in the answer actually exist in sources\n",
        "# 3. Look for phrases like \"according to X.pdf\" or \"from X.pdf\"\n",
        "# 4. Return a report of citation accuracy\n",
        "\n",
        "# TODO: Test your citation validation with at least one example\n",
        "# Use a question and manually check if citations match sources\n",
        "\n",
        "# BONUS: Implement additional validation:\n",
        "# - Check if cited content actually appears in the mentioned source\n",
        "# - Flag potential hallucinations where facts don't match sources"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Completion Checklist\n",
        "\n",
        "Before submitting, verify you have completed:\n",
        "\n",
        "### ✅ Required Deliverables\n",
        "- [ ] Built a searchable index from the provided sustainable energy documents\n",
        "- [ ] Implemented top-k retrieval (tested with k=2 and k=3)\n",
        "- [ ] Generated answers that include source citations\n",
        "- [ ] Validated that citations reference actual source documents\n",
        "\n",
        "### ✅ Technical Implementation\n",
        "- [ ] Successfully loaded and chunked documents\n",
        "- [ ] Created embeddings and vector store index\n",
        "- [ ] Implemented similarity search with scores\n",
        "- [ ] Built complete RAG chain with custom prompt\n",
        "- [ ] Generated responses to all test questions\n",
        "\n",
        "### ✅ Quality Checks\n",
        "- [ ] Answers are grounded in provided context\n",
        "- [ ] Citations reference actual source document names\n",
        "- [ ] Retrieved chunks are relevant to queries\n",
        "- [ ] No obvious hallucinations or made-up facts\n",
        "- [ ] Code runs without errors\n",
        "\n",
        "## Reflection Questions\n",
        "\n",
        "1. **Retrieval Quality**: Did your system retrieve relevant chunks for each query? What could improve retrieval accuracy?\n",
        "\n",
        "2. **Citation Accuracy**: Are the citations in your answers accurate? Do they reference the correct source documents?\n",
        "\n",
        "3. **Answer Quality**: Are the generated answers helpful and grounded in the provided context?\n",
        "\n",
        "4. **Chunk Strategy**: How did your chunking approach affect retrieval quality? Would different chunk sizes help?\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "After completing this lab, you're ready to:\n",
        "- Experiment with different chunking strategies\n",
        "- Try hybrid search combining semantic and keyword search\n",
        "- Implement more sophisticated citation validation\n",
        "- Add metadata filtering to improve precision\n",
        "- Scale to larger document collections"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}