{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LlamaIndex & AutoGen Quickstarts - Lab\n",
        "\n",
        "**Hands-on**: \"Incident update\" assistant over sample logs; note quality before/after rerank\n",
        "\n",
        "**Deliverable**: short eval note\n",
        "\n",
        "## Lab Objectives\n",
        "- Build an incident update assistant using LlamaIndex\n",
        "- Process sample system logs for incident analysis\n",
        "- Compare retrieval quality before and after reranking\n",
        "- Create evaluation notes on system performance\n",
        "- Generate incident update reports\n",
        "\n",
        "## Instructions\n",
        "Follow the comments in each cell to implement your incident update assistant. Focus on:\n",
        "1. Setting up the LlamaIndex components\n",
        "2. Processing log data effectively\n",
        "3. Implementing reranking for better results\n",
        "4. Evaluating quality differences\n",
        "5. Creating structured incident updates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Install required packages for Google Colab\n",
        "# Install llama-index, llama-index-embeddings-openai, llama-index-llms-openai\n",
        "# Install llama-index-postprocessor-cohere-rerank for reranking functionality\n",
        "# Install any other dependencies you need for log processing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Import necessary libraries\n",
        "# Import LlamaIndex core components: VectorStoreIndex, ServiceContext, Settings\n",
        "# Import OpenAI embeddings and LLM classes\n",
        "# Import CohereRerank for reranking functionality\n",
        "# Import Document class for creating log documents\n",
        "# Import any other utilities you need\n",
        "\n",
        "# TODO: Set up API keys\n",
        "# Set OPENAI_API_KEY environment variable\n",
        "# Set COHERE_API_KEY environment variable (for reranking)\n",
        "# You may use os.environ or getpass for secure key input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create Sample Incident Log Data\n",
        "\n",
        "Create a realistic dataset of system logs representing different incidents for your assistant to analyze."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create sample incident logs\n",
        "# Create at least 10-15 log entries representing 2-3 different incidents\n",
        "# Include various log levels (ERROR, WARN, INFO)\n",
        "# Include different services (api-gateway, database, user-service, etc.)\n",
        "# Include timestamps and incident IDs\n",
        "# Make logs realistic - show cause and effect relationships\n",
        "\n",
        "# Example format for each log:\n",
        "# {\n",
        "#     \"timestamp\": \"2024-01-15 14:23:15\",\n",
        "#     \"level\": \"ERROR\",\n",
        "#     \"service\": \"api-gateway\", \n",
        "#     \"message\": \"Connection timeout to user-service\",\n",
        "#     \"incident_id\": \"INC-001\"\n",
        "# }\n",
        "\n",
        "# TODO: Convert logs to LlamaIndex Document objects\n",
        "# Format each log as a readable string\n",
        "# Include metadata (timestamp, level, service, incident_id)\n",
        "# Create Document objects with text content and metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Set Up LlamaIndex Components\n",
        "\n",
        "Configure the basic LlamaIndex components for document processing and retrieval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Configure LlamaIndex Settings\n",
        "# Set up OpenAI LLM with appropriate temperature (0 for consistent results)\n",
        "# Configure OpenAI embeddings for vector representations\n",
        "# Use Settings.llm and Settings.embed_model to configure globally"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create Vector Store Index\n",
        "# Use VectorStoreIndex.from_documents() to create index from your log documents\n",
        "# This will automatically embed all documents for semantic search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Build Basic Query Engine (Without Reranking)\n",
        "\n",
        "Create a basic query engine to establish baseline performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create basic query engine\n",
        "# Use index.as_query_engine() to create a simple query engine\n",
        "# Set similarity_top_k to retrieve 5-7 relevant documents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Test basic retrieval with sample queries\n",
        "# Create 3-4 test queries about your incidents:\n",
        "# - \"What caused incident INC-001?\"\n",
        "# - \"Which services were affected by database issues?\"\n",
        "# - \"How was the memory problem resolved?\"\n",
        "# - \"What was the timeline of the SSL certificate incident?\"\n",
        "\n",
        "# For each query:\n",
        "# - Get the response using query_engine.query()\n",
        "# - Print the response text\n",
        "# - Print the source documents used\n",
        "# - Note the quality and relevance of results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Implement Reranking\n",
        "\n",
        "Add Cohere reranking to improve retrieval quality and compare results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Set up Cohere reranker\n",
        "# Create CohereRerank postprocessor with your API key\n",
        "# Set top_n to 3-4 to focus on most relevant results\n",
        "# Handle the case where Cohere API key might not be available"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create reranked query engine\n",
        "# Use index.as_query_engine() with node_postprocessors parameter\n",
        "# Include the CohereRerank postprocessor in the list\n",
        "# Keep similarity_top_k higher (e.g., 7-10) since reranker will filter down"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Compare Quality Before and After Reranking\n",
        "\n",
        "Evaluate the difference in retrieval quality with and without reranking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Compare basic vs reranked results\n",
        "# Use the same test queries from Step 3\n",
        "# For each query:\n",
        "# 1. Get response from basic query engine\n",
        "# 2. Get response from reranked query engine  \n",
        "# 3. Compare:\n",
        "#    - Response quality and accuracy\n",
        "#    - Relevance of source documents\n",
        "#    - Number of source documents used\n",
        "#    - Completeness of information\n",
        "\n",
        "# Create a side-by-side comparison format for easy evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Build Incident Update Assistant\n",
        "\n",
        "Create a specialized assistant for generating incident update reports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Create incident update query engine with custom prompt\n",
        "# Use your reranked query engine as the base\n",
        "# Create a custom system prompt that instructs the LLM to:\n",
        "# - Generate structured incident updates\n",
        "# - Include timeline, root cause, impact, and resolution status\n",
        "# - Use professional incident management language\n",
        "# - Provide actionable next steps when applicable\n",
        "\n",
        "# Example prompt template:\n",
        "# \"You are an incident management assistant. Generate structured incident updates \n",
        "#  based on system logs. Include: Timeline, Root Cause, Impact, Current Status, Next Steps.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TODO: Test incident update generation\n",
        "# Create queries for incident updates:\n",
        "# - \"Generate an incident update for INC-001\"\n",
        "# - \"Provide status report for the database connection issue\"\n",
        "# - \"Create incident summary for all SSL certificate problems\"\n",
        "\n",
        "# Evaluate the quality of generated updates:\n",
        "# - Are they professional and clear?\n",
        "# - Do they include all relevant information?\n",
        "# - Are the timelines accurate?\n",
        "# - Are next steps actionable?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Create Your Evaluation Note\n",
        "\n",
        "Document your findings and create the deliverable evaluation note."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Evaluation Note\n",
        "\n",
        "**Instructions**: Replace this section with your evaluation findings. Address these points:\n",
        "\n",
        "#### Basic vs Reranked Retrieval Quality\n",
        "- TODO: Compare accuracy of retrieved documents\n",
        "- TODO: Note improvements in relevance ranking\n",
        "- TODO: Assess impact on response quality\n",
        "\n",
        "#### Incident Assistant Performance  \n",
        "- TODO: Evaluate quality of generated incident updates\n",
        "- TODO: Note strengths and weaknesses\n",
        "- TODO: Assess professional language and structure\n",
        "\n",
        "#### Technical Observations\n",
        "- TODO: Document any setup challenges\n",
        "- TODO: Note performance differences\n",
        "- TODO: Identify areas for improvement\n",
        "\n",
        "#### Recommendations\n",
        "- TODO: Suggest best practices for production use\n",
        "- TODO: Recommend when to use reranking\n",
        "- TODO: Propose additional features or improvements\n",
        "\n",
        "#### Summary Score\n",
        "- TODO: Rate the overall effectiveness (1-10)\n",
        "- TODO: Provide justification for your score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional Extensions\n",
        "\n",
        "If you have extra time, try these additional challenges:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OPTIONAL: Implement incident severity classification\n",
        "# TODO: Create a function that analyzes logs and assigns severity levels\n",
        "# Consider factors like: error types, affected services, duration\n",
        "# Categories: Critical, High, Medium, Low"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OPTIONAL: Add temporal analysis\n",
        "# TODO: Create queries that analyze incident patterns over time\n",
        "# - \"What incidents occurred in the last hour?\"\n",
        "# - \"Show the timeline of service failures\"\n",
        "# - \"Which services have the most frequent issues?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OPTIONAL: Implement automated root cause analysis\n",
        "# TODO: Create a system that identifies likely root causes\n",
        "# Use patterns in logs to suggest common causes:\n",
        "# - Memory issues → OutOfMemoryError patterns\n",
        "# - Network issues → timeout/connection patterns\n",
        "# - Configuration issues → startup/initialization patterns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lab Summary\n",
        "\n",
        "In this lab, you:\n",
        "\n",
        "1. ✅ **Built an incident assistant** using LlamaIndex components\n",
        "2. ✅ **Processed system logs** into searchable document format\n",
        "3. ✅ **Implemented reranking** with Cohere to improve retrieval quality\n",
        "4. ✅ **Compared quality** before and after reranking implementation\n",
        "5. ✅ **Generated incident updates** with structured, professional formatting\n",
        "6. ✅ **Created evaluation notes** documenting your findings and recommendations\n",
        "\n",
        "### Key Takeaways\n",
        "- Reranking significantly improves retrieval relevance for domain-specific queries\n",
        "- Structured prompting creates more professional, actionable incident reports\n",
        "- LlamaIndex provides flexible components for building specialized AI assistants\n",
        "- Quality evaluation is essential for production AI systems\n",
        "\n",
        "**Remember**: Your evaluation note is the deliverable - make sure it's thorough and insightful!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}