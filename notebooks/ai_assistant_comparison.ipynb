{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Assistant Comparison Demo\n",
        "\n",
        "## Learning Objectives\n",
        "- Compare different AI models on identical tasks\n",
        "- Understand model strengths and weaknesses\n",
        "- Learn to select the right model for specific use cases\n",
        "- Analyze performance, cost, and quality trade-offs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "!pip3 install rich install asksageclient pip_system_certs\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import tiktoken\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# Import our AskSage client\n",
        "from asksageclient import AskSageClient\n",
        "\n",
        "# Get API credentials from Google Colab secrets\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get(\"ASKSAGE_API_KEY\")\n",
        "email = userdata.get(\"ASKSAGE_EMAIL\")\n",
        "\n",
        "# Initialize client and tokenizer\n",
        "client = AskSageClient(api_key=api_key, email=email)\n",
        "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "print(\"AskSage client initialized successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test task for comparison\n",
        "market_analysis_task = \"\"\"\n",
        "Analyze this market scenario and provide strategic recommendations:\n",
        "\n",
        "SCENARIO:\n",
        "TechStartup Inc. is a 2-year-old SaaS company with M ARR, growing 15% monthly.\n",
        "They offer project management software for remote teams.\n",
        "\n",
        "CURRENT SITUATION:\n",
        "- 500 paying customers (average K/year)\n",
        "- 85% customer retention rate\n",
        "- 25-person team, burning K/month\n",
        "- .5M in funding remaining\n",
        "\n",
        "QUESTION: Should they raise Series A, focus on profitability, or pivot to enterprise?\n",
        "Provide analysis with specific recommendations and timeline.\n",
        "\"\"\"\n",
        "\n",
        "system_prompt = \"You are a senior business strategy consultant with 15 years of experience advising SaaS startups. Provide actionable, data-driven recommendations.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test GPT-5-mini\n",
        "print(\"=== TESTING GPT-5-mini ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "response_gpt5_mini = client.query(\n",
        "    message=market_analysis_task,\n",
        "    system_prompt=system_prompt,\n",
        "    temperature=0.3,\n",
        "    model=\"gpt-5-mini\",\n",
        "    live=0,\n",
        "    limit_references=0,\n",
        ")\n",
        "\n",
        "gpt5_mini_time = time.time() - start_time\n",
        "gpt5_mini_response = response_gpt5_mini.get(\"message\").strip()\n",
        "gpt5_mini_tokens = len(tokenizer.encode(gpt5_mini_response))\n",
        "\n",
        "print(f\"Response time: {gpt5_mini_time:.2f}s\")\n",
        "print(f\"Response length: {gpt5_mini_tokens} tokens\")\n",
        "print(f\"Response preview: {gpt5_mini_response[:300]}...\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Claude-3.5-Sonnet\n",
        "print(\"=== TESTING CLAUDE-3.5-SONNET ===\")\n",
        "start_time = time.time()\n",
        "\n",
        "response_claude = client.query(\n",
        "    message=market_analysis_task,\n",
        "    system_prompt=system_prompt,\n",
        "    temperature=0.3,\n",
        "    model=\"claude-3.5-sonnet\",\n",
        "    live=0,\n",
        "    limit_references=0,\n",
        ")\n",
        "\n",
        "claude_time = time.time() - start_time\n",
        "claude_response = response_claude.get(\"message\").strip()\n",
        "claude_tokens = len(tokenizer.encode(claude_response))\n",
        "\n",
        "print(f\"Response time: {claude_time:.2f}s\")\n",
        "print(f\"Response length: {claude_tokens} tokens\")\n",
        "print(f\"Response preview: {claude_response[:300]}...\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparison summary\n",
        "print(\"=== MODEL COMPARISON SUMMARY ===\")\n",
        "print(f\"ðŸ“Š Performance Metrics:\")\n",
        "print(f\"GPT-5-mini:     {gpt5_mini_time:.2f}s | {gpt5_mini_tokens:4d} tokens\")\n",
        "print(f\"Claude-3.5:     {claude_time:.2f}s | {claude_tokens:4d} tokens\")\n",
        "\n",
        "print(\"ðŸŽ¯ Key Insights:\")\n",
        "print(\"â€¢ Different models excel at different aspects\")\n",
        "print(\"â€¢ Speed vs. quality trade-offs are significant\")\n",
        "print(\"â€¢ System prompts greatly influence output quality\")\n",
        "print(\"â€¢ Model selection should match use case requirements\")\n",
        "\n",
        "print(\"ðŸ”§ Selection Guidelines:\")\n",
        "print(\"â€¢ GPT-5-mini: Fast iterations, cost-sensitive applications\")\n",
        "print(\"â€¢ Claude-3.5: Detailed analysis, creative tasks\")\n",
        "print(\"â€¢ Choose based on speed, cost, and quality requirements\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}