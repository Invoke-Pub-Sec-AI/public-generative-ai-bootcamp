{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 9: Note Catalog System\n",
        "\n",
        "## Learning Objectives\n",
        "- Build a knowledge management system with AI assistance\n",
        "- Implement note indexing and search functionality\n",
        "- Create semantic search with embeddings\n",
        "- Design a command-line interface for note management\n",
        "\n",
        "## Lab Overview\n",
        "Build an AI-powered note catalog system that can:\n",
        "1. **Import and Index Notes** - Process markdown files and extract metadata\n",
        "2. **Semantic Search** - Find relevant notes using natural language queries\n",
        "3. **Auto-Tagging** - Generate relevant tags for notes automatically\n",
        "4. **Knowledge Graph** - Build connections between related notes\n",
        "\n",
        "## Exit Ticket\n",
        "- [ ] Functional note import system\n",
        "- [ ] Working semantic search\n",
        "- [ ] AI-powered auto-tagging\n",
        "- [ ] CLI interface for note operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install asksageclient pip_system_certs tiktoken pandas numpy scikit-learn click rich"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 🔐 Cell 1 — Load secrets (Colab) + pricing + token utils\n",
        "# ================================\n",
        "import os, time, csv\n",
        "from typing import Optional, Dict\n",
        "import tiktoken\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "ASKSAGE_API_KEY = userdata.get(\"ASKSAGE_API_KEY\")\n",
        "ASKSAGE_BASE_URL = userdata.get(\"ASKSAGE_BASE_URL\")\n",
        "ASKSAGE_EMAIL = userdata.get(\"ASKSAGE_EMAIL\")\n",
        "\n",
        "assert ASKSAGE_API_KEY, \"ASKSAGE_API_KEY not provided.\"\n",
        "assert ASKSAGE_EMAIL, \"ASKSAGE_EMAIL not provided.\"\n",
        "\n",
        "print(\"✓ Secrets loaded\")\n",
        "print(\"  • EMAIL:\", ASKSAGE_EMAIL)\n",
        "print(\"  • BASE URL:\", ASKSAGE_BASE_URL or \"(default)\")\n",
        "\n",
        "# Pricing (USD per 1,000,000 tokens)\n",
        "PRICES_PER_M = {\n",
        "    \"gpt-5\": {\"input_per_m\": 1.25, \"output_per_m\": 10.00},\n",
        "    \"gpt-5-mini\": {\"input_per_m\": 0.25, \"output_per_m\": 2.00},\n",
        "}\n",
        "\n",
        "# Tokenizer\n",
        "enc = tiktoken.get_encoding(\"o200k_base\")\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(enc.encode(text or \"\"))\n",
        "\n",
        "def cost_usd(model: str, input_tokens: int, output_tokens: int) -> float:\n",
        "    if model not in PRICES_PER_M:\n",
        "        raise ValueError(f\"Unknown model: {model}\")\n",
        "    r = PRICES_PER_M[model]\n",
        "    return (input_tokens / 1_000_000) * r[\"input_per_m\"] + (output_tokens / 1_000_000) * r[\"output_per_m\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 🔧 Cell 2 — Import bootcamp_common and setup AskSage client\n",
        "# ================================\n",
        "import sys\n",
        "sys.path.append('../../../')  # Adjust path to reach bootcamp_common\n",
        "\n",
        "from bootcamp_common.ask_sage import AskSageClient\n",
        "\n",
        "# Initialize AskSage client\n",
        "client = AskSageClient(\n",
        "    api_key=ASKSAGE_API_KEY,\n",
        "    base_url=ASKSAGE_BASE_URL\n",
        ")\n",
        "\n",
        "print(\"✓ AskSage client initialized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "from dataclasses import dataclass, asdict\n",
        "from datetime import datetime\n",
        "\n",
        "import openai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import click\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.panel import Panel\n",
        "\n",
        "console = Console()\n",
        "print(\"📚 Note Catalog System loading...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Note Data Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Note:\n",
        "    \"\"\"Represents a single note in the catalog\"\"\"\n",
        "    id: str\n",
        "    title: str\n",
        "    content: str\n",
        "    filepath: str\n",
        "    tags: List[str]\n",
        "    created_at: str\n",
        "    modified_at: str\n",
        "    word_count: int\n",
        "    embedding: Optional[List[float]] = None\n",
        "    \n",
        "    @classmethod\n",
        "    def from_file(cls, filepath: Path) -> 'Note':\n",
        "        \"\"\"Create Note from markdown file\"\"\"\n",
        "        content = filepath.read_text(encoding='utf-8')\n",
        "        \n",
        "        # Extract title (first # heading or filename)\n",
        "        lines = content.split('\\n')\n",
        "        title = filepath.stem\n",
        "        for line in lines:\n",
        "            if line.startswith('# '):\n",
        "                title = line[2:].strip()\n",
        "                break\n",
        "        \n",
        "        # Generate ID from filepath\n",
        "        note_id = hashlib.md5(str(filepath).encode()).hexdigest()[:8]\n",
        "        \n",
        "        # File timestamps\n",
        "        stat = filepath.stat()\n",
        "        created_at = datetime.fromtimestamp(stat.st_ctime).isoformat()\n",
        "        modified_at = datetime.fromtimestamp(stat.st_mtime).isoformat()\n",
        "        \n",
        "        return cls(\n",
        "            id=note_id,\n",
        "            title=title,\n",
        "            content=content,\n",
        "            filepath=str(filepath),\n",
        "            tags=[],  # Will be populated by AI\n",
        "            created_at=created_at,\n",
        "            modified_at=modified_at,\n",
        "            word_count=len(content.split())\n",
        "        )\n",
        "\n",
        "print(\"📋 Note model defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Note Catalog Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NoteCatalog:\n",
        "    \"\"\"Manages a catalog of notes with AI-powered features\"\"\"\n",
        "    \n",
        "    def __init__(self, catalog_path: str = \"note_catalog.json\"):\n",
        "        self.catalog_path = catalog_path\n",
        "        self.notes: Dict[str, Note] = {}\n",
        "        self.setup_client()\n",
        "        self.load_catalog()\n",
        "    \n",
        "    def setup_client(self):\n",
        "        \"\"\"Setup OpenAI client\"\"\"\n",
        "        if os.getenv('OPENAI_API_KEY'):\n",
        "            try:\n",
        "                self.client = openai.OpenAI()\n",
        "                self.has_api = True\n",
        "                console.print(\"✅ OpenAI client configured\")\n",
        "            except Exception as e:\n",
        "                self.has_api = False\n",
        "                console.print(f\"⚠️ Using mock responses: {e}\")\n",
        "        else:\n",
        "            self.has_api = False\n",
        "            console.print(\"💡 No API key found, using mock features\")\n",
        "    \n",
        "    def load_catalog(self):\n",
        "        \"\"\"Load existing catalog from disk\"\"\"\n",
        "        if Path(self.catalog_path).exists():\n",
        "            with open(self.catalog_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "                for note_data in data.get('notes', []):\n",
        "                    note = Note(**note_data)\n",
        "                    self.notes[note.id] = note\n",
        "            console.print(f\"📚 Loaded {len(self.notes)} notes from catalog\")\n",
        "    \n",
        "    def save_catalog(self):\n",
        "        \"\"\"Save catalog to disk\"\"\"\n",
        "        data = {\n",
        "            'notes': [asdict(note) for note in self.notes.values()],\n",
        "            'updated_at': datetime.now().isoformat()\n",
        "        }\n",
        "        with open(self.catalog_path, 'w') as f:\n",
        "            json.dump(data, f, indent=2)\n",
        "        console.print(f\"💾 Saved catalog with {len(self.notes)} notes\")\n",
        "\n",
        "# TODO: Implement the import_notes method\n",
        "    def import_notes(self, directory: str) -> int:\n",
        "        \"\"\"Import markdown notes from directory\"\"\"\n",
        "        imported = 0\n",
        "        notes_dir = Path(directory)\n",
        "        \n",
        "        if not notes_dir.exists():\n",
        "            console.print(f\"❌ Directory not found: {directory}\")\n",
        "            return 0\n",
        "        \n",
        "        # TODO: Find all .md files in directory\n",
        "        # TODO: Create Note objects from files\n",
        "        # TODO: Generate embeddings and tags for each note\n",
        "        # TODO: Add notes to catalog\n",
        "        \n",
        "        # HINT: Use Path.glob(\"**/*.md\") to find markdown files\n",
        "        # HINT: Call generate_tags() and generate_embedding() for each note\n",
        "        \n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "# Initialize catalog\n",
        "catalog = NoteCatalog()\n",
        "print(\"📚 Note catalog ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AI-Powered Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AIFeatures:\n",
        "    \"\"\"AI-powered note analysis features\"\"\"\n",
        "    \n",
        "    def __init__(self, catalog: NoteCatalog):\n",
        "        self.catalog = catalog\n",
        "    \n",
        "    def generate_tags(self, note: Note) -> List[str]:\n",
        "        \"\"\"Generate relevant tags for a note using AI\"\"\"\n",
        "        \n",
        "        prompt = f\"\"\"Analyze this note and generate 3-5 relevant tags.\n",
        "Return only the tags as a comma-separated list.\n",
        "\n",
        "Title: {note.title}\n",
        "Content: {note.content[:500]}...\n",
        "\n",
        "Tags:\"\"\"\n",
        "        \n",
        "        if self.catalog.has_api:\n",
        "            try:\n",
        "                response = self.catalog.client.chat.completions.create(\n",
        "                    model=\"gpt-3.5-turbo\",\n",
        "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                    max_tokens=50,\n",
        "                    temperature=0.3\n",
        "                )\n",
        "                tags_text = response.choices[0].message.content.strip()\n",
        "                return [tag.strip() for tag in tags_text.split(',')]\n",
        "            except Exception as e:\n",
        "                console.print(f\"⚠️ Tag generation failed: {e}\")\n",
        "        \n",
        "        # Mock tags based on content\n",
        "        content_lower = note.content.lower()\n",
        "        mock_tags = []\n",
        "        if 'python' in content_lower: mock_tags.append('python')\n",
        "        if 'ai' in content_lower or 'machine learning' in content_lower: mock_tags.append('ai')\n",
        "        if 'data' in content_lower: mock_tags.append('data')\n",
        "        if 'web' in content_lower: mock_tags.append('web')\n",
        "        return mock_tags or ['general']\n",
        "    \n",
        "    def generate_embedding(self, text: str) -> List[float]:\n",
        "        \"\"\"Generate text embedding for semantic search\"\"\"\n",
        "        \n",
        "        if self.catalog.has_api:\n",
        "            try:\n",
        "                response = self.catalog.client.embeddings.create(\n",
        "                    model=\"text-embedding-ada-002\",\n",
        "                    input=text[:8000]  # Limit text length\n",
        "                )\n",
        "                return response.data[0].embedding\n",
        "            except Exception as e:\n",
        "                console.print(f\"⚠️ Embedding generation failed: {e}\")\n",
        "        \n",
        "        # Mock embedding (random vector for testing)\n",
        "        return np.random.rand(1536).tolist()\n",
        "\n",
        "# TODO: Implement semantic search\n",
        "    def semantic_search(self, query: str, top_k: int = 5) -> List[tuple]:\n",
        "        \"\"\"Search notes using semantic similarity\"\"\"\n",
        "        \n",
        "        # TODO: Generate embedding for query\n",
        "        # TODO: Calculate similarity with all note embeddings\n",
        "        # TODO: Return top-k most similar notes with scores\n",
        "        \n",
        "        # HINT: Use cosine_similarity from sklearn\n",
        "        # HINT: Filter out notes without embeddings\n",
        "        \n",
        "        pass  # Replace with your implementation\n",
        "\n",
        "# Initialize AI features\n",
        "ai_features = AIFeatures(catalog)\n",
        "print(\"🤖 AI features ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demo: Create Sample Notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample notes directory\n",
        "sample_dir = Path(\"sample_notes\")\n",
        "sample_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Sample notes content\n",
        "sample_notes = {\n",
        "    \"python_basics.md\": \"\"\"# Python Basics\n",
        "\n",
        "Python is a high-level programming language known for its simplicity and readability.\n",
        "\n",
        "## Key Features\n",
        "- Easy to learn syntax\n",
        "- Extensive standard library\n",
        "- Large ecosystem of third-party packages\n",
        "- Great for data science, web development, and automation\n",
        "\n",
        "## Getting Started\n",
        "```python\n",
        "print(\"Hello, World!\")\n",
        "```\"\"\",\n",
        "    \n",
        "    \"machine_learning_intro.md\": \"\"\"# Introduction to Machine Learning\n",
        "\n",
        "Machine learning is a subset of AI that enables computers to learn without explicit programming.\n",
        "\n",
        "## Types of ML\n",
        "1. **Supervised Learning** - Learning with labeled data\n",
        "2. **Unsupervised Learning** - Finding patterns in unlabeled data\n",
        "3. **Reinforcement Learning** - Learning through interaction\n",
        "\n",
        "## Popular Libraries\n",
        "- scikit-learn\n",
        "- TensorFlow\n",
        "- PyTorch\"\"\",\n",
        "    \n",
        "    \"web_development.md\": \"\"\"# Web Development Notes\n",
        "\n",
        "Web development involves creating applications that run on the internet.\n",
        "\n",
        "## Frontend Technologies\n",
        "- HTML/CSS for structure and styling\n",
        "- JavaScript for interactivity\n",
        "- React, Vue, Angular for frameworks\n",
        "\n",
        "## Backend Technologies\n",
        "- Python (Django, Flask)\n",
        "- Node.js\n",
        "- Database integration\"\"\"\n",
        "}\n",
        "\n",
        "# Write sample files\n",
        "for filename, content in sample_notes.items():\n",
        "    filepath = sample_dir / filename\n",
        "    filepath.write_text(content, encoding='utf-8')\n",
        "\n",
        "console.print(f\"📝 Created {len(sample_notes)} sample notes in {sample_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Implement Note Import\n",
        "\n",
        "Complete the `import_notes` method in the `NoteCatalog` class above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Test your import_notes implementation\n",
        "# imported_count = catalog.import_notes(\"sample_notes\")\n",
        "# console.print(f\"✅ Imported {imported_count} notes\")\n",
        "# catalog.save_catalog()\n",
        "\n",
        "pass  # Replace with your test code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Implement Semantic Search\n",
        "\n",
        "Complete the `semantic_search` method in the `AIFeatures` class above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Test your semantic search implementation\n",
        "# search_results = ai_features.semantic_search(\"python programming\")\n",
        "# \n",
        "# table = Table(title=\"Search Results\")\n",
        "# table.add_column(\"Score\", style=\"green\")\n",
        "# table.add_column(\"Title\", style=\"blue\")\n",
        "# table.add_column(\"Tags\", style=\"yellow\")\n",
        "# \n",
        "# for score, note in search_results:\n",
        "#     table.add_row(f\"{score:.3f}\", note.title, \", \".join(note.tags))\n",
        "# \n",
        "# console.print(table)\n",
        "\n",
        "pass  # Replace with your test code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Build CLI Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Implement a CLI interface using Click\n",
        "# Commands to implement:\n",
        "# - import: Import notes from directory\n",
        "# - search: Search notes by query\n",
        "# - list: List all notes\n",
        "# - show: Show specific note content\n",
        "# - tags: List all tags\n",
        "\n",
        "@click.group()\n",
        "def cli():\n",
        "    \"\"\"Note Catalog CLI\"\"\"\n",
        "    pass\n",
        "\n",
        "# TODO: Add CLI commands here\n",
        "# Example:\n",
        "# @cli.command()\n",
        "# @click.argument('directory')\n",
        "# def import_cmd(directory):\n",
        "#     \"\"\"Import notes from directory\"\"\"\n",
        "#     pass\n",
        "\n",
        "print(\"🖥️ CLI framework ready (implement commands above)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extension Ideas\n",
        "\n",
        "🚀 **Advanced Features to Implement:**\n",
        "\n",
        "1. **Knowledge Graph**: Build connections between related notes\n",
        "2. **Auto-Summary**: Generate summaries of long notes\n",
        "3. **Duplicate Detection**: Find similar or duplicate notes\n",
        "4. **Export Features**: Export to various formats (PDF, HTML)\n",
        "5. **Version Control**: Track note changes over time\n",
        "6. **Web Interface**: Build a web UI with Streamlit or Flask\n",
        "7. **Integration**: Connect with existing note apps (Obsidian, Notion)\n",
        "\n",
        "## Deliverable Checklist\n",
        "\n",
        "- [ ] Functional note import system that processes markdown files\n",
        "- [ ] AI-powered tag generation for automatic categorization\n",
        "- [ ] Semantic search using embeddings and similarity matching\n",
        "- [ ] Command-line interface for note operations\n",
        "- [ ] Proper error handling and user feedback\n",
        "- [ ] Data persistence with JSON catalog storage\n",
        "\n",
        "**Bonus Points:**\n",
        "- [ ] Performance optimization for large note collections\n",
        "- [ ] Advanced search filters (date, tags, file type)\n",
        "- [ ] Export functionality for search results\n",
        "- [ ] Integration with external APIs or services"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}