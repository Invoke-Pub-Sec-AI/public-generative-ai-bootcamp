{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "27d15c0cdbb04788a1607137580a74dc",
      "metadata": {},
      "source": [
        "# Lab 05: Reflection and Self-Correction\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand the concept of reflection for improving LLM output\n",
        "- Implement a multi-step process: generate, critique, and refine\n",
        "- Write effective prompts for a 'critic' LLM\n",
        "- See how iterative refinement can lead to higher-quality results\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c51081d7e64acb96bc4040e54fbf69",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, Any"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c65377dfeb74bed894c87e738d9b5ee",
      "metadata": {},
      "source": [
        "## Part 1: The Reflection Framework\n",
        "\n",
        "Reflection is a process where an agent critically assesses its own work and uses that assessment to improve it. In the context of LLMs, this typically involves a multi-step workflow:\n",
        "\n",
        "1.  **Generate**: The LLM produces an initial draft based on a user's prompt.\n",
        "2.  **Critique (Reflect)**: The LLM (or another LLM) is prompted to act as a critic. It reviews the initial draft against a set of criteria and identifies flaws, omissions, or areas for improvement.\n",
        "3.  **Refine (Self-Correct)**: The LLM receives the original prompt, the initial draft, and the critique, and is tasked with generating a new, improved version that addresses the feedback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ce990d4cc546e4938c3400704ba875",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Mock LLM with Different Personas ---\n",
        "class ReflectiveLLM:\n",
        "    def generate_draft(self, prompt: str) -> str:\n",
        "        \"\"\"Generates a quick, potentially flawed first draft.\"\"\"\n",
        "        if 'python function' in prompt.lower() and 'add two numbers' in prompt.lower():\n",
        "            # A flawed implementation\n",
        "            return 'def add(x, y):\\n  return x + y'\n",
        "        return 'Initial draft content.'\n",
        "\n",
        "    def critique_draft(self, draft: str, criteria: str) -> str:\n",
        "        \"\"\"Acts as a critic to find flaws based on given criteria.\"\"\"\n",
        "        critique = ''\n",
        "        if 'docstring' in criteria.lower() and 'def add' in draft:\n",
        "            critique += '- The function is missing a docstring explaining what it does.\\n'\n",
        "        if 'type hints' in criteria.lower() and 'def add' in draft:\n",
        "            critique += '- The function parameters and return value are missing type hints.'\n",
        "        return critique if critique else 'The draft looks good.'\n",
        "\n",
        "    def refine_draft(self, original_prompt: str, draft: str, critique: str) -> str:\n",
        "        \"\"\"Generates a new version that addresses the critique.\"\"\"\n",
        "        if 'missing a docstring' in critique and 'missing type hints' in critique:\n",
        "            return (\n",
        "                'def add(x: int, y: int) -> int:\\n'\n",
        "                '    \"\"\"Adds two integers together.\"\"\"\\n'\n",
        "                '    return x + y'\n",
        "            )\n",
        "        return draft # Return original if no changes needed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2957268c9c06445caebc9d4849728aab",
      "metadata": {},
      "source": [
        "## Part 2: The Reflection and Refinement Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7542ed2b07ab405bbf645ca7d5d16e0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_reflection_process(prompt: str, critique_criteria: str):\n",
        "    llm = ReflectiveLLM()\n",
        "    \n",
        "    # 1. Generate Initial Draft\n",
        "    print(\"--- Step 1: Generating Initial Draft ---\")\n",
        "    initial_draft = llm.generate_draft(prompt)\n",
        "    print(f'Initial Draft:\n",
        "{initial_draft}')\n",
        "    \n",
        "    # 2. Critique the Draft\n",
        "    print(\"\n",
        "--- Step 2: Critiquing the Draft ---\")\n",
        "    critique = llm.critique_draft(initial_draft, critique_criteria)\n",
        "    print(f'Critique:\n",
        "{critique}')\n",
        "    \n",
        "    if 'looks good' in critique:\n",
        "        print(\"\n",
        "--- No refinement needed. ---\")\n",
        "        return initial_draft\n",
        "        \n",
        "    # 3. Refine the Draft based on the Critique\n",
        "    print(\"\n",
        "--- Step 3: Refining the Draft ---\")\n",
        "    refined_draft = llm.refine_draft(prompt, initial_draft, critique)\n",
        "    print(f'Refined Draft:\n",
        "{refined_draft}')\n",
        "    \n",
        "    return refined_draft\n",
        "\n",
        "# --- Run the Process ---\n",
        "task_prompt = 'Write a python function to add two numbers.'\n",
        "# The criteria for the critic are crucial for getting good feedback\n",
        "code_critique_criteria = (\n",
        "    'Check the following for the Python code provided:\n",
        "'\n",
        "    '1. Is there a clear and concise docstring?\n",
        "'\n",
        "    '2. Are there type hints for all parameters and the return value?'\n",
        "    '3. Is the code efficient and readable?'\n",
        ")\n",
        "\n",
        "final_code = run_reflection_process(task_prompt, code_critique_criteria)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23188cb1771c4fee882deef13bd51127",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "1. **Add Another Refinement Loop**: What if the refined draft still isn't perfect? Modify the `run_reflection_process` to loop. After refining, it should critique the *new* draft. The loop should end when the critique comes back empty (e.g., \"The draft looks good\") or after a maximum number of iterations.\n",
        "2. **Critique for a Different Task**: Write a new `task_prompt` to generate a short story about a robot. Then, write a `story_critique_criteria` string that asks the critic to check for character development, plot consistency, and descriptive language. Modify the `ReflectiveLLM` to handle this new task and see how the process works for creative writing.\n",
        "3. **Self-Critique Prompt**: Combine the generation and critique steps. Write a single, complex prompt that asks the LLM to first generate a draft and then, in the same response, provide a critique of its own work. This is a common technique when you want to save on the number of LLM calls.\n",
        "\n",
        "## Summary\n",
        "\n",
        "You learned:\n",
        "- The **Reflection Framework**, an iterative process of generating, critiquing, and refining work to improve its quality.\n",
        "- The importance of a well-defined **critique prompt** that gives the LLM clear criteria for evaluating a draft.\n",
        "- How this self-correction mechanism can be used to produce more robust, accurate, and polished output for a wide range of tasks, from coding to creative writing."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}