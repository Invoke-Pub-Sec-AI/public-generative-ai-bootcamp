{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reliability in Practice - Demo with GPT-5-Mini\n",
        "\n",
        "**Focus**: retries with jitter, timeouts, concurrency, budget caps using GPT-5-Mini via AskSage\n",
        "\n",
        "This notebook demonstrates practical techniques for building reliable AI applications that can handle failures gracefully and operate within budget constraints using GPT-5-Mini through the AskSage platform.\n",
        "\n",
        "## Learning Objectives\n",
        "- Implement retry mechanisms with exponential backoff and jitter\n",
        "- Add timeouts to prevent hanging operations\n",
        "- Manage concurrent API calls safely\n",
        "- Implement budget caps and cost monitoring\n",
        "- Build resilient error handling patterns\n",
        "- Use GPT-5-Mini via AskSage for AI operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for Google Colab\n",
        "!pip install asksageclient tenacity asyncio aiohttp requests matplotlib pandas\n",
        "\n",
        "import time\n",
        "import random\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import os\n",
        "from asksageclient import AskSageClient\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "import concurrent.futures\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import logging\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional, Callable\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"‚úÖ All packages installed and modules imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize AskSage client with credentials\n",
        "# Note: Set your environment variables or provide credentials directly\n",
        "# ASKSAGE_API_KEY should be set in your environment\n",
        "# ASKSAGE_BASE_URL should be set (e.g., 'https://api.asksage.ai')\n",
        "\n",
        "try:\n",
        "    ask_sage_client = AskSageClient(\n",
        "        api_key=os.getenv('ASKSAGE_API_KEY'),\n",
        "        base_url=os.getenv('ASKSAGE_BASE_URL', 'https://api.asksage.ai')\n",
        "    )\n",
        "    print(\"‚úÖ AskSage client initialized successfully!\")\n",
        "    \n",
        "    # Test the connection and get available models\n",
        "    models_response = ask_sage_client.get_models()\n",
        "    if 'response' in models_response:\n",
        "        available_models = models_response['response']\n",
        "        print(f\"üìã Available models: {len(available_models)} total\")\n",
        "        \n",
        "        # Check if gpt-5-mini is available\n",
        "        if 'gpt-5-mini' in available_models:\n",
        "            print(\"‚úÖ GPT-5-Mini is available!\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  GPT-5-Mini not found. Available models:\")\n",
        "            for model in available_models[:10]:  # Show first 10 models\n",
        "                print(f\"  - {model}\")\n",
        "            if len(available_models) > 10:\n",
        "                print(f\"  ... and {len(available_models) - 10} more\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Could not retrieve model list\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error initializing AskSage client: {e}\")\n",
        "    print(\"Please ensure your ASKSAGE_API_KEY and ASKSAGE_BASE_URL are set correctly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Retry Mechanisms with Jitter\n",
        "\n",
        "Retries are essential for handling transient failures, but naive retry patterns can create thundering herd problems. Adding jitter helps distribute retry attempts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate an unreliable AI API using GPT-5-Mini\n",
        "class UnreliableAIAPI:\n",
        "    def __init__(self, success_rate=0.7, use_gpt5_mini=True):\n",
        "        self.success_rate = success_rate\n",
        "        self.call_count = 0\n",
        "        self.use_gpt5_mini = use_gpt5_mini\n",
        "        \n",
        "    def make_ai_request(self, prompt: str, task_type: str = \"general\"):\n",
        "        self.call_count += 1\n",
        "        \n",
        "        # Simulate network delay\n",
        "        time.sleep(random.uniform(0.1, 0.5))\n",
        "        \n",
        "        # Random failure based on success rate\n",
        "        if random.random() > self.success_rate:\n",
        "            failure_types = [\n",
        "                (ConnectionError, \"Network connection failed\"),\n",
        "                (TimeoutError, \"Request timed out\"),\n",
        "                (ValueError, \"Invalid request format\"),\n",
        "                (Exception, \"Rate limit exceeded\")\n",
        "            ]\n",
        "            error_type, error_msg = random.choice(failure_types)\n",
        "            raise error_type(error_msg)\n",
        "        \n",
        "        # Make actual AI request using GPT-5-Mini\n",
        "        try:\n",
        "            if self.use_gpt5_mini:\n",
        "                # Create a system prompt based on task type\n",
        "                system_prompts = {\n",
        "                    \"analysis\": \"You are an expert analyst. Provide concise, factual analysis.\",\n",
        "                    \"creative\": \"You are a creative assistant. Be imaginative and engaging.\",\n",
        "                    \"technical\": \"You are a technical expert. Provide accurate, detailed explanations.\",\n",
        "                    \"general\": \"You are a helpful AI assistant. Be clear and informative.\"\n",
        "                }\n",
        "                \n",
        "                system_prompt = system_prompts.get(task_type, system_prompts[\"general\"])\n",
        "                \n",
        "                # Use AskSage client to query GPT-5-Mini\n",
        "                response = ask_sage_client.query(\n",
        "                    message=prompt,\n",
        "                    model=\"gpt-5-mini\",  # Specify GPT-5-Mini\n",
        "                    system_prompt=system_prompt,\n",
        "                    max_tokens=150  # Keep responses concise for demo\n",
        "                )\n",
        "                \n",
        "                if 'response' in response:\n",
        "                    ai_result = response['response']\n",
        "                else:\n",
        "                    ai_result = \"AI response received but format unexpected\"\n",
        "            else:\n",
        "                # Fallback simulated response\n",
        "                ai_result = f\"Simulated AI response for: {prompt[:50]}...\"\n",
        "        \n",
        "        except Exception as ai_error:\n",
        "            logger.warning(f\"AI API error: {ai_error}\")\n",
        "            ai_result = f\"AI processing failed: {str(ai_error)[:100]}...\"\n",
        "        \n",
        "        return {\n",
        "            \"prompt\": prompt,\n",
        "            \"result\": ai_result,\n",
        "            \"task_type\": task_type,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"call_number\": self.call_count\n",
        "        }\n",
        "\n",
        "# Initialize our unreliable AI API\n",
        "ai_api = UnreliableAIAPI(success_rate=0.6)  # 60% success rate\n",
        "\n",
        "print(\"Unreliable AI API initialized with 60% success rate using GPT-5-Mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retry with exponential backoff and jitter for AI requests\n",
        "@retry(\n",
        "    stop=stop_after_attempt(5),\n",
        "    wait=wait_exponential(multiplier=1, min=1, max=10) + wait_exponential(multiplier=0.1, min=0, max=2),\n",
        "    retry=retry_if_exception_type((ConnectionError, TimeoutError))\n",
        ")\n",
        "def reliable_ai_call(prompt: str, task_type: str = \"general\"):\n",
        "    logger.info(f\"Attempting AI call for task '{task_type}': {prompt[:50]}...\")\n",
        "    return ai_api.make_ai_request(prompt, task_type)\n",
        "\n",
        "# Test retry mechanism with various AI prompts\n",
        "test_prompts = [\n",
        "    (\"Explain the concept of machine learning in simple terms.\", \"technical\"),\n",
        "    (\"Write a creative short story about a robot learning to paint.\", \"creative\"),\n",
        "    (\"Analyze the pros and cons of renewable energy sources.\", \"analysis\")\n",
        "]\n",
        "\n",
        "results = []\n",
        "failures = []\n",
        "\n",
        "print(\"Testing retry mechanism with GPT-5-Mini...\\n\")\n",
        "\n",
        "for i, (prompt, task_type) in enumerate(test_prompts, 1):\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        result = reliable_ai_call(prompt, task_type)\n",
        "        end_time = time.time()\n",
        "        \n",
        "        results.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"result\": result,\n",
        "            \"duration\": end_time - start_time,\n",
        "            \"success\": True,\n",
        "            \"task_type\": task_type\n",
        "        })\n",
        "        \n",
        "        print(f\"‚úÖ Success for prompt {i} ({task_type}) after {end_time - start_time:.2f}s\")\n",
        "        print(f\"   Response preview: {result['result'][:100]}...\\n\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        failures.append({\"prompt\": prompt, \"error\": str(e), \"task_type\": task_type})\n",
        "        logger.error(f\"‚ùå Failed for prompt {i} ({task_type}): {e}\")\n",
        "\n",
        "print(f\"\\nüìä Results: {len(results)} successes, {len(failures)} failures\")\n",
        "print(f\"Total API calls made: {ai_api.call_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Timeout Implementation\n",
        "\n",
        "Timeouts prevent operations from hanging indefinitely and help maintain system responsiveness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import signal\n",
        "from contextlib import contextmanager\n",
        "\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "@contextmanager\n",
        "def timeout(duration):\n",
        "    def timeout_handler(signum, frame):\n",
        "        raise TimeoutException(f\"Operation timed out after {duration} seconds\")\n",
        "    \n",
        "    # Set the signal handler\n",
        "    old_handler = signal.signal(signal.SIGALRM, timeout_handler)\n",
        "    signal.alarm(duration)\n",
        "    \n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        # Restore the old handler\n",
        "        signal.alarm(0)\n",
        "        signal.signal(signal.SIGALRM, old_handler)\n",
        "\n",
        "# Function with timeout wrapper for AI requests\n",
        "def ai_call_with_timeout(prompt: str, task_type: str = \"general\", timeout_seconds: int = 10):\n",
        "    try:\n",
        "        with timeout(timeout_seconds):\n",
        "            return ai_api.make_ai_request(prompt, task_type)\n",
        "    except TimeoutException as e:\n",
        "        logger.warning(f\"Timeout for prompt '{prompt[:50]}...': {e}\")\n",
        "        raise\n",
        "\n",
        "# Test timeout mechanism\n",
        "print(\"Testing timeout mechanism with GPT-5-Mini...\")\n",
        "test_prompt = \"Explain quantum computing and its potential applications in detail.\"\n",
        "\n",
        "try:\n",
        "    result = ai_call_with_timeout(test_prompt, \"technical\", timeout_seconds=8)\n",
        "    print(f\"‚úÖ Call completed successfully!\")\n",
        "    print(f\"üìù Response: {result['result'][:200]}...\")\n",
        "except TimeoutException as e:\n",
        "    print(f\"‚è∞ Timeout occurred: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Other error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Concurrency Management\n",
        "\n",
        "Managing concurrent requests helps balance throughput with resource constraints and rate limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concurrent AI request manager for GPT-5-Mini\n",
        "class ConcurrentAIManager:\n",
        "    def __init__(self, max_workers=5, rate_limit_per_second=10):\n",
        "        self.max_workers = max_workers\n",
        "        self.rate_limit = rate_limit_per_second\n",
        "        self.last_request_times = []\n",
        "        self.lock = threading.Lock()\n",
        "        \n",
        "    def _enforce_rate_limit(self):\n",
        "        with self.lock:\n",
        "            now = time.time()\n",
        "            # Remove requests older than 1 second\n",
        "            self.last_request_times = [t for t in self.last_request_times if now - t < 1.0]\n",
        "            \n",
        "            if len(self.last_request_times) >= self.rate_limit:\n",
        "                sleep_time = 1.0 - (now - self.last_request_times[0])\n",
        "                if sleep_time > 0:\n",
        "                    time.sleep(sleep_time)\n",
        "            \n",
        "            self.last_request_times.append(time.time())\n",
        "    \n",
        "    def make_concurrent_requests(self, prompt_tasks):\n",
        "        \"\"\"\n",
        "        Make concurrent AI requests.\n",
        "        \n",
        "        Args:\n",
        "            prompt_tasks: List of (prompt, task_type) tuples\n",
        "        \"\"\"\n",
        "        def single_request(prompt_task):\n",
        "            prompt, task_type = prompt_task\n",
        "            self._enforce_rate_limit()\n",
        "            try:\n",
        "                return reliable_ai_call(prompt, task_type)\n",
        "            except Exception as e:\n",
        "                return {\"error\": str(e), \"prompt\": prompt, \"task_type\": task_type}\n",
        "        \n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            futures = {executor.submit(single_request, pt): pt for pt in prompt_tasks}\n",
        "            results = []\n",
        "            \n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    results.append(result)\n",
        "                except Exception as e:\n",
        "                    prompt_task = futures[future]\n",
        "                    results.append({\"error\": str(e), \"prompt\": prompt_task[0], \"task_type\": prompt_task[1]})\n",
        "            \n",
        "            return results\n",
        "\n",
        "import threading\n",
        "\n",
        "# Test concurrent requests with various AI tasks\n",
        "manager = ConcurrentAIManager(max_workers=3, rate_limit_per_second=5)\n",
        "\n",
        "# Create diverse test requests\n",
        "test_requests = [\n",
        "    (\"Summarize the benefits of exercise.\", \"analysis\"),\n",
        "    (\"Write a haiku about technology.\", \"creative\"),\n",
        "    (\"Explain how neural networks work.\", \"technical\"),\n",
        "    (\"What are the main causes of climate change?\", \"analysis\"),\n",
        "    (\"Create a short dialogue between two AI assistants.\", \"creative\"),\n",
        "    (\"Describe the process of photosynthesis.\", \"technical\"),\n",
        "    (\"List pros and cons of remote work.\", \"analysis\"),\n",
        "    (\"Write a limerick about coding.\", \"creative\")\n",
        "]\n",
        "\n",
        "print(f\"Testing concurrent processing of {len(test_requests)} AI requests...\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "concurrent_results = manager.make_concurrent_requests(test_requests)\n",
        "end_time = time.time()\n",
        "\n",
        "successful = [r for r in concurrent_results if \"error\" not in r]\n",
        "failed = [r for r in concurrent_results if \"error\" in r]\n",
        "\n",
        "print(f\"\\nüìä Concurrent processing completed in {end_time - start_time:.2f}s\")\n",
        "print(f\"‚úÖ Successful requests: {len(successful)}\")\n",
        "print(f\"‚ùå Failed requests: {len(failed)}\")\n",
        "print(f\"üîÑ Total API calls: {ai_api.call_count}\")\n",
        "\n",
        "# Show sample successful responses\n",
        "if successful:\n",
        "    print(\"\\nüìã Sample successful responses:\")\n",
        "    for i, result in enumerate(successful[:3]):\n",
        "        print(f\"  {i+1}. [{result.get('task_type', 'unknown')}] {result.get('result', 'N/A')[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Budget Caps and Cost Monitoring\n",
        "\n",
        "Implementing budget controls prevents runaway costs and provides visibility into API usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class AIUsage:\n",
        "    calls_made: int = 0\n",
        "    total_cost: float = 0.0\n",
        "    successful_calls: int = 0\n",
        "    failed_calls: int = 0\n",
        "    total_tokens: int = 0\n",
        "    start_time: datetime = None\n",
        "\n",
        "class BudgetManager:\n",
        "    def __init__(self, daily_budget=50.0, cost_per_1k_tokens=0.0015):\n",
        "        \"\"\"Initialize budget manager.\n",
        "        \n",
        "        Args:\n",
        "            daily_budget: Maximum daily budget in USD\n",
        "            cost_per_1k_tokens: Cost per 1000 tokens for GPT-5-Mini\n",
        "        \"\"\"\n",
        "        self.daily_budget = daily_budget\n",
        "        self.cost_per_1k_tokens = cost_per_1k_tokens\n",
        "        self.usage = AIUsage(start_time=datetime.now())\n",
        "        self.lock = threading.Lock()\n",
        "        \n",
        "    def estimate_tokens(self, text: str) -> int:\n",
        "        \"\"\"Rough estimation of tokens (approximately 4 characters per token)\"\"\"\n",
        "        return len(text) // 4\n",
        "        \n",
        "    def can_make_call(self, estimated_prompt_tokens: int = 100) -> bool:\n",
        "        with self.lock:\n",
        "            estimated_cost = (estimated_prompt_tokens / 1000) * self.cost_per_1k_tokens\n",
        "            projected_cost = self.usage.total_cost + estimated_cost\n",
        "            return projected_cost <= self.daily_budget\n",
        "    \n",
        "    def record_call(self, success: bool, prompt: str = \"\", response: str = \"\"):\n",
        "        with self.lock:\n",
        "            self.usage.calls_made += 1\n",
        "            \n",
        "            # Estimate tokens used\n",
        "            prompt_tokens = self.estimate_tokens(prompt)\n",
        "            response_tokens = self.estimate_tokens(response)\n",
        "            total_tokens = prompt_tokens + response_tokens\n",
        "            \n",
        "            # Calculate cost\n",
        "            call_cost = (total_tokens / 1000) * self.cost_per_1k_tokens\n",
        "            \n",
        "            self.usage.total_tokens += total_tokens\n",
        "            self.usage.total_cost += call_cost\n",
        "            \n",
        "            if success:\n",
        "                self.usage.successful_calls += 1\n",
        "            else:\n",
        "                self.usage.failed_calls += 1\n",
        "    \n",
        "    def get_usage_report(self) -> Dict:\n",
        "        with self.lock:\n",
        "            runtime = datetime.now() - self.usage.start_time\n",
        "            return {\n",
        "                \"total_calls\": self.usage.calls_made,\n",
        "                \"successful_calls\": self.usage.successful_calls,\n",
        "                \"failed_calls\": self.usage.failed_calls,\n",
        "                \"success_rate\": self.usage.successful_calls / max(1, self.usage.calls_made) * 100,\n",
        "                \"total_cost\": self.usage.total_cost,\n",
        "                \"total_tokens\": self.usage.total_tokens,\n",
        "                \"budget_remaining\": self.daily_budget - self.usage.total_cost,\n",
        "                \"budget_used_percent\": (self.usage.total_cost / self.daily_budget) * 100,\n",
        "                \"runtime_minutes\": runtime.total_seconds() / 60,\n",
        "                \"calls_per_minute\": self.usage.calls_made / max(1, runtime.total_seconds() / 60),\n",
        "                \"avg_cost_per_call\": self.usage.total_cost / max(1, self.usage.calls_made)\n",
        "            }\n",
        "\n",
        "# Budget-aware AI caller\n",
        "class BudgetAwareAI:\n",
        "    def __init__(self, budget_manager: BudgetManager):\n",
        "        self.budget_manager = budget_manager\n",
        "        \n",
        "    def make_call(self, prompt: str, task_type: str = \"general\"):\n",
        "        estimated_tokens = self.budget_manager.estimate_tokens(prompt) + 150  # Estimate response tokens\n",
        "        \n",
        "        if not self.budget_manager.can_make_call(estimated_tokens):\n",
        "            raise ValueError(\"Budget limit reached - cannot make more calls\")\n",
        "        \n",
        "        try:\n",
        "            result = ai_api.make_ai_request(prompt, task_type)\n",
        "            response_text = result.get('result', '')\n",
        "            self.budget_manager.record_call(success=True, prompt=prompt, response=response_text)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            self.budget_manager.record_call(success=False, prompt=prompt, response=\"\")\n",
        "            raise e\n",
        "\n",
        "# Test budget management\n",
        "budget_mgr = BudgetManager(daily_budget=2.0, cost_per_1k_tokens=0.0015)  # Small budget for testing\n",
        "budget_ai = BudgetAwareAI(budget_mgr)\n",
        "\n",
        "print(\"Testing budget management with GPT-5-Mini...\\n\")\n",
        "\n",
        "test_prompts_budget = [\n",
        "    \"Explain artificial intelligence.\",\n",
        "    \"Write a short poem about nature.\",\n",
        "    \"Describe the solar system.\",\n",
        "    \"What is machine learning?\",\n",
        "    \"Create a simple recipe for cookies.\"\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(test_prompts_budget):\n",
        "    try:\n",
        "        result = budget_ai.make_call(prompt, \"general\")\n",
        "        print(f\"‚úÖ Call {i+1} successful: {result['result'][:60]}...\")\n",
        "    except ValueError as e:\n",
        "        print(f\"üí∞ Budget limit reached at call {i+1}: {e}\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Call {i+1} failed: {e}\")\n",
        "\n",
        "# Print usage report\n",
        "report = budget_mgr.get_usage_report()\n",
        "print(\"\\nüìä Budget Usage Report:\")\n",
        "print(\"=\" * 40)\n",
        "for key, value in report.items():\n",
        "    if isinstance(value, float):\n",
        "        if 'percent' in key or 'rate' in key:\n",
        "            print(f\"{key}: {value:.1f}%\")\n",
        "        elif 'cost' in key:\n",
        "            print(f\"{key}: ${value:.4f}\")\n",
        "        else:\n",
        "            print(f\"{key}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comprehensive Reliability System\n",
        "\n",
        "Combining all techniques into a production-ready reliability system for GPT-5-Mini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReliableAIClient:\n",
        "    def __init__(self, budget_manager, max_workers=3, timeout_seconds=10):\n",
        "        self.budget_manager = budget_manager\n",
        "        self.max_workers = max_workers\n",
        "        self.timeout_seconds = timeout_seconds\n",
        "        self.metrics = {\n",
        "            \"requests_attempted\": 0,\n",
        "            \"requests_successful\": 0,\n",
        "            \"requests_failed\": 0,\n",
        "            \"budget_limited\": 0,\n",
        "            \"timeouts\": 0,\n",
        "            \"retries_triggered\": 0,\n",
        "            \"total_response_time\": 0.0\n",
        "        }\n",
        "    \n",
        "    @retry(\n",
        "        stop=stop_after_attempt(3),\n",
        "        wait=wait_exponential(multiplier=1, min=1, max=5) + wait_exponential(multiplier=0.1, min=0, max=1),\n",
        "        retry=retry_if_exception_type((ConnectionError, TimeoutError))\n",
        "    )\n",
        "    def _make_single_request(self, prompt: str, task_type: str = \"general\"):\n",
        "        estimated_tokens = self.budget_manager.estimate_tokens(prompt) + 150\n",
        "        \n",
        "        if not self.budget_manager.can_make_call(estimated_tokens):\n",
        "            self.metrics[\"budget_limited\"] += 1\n",
        "            raise ValueError(\"Budget limit exceeded\")\n",
        "        \n",
        "        try:\n",
        "            # Use timeout wrapper for the AI request\n",
        "            with timeout(self.timeout_seconds):\n",
        "                result = ai_api.make_ai_request(prompt, task_type)\n",
        "            \n",
        "            response_text = result.get('result', '')\n",
        "            self.budget_manager.record_call(success=True, prompt=prompt, response=response_text)\n",
        "            self.metrics[\"requests_successful\"] += 1\n",
        "            return result\n",
        "            \n",
        "        except TimeoutException:\n",
        "            self.metrics[\"timeouts\"] += 1\n",
        "            self.budget_manager.record_call(success=False, prompt=prompt, response=\"\")\n",
        "            raise TimeoutError(\"Request timed out\")\n",
        "            \n",
        "        except (ConnectionError, TimeoutError) as e:\n",
        "            self.metrics[\"retries_triggered\"] += 1\n",
        "            self.budget_manager.record_call(success=False, prompt=prompt, response=\"\")\n",
        "            raise\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.budget_manager.record_call(success=False, prompt=prompt, response=\"\")\n",
        "            self.metrics[\"requests_failed\"] += 1\n",
        "            raise\n",
        "    \n",
        "    def process_batch(self, prompt_tasks):\n",
        "        \"\"\"\n",
        "        Process a batch of (prompt, task_type) tuples.\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        \n",
        "        def process_single(prompt_task):\n",
        "            prompt, task_type = prompt_task\n",
        "            self.metrics[\"requests_attempted\"] += 1\n",
        "            start_time = time.time()\n",
        "            \n",
        "            try:\n",
        "                result = self._make_single_request(prompt, task_type)\n",
        "                duration = time.time() - start_time\n",
        "                self.metrics[\"total_response_time\"] += duration\n",
        "                \n",
        "                return {\n",
        "                    \"prompt\": prompt,\n",
        "                    \"task_type\": task_type,\n",
        "                    \"result\": result,\n",
        "                    \"success\": True,\n",
        "                    \"duration\": duration,\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                }\n",
        "            except Exception as e:\n",
        "                duration = time.time() - start_time\n",
        "                self.metrics[\"total_response_time\"] += duration\n",
        "                \n",
        "                return {\n",
        "                    \"prompt\": prompt,\n",
        "                    \"task_type\": task_type,\n",
        "                    \"error\": str(e),\n",
        "                    \"success\": False,\n",
        "                    \"duration\": duration,\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                }\n",
        "        \n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            futures = {executor.submit(process_single, pt): pt for pt in prompt_tasks}\n",
        "            \n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                results.append(future.result())\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def get_metrics(self):\n",
        "        total_attempted = self.metrics[\"requests_attempted\"]\n",
        "        if total_attempted > 0:\n",
        "            success_rate = (self.metrics[\"requests_successful\"] / total_attempted) * 100\n",
        "            failure_rate = (self.metrics[\"requests_failed\"] / total_attempted) * 100\n",
        "            avg_response_time = self.metrics[\"total_response_time\"] / total_attempted\n",
        "        else:\n",
        "            success_rate = failure_rate = avg_response_time = 0\n",
        "        \n",
        "        return {\n",
        "            **self.metrics,\n",
        "            \"success_rate_percent\": success_rate,\n",
        "            \"failure_rate_percent\": failure_rate,\n",
        "            \"avg_response_time_seconds\": avg_response_time\n",
        "        }\n",
        "\n",
        "# Create a comprehensive test with GPT-5-Mini\n",
        "comprehensive_budget = BudgetManager(daily_budget=5.0, cost_per_1k_tokens=0.0015)\n",
        "reliable_client = ReliableAIClient(comprehensive_budget, max_workers=4)\n",
        "\n",
        "# Create a diverse set of test tasks\n",
        "comprehensive_test_batch = [\n",
        "    (\"Summarize the key principles of sustainable development.\", \"analysis\"),\n",
        "    (\"Write a creative story about a time-traveling scientist.\", \"creative\"),\n",
        "    (\"Explain how blockchain technology works.\", \"technical\"),\n",
        "    (\"Compare and contrast different programming paradigms.\", \"technical\"),\n",
        "    (\"Create a motivational speech for entrepreneurs.\", \"creative\"),\n",
        "    (\"Analyze the impact of social media on society.\", \"analysis\"),\n",
        "    (\"Describe the process of cellular respiration.\", \"technical\"),\n",
        "    (\"Write a dialogue between a customer and support agent.\", \"creative\"),\n",
        "    (\"Evaluate the pros and cons of electric vehicles.\", \"analysis\"),\n",
        "    (\"Explain the concept of quantum entanglement simply.\", \"technical\")\n",
        "]\n",
        "\n",
        "print(\"üöÄ Running comprehensive reliability test with GPT-5-Mini...\\n\")\n",
        "print(f\"Processing {len(comprehensive_test_batch)} diverse AI tasks...\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "batch_results = reliable_client.process_batch(comprehensive_test_batch)\n",
        "end_time = time.time()\n",
        "\n",
        "# Analyze results\n",
        "successful_results = [r for r in batch_results if r[\"success\"]]\n",
        "failed_results = [r for r in batch_results if not r[\"success\"]]\n",
        "\n",
        "print(f\"\\nüîç Comprehensive Test Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total processing time: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"‚úÖ Successful requests: {len(successful_results)}\")\n",
        "print(f\"‚ùå Failed requests: {len(failed_results)}\")\n",
        "\n",
        "# Show sample results by task type\n",
        "if successful_results:\n",
        "    print(\"\\nüìã Sample Results by Task Type:\")\n",
        "    task_types = set(r['task_type'] for r in successful_results)\n",
        "    for task_type in task_types:\n",
        "        task_results = [r for r in successful_results if r['task_type'] == task_type]\n",
        "        if task_results:\n",
        "            sample = task_results[0]\n",
        "            print(f\"\\n  [{task_type.upper()}] Sample Response:\")\n",
        "            print(f\"  Prompt: {sample['prompt'][:60]}...\")\n",
        "            print(f\"  Response: {sample['result']['result'][:120]}...\")\n",
        "\n",
        "# Print client metrics\n",
        "print(\"\\nüìà Client Performance Metrics:\")\n",
        "print(\"=\" * 50)\n",
        "metrics = reliable_client.get_metrics()\n",
        "for key, value in metrics.items():\n",
        "    if \"percent\" in key:\n",
        "        print(f\"{key}: {value:.1f}%\")\n",
        "    elif \"time\" in key and \"seconds\" in key:\n",
        "        print(f\"{key}: {value:.3f}s\")\n",
        "    elif isinstance(value, float):\n",
        "        print(f\"{key}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "# Print final budget report\n",
        "print(\"\\nüí∞ Final Budget Report:\")\n",
        "print(\"=\" * 50)\n",
        "final_report = comprehensive_budget.get_usage_report()\n",
        "for key, value in final_report.items():\n",
        "    if isinstance(value, float):\n",
        "        if 'percent' in key or 'rate' in key:\n",
        "            print(f\"{key}: {value:.1f}%\")\n",
        "        elif 'cost' in key:\n",
        "            print(f\"{key}: ${value:.4f}\")\n",
        "        else:\n",
        "            print(f\"{key}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This demo covered key reliability patterns for production AI applications using **GPT-5-Mini via AskSage**:\n",
        "\n",
        "### üîÑ **Retries with Jitter**\n",
        "- Exponential backoff prevents thundering herd problems\n",
        "- Jitter adds randomization to distribute retry attempts\n",
        "- Selective retry logic for different error types\n",
        "- Applied to GPT-5-Mini API calls through AskSage\n",
        "\n",
        "### ‚è∞ **Timeout Management**\n",
        "- Prevents hanging operations during AI processing\n",
        "- Maintains system responsiveness\n",
        "- Configurable timeout durations for different task types\n",
        "\n",
        "### üöÄ **Concurrency Control**\n",
        "- Thread pool management for parallel AI processing\n",
        "- Rate limiting to respect AskSage API constraints\n",
        "- Resource management and cleanup\n",
        "- Efficient handling of multiple AI task types\n",
        "\n",
        "### üí∞ **Budget Caps**\n",
        "- Real-time cost tracking based on token usage\n",
        "- GPT-5-Mini specific pricing considerations\n",
        "- Usage metrics and detailed reporting\n",
        "- Automatic request blocking when limits reached\n",
        "\n",
        "### üõ°Ô∏è **Comprehensive Reliability**\n",
        "- Integration of all reliability patterns\n",
        "- Detailed metrics and monitoring for AI operations\n",
        "- Production-ready error handling for AskSage integration\n",
        "- Support for different AI task types (analysis, creative, technical)\n",
        "\n",
        "### ü§ñ **GPT-5-Mini Integration**\n",
        "- AskSage client setup and configuration\n",
        "- Model-specific prompt engineering\n",
        "- Token estimation and cost calculation\n",
        "- Task-type specific system prompts\n",
        "\n",
        "These patterns are essential for building robust, cost-effective AI applications that can handle real-world failures and constraints gracefully while leveraging the power of GPT-5-Mini through the AskSage platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final verification - test AskSage connection and available models\n",
        "print(\"üîç Final System Verification\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "try:\n",
        "    # Check AskSage connection\n",
        "    models = ask_sage_client.get_models()\n",
        "    if 'response' in models:\n",
        "        available_models = models['response']\n",
        "        print(f\"‚úÖ Connected to AskSage successfully\")\n",
        "        print(f\"üìã Total available models: {len(available_models)}\")\n",
        "        \n",
        "        # Check for GPT-5-Mini specifically\n",
        "        gpt5_models = [m for m in available_models if 'gpt-5' in m.lower()]\n",
        "        if gpt5_models:\n",
        "            print(f\"üéØ GPT-5 models found: {gpt5_models}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  GPT-5-Mini not found. Consider using gpt-4o-mini or gpt-4o instead.\")\n",
        "            gpt4_models = [m for m in available_models if 'gpt-4' in m.lower()]\n",
        "            if gpt4_models:\n",
        "                print(f\"üîÑ Alternative GPT-4 models: {gpt4_models[:5]}\")\n",
        "                \n",
        "    # Summary of reliability features implemented\n",
        "    print(\"\\nüõ°Ô∏è Reliability Features Implemented:\")\n",
        "    features = [\n",
        "        \"‚úÖ Retry mechanisms with exponential backoff and jitter\",\n",
        "        \"‚úÖ Timeout protection for AI operations\", \n",
        "        \"‚úÖ Concurrent request management with rate limiting\",\n",
        "        \"‚úÖ Budget tracking and cost monitoring\",\n",
        "        \"‚úÖ Comprehensive error handling and metrics\",\n",
        "        \"‚úÖ AskSage integration with model selection\",\n",
        "        \"‚úÖ Task-type specific prompt engineering\"\n",
        "    ]\n",
        "    \n",
        "    for feature in features:\n",
        "        print(f\"  {feature}\")\n",
        "    \n",
        "    print(\"\\nüéâ Reliability demo setup complete!\")\n",
        "    print(\"üí° Ready for production AI applications with GPT-5-Mini via AskSage\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error during final verification: {e}\")\n",
        "    print(\"üîß Please check your AskSage credentials and connection\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}