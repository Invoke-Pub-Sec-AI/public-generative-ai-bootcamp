{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 6: Build a Prompt Library\n",
        "\n",
        "## Learning Objectives\n",
        "- Create a reusable library of battle-tested prompts\n",
        "- Implement prompt templates with variable substitution\n",
        "- Build validation and testing frameworks for prompts\n",
        "- Design prompt versioning and management systems\n",
        "\n",
        "## Lab Overview\n",
        "You'll build a comprehensive prompt library system that stores, manages, and validates prompts for common tasks. This becomes your \"prompt arsenal\" for future projects.\n",
        "\n",
        "**Estimated Time:** 60 minutes\n",
        "\n",
        "## Your Mission\n",
        "Create a production-ready prompt library with templates, validation, and performance tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install jinja2 pydantic rich jsonlines pyyaml tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# üîê Cell 1 ‚Äî Load secrets (Colab) + pricing + token utils\n",
        "# ================================\n",
        "import os, time, csv\n",
        "from typing import Optional, Dict\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "ASKSAGE_API_KEY = userdata.get(\"ASKSAGE_API_KEY\")\n",
        "ASKSAGE_BASE_URL = userdata.get(\"ASKSAGE_BASE_URL\")\n",
        "ASKSAGE_EMAIL = userdata.get(\"ASKSAGE_EMAIL\")\n",
        "\n",
        "\n",
        "\n",
        "assert ASKSAGE_API_KEY, \"ASKSAGE_API_KEY not provided.\"\n",
        "assert ASKSAGE_EMAIL, \"ASKSAGE_EMAIL not provided.\"\n",
        "\n",
        "\n",
        "print(\"‚úì Secrets loaded\")\n",
        "print(\"  ‚Ä¢ EMAIL:\", ASKSAGE_EMAIL)\n",
        "print(\"  ‚Ä¢ BASE URL:\", ASKSAGE_BASE_URL or \"(default)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../../../')  # Adjust path to reach bootcamp_common\n",
        "\n",
        "from bootcamp_common.ask_sage import AskSageClient\n",
        "\n",
        "# Initialize AskSage client\n",
        "client = AskSageClient(\n",
        "    api_key=ASKSAGE_API_KEY,\n",
        "    base_url=ASKSAGE_BASE_URL\n",
        ")\n",
        "\n",
        "print(\"‚úì AskSage client initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Design Prompt Template System\n",
        "\n",
        "**TODO:** Create a flexible prompt template system with validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, ValidationError, Field, validator\n",
        "from jinja2 import Template\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "class PromptTemplate(BaseModel):\n",
        "    \"\"\"Structured prompt template with validation\"\"\"\n",
        "    id: str\n",
        "    name: str\n",
        "    description: str\n",
        "    category: str\n",
        "    template: str\n",
        "    variables: List[str]\n",
        "    system_message: Optional[str] = None\n",
        "    examples: List[Dict[str, str]] = []\n",
        "    tags: List[str] = []\n",
        "    version: str = \"1.0\"\n",
        "    author: str = \"bootcamp\"\n",
        "    created_at: str = None\n",
        "    performance_metrics: Dict[str, float] = {}\n",
        "\n",
        "@dataclass\n",
        "class PromptExecution:\n",
        "    \"\"\"Record of prompt execution with metadata\"\"\"\n",
        "    template_id: str\n",
        "    variables: Dict[str, Any]\n",
        "    rendered_prompt: str\n",
        "    response: str\n",
        "    success: bool\n",
        "    response_time: float\n",
        "    token_count: int\n",
        "    cost: float\n",
        "    timestamp: str\n",
        "\n",
        "class PromptLibrary:\n",
        "    \"\"\"Main prompt library management system\"\"\"\n",
        "    \n",
        "    def __init__(self, library_path: str = \"prompt_library\"):\n",
        "        self.library_path = Path(library_path)\n",
        "        self.library_path.mkdir(exist_ok=True)\n",
        "        self.templates: Dict[str, PromptTemplate] = {}\n",
        "        self.execution_log: List[PromptExecution] = []\n",
        "        self._load_templates()\n",
        "        \n",
        "    def _load_templates(self):\n",
        "        \"\"\"Load templates from YAML files\"\"\"\n",
        "        for yaml_file in self.library_path.glob(\"*.yaml\"):\n",
        "            try:\n",
        "                with open(yaml_file, 'r') as f:\n",
        "                    template_data = yaml.safe_load(f)\n",
        "                template = PromptTemplate(**template_data)\n",
        "                self.templates[template.id] = template\n",
        "            except Exception as e:\n",
        "                console.print(f\"[red]Error loading {yaml_file}: {e}[/red]\")\n",
        "        \n",
        "        # Create starter templates if none exist\n",
        "        if not self.templates:\n",
        "            self._create_starter_templates()\n",
        "    \n",
        "    def _create_starter_templates(self):\n",
        "        \"\"\"Create basic starter templates\"\"\"\n",
        "        starter_templates = [\n",
        "            {\n",
        "                \"id\": \"text_summarizer\",\n",
        "                \"name\": \"Text Summarizer\",\n",
        "                \"description\": \"Summarize text with specified length and style\",\n",
        "                \"category\": \"text_processing\",\n",
        "                \"template\": \"\"\"Summarize the following text in {{ max_words }} words or less.\n",
        "Style: {{ style }}\n",
        "Focus on: {{ focus_areas }}\n",
        "\n",
        "Text:\n",
        "{{ text }}\n",
        "\n",
        "Summary:\"\"\",\n",
        "                \"variables\": [\"text\", \"max_words\", \"style\", \"focus_areas\"],\n",
        "                \"examples\": [\n",
        "                    {\n",
        "                        \"text\": \"Long article about AI trends...\",\n",
        "                        \"max_words\": \"50\",\n",
        "                        \"style\": \"bullet points\",\n",
        "                        \"focus_areas\": \"key developments and future outlook\"\n",
        "                    }\n",
        "                ],\n",
        "                \"tags\": [\"summarization\", \"text_processing\"],\n",
        "                \"created_at\": datetime.now().isoformat()\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"email_classifier\",\n",
        "                \"name\": \"Email Classifier\",\n",
        "                \"description\": \"Classify emails by priority and category\",\n",
        "                \"category\": \"classification\",\n",
        "                \"template\": \"\"\"Classify this email:\n",
        "\n",
        "Email: {{ email_content }}\n",
        "\n",
        "Priority: [urgent/normal/low]\n",
        "Category: [work/personal/spam/newsletter]\n",
        "Reasoning:\"\"\",\n",
        "                \"variables\": [\"email_content\"],\n",
        "                \"tags\": [\"classification\", \"email\"],\n",
        "                \"created_at\": datetime.now().isoformat()\n",
        "            }\n",
        "        ]\n",
        "        \n",
        "        for template_data in starter_templates:\n",
        "            template = PromptTemplate(**template_data)\n",
        "            self.templates[template.id] = template\n",
        "            self.save_template(template)\n",
        "    \n",
        "    def add_template(self, template_data: Dict) -> str:\n",
        "        \"\"\"Add new template to library\"\"\"\n",
        "        try:\n",
        "            template_data[\"created_at\"] = datetime.now().isoformat()\n",
        "            template = PromptTemplate(**template_data)\n",
        "            self.templates[template.id] = template\n",
        "            self.save_template(template)\n",
        "            return template.id\n",
        "        except ValidationError as e:\n",
        "            console.print(f\"[red]Template validation error: {e}[/red]\")\n",
        "            return None\n",
        "    \n",
        "    def get_template(self, template_id: str) -> Optional[PromptTemplate]:\n",
        "        \"\"\"Retrieve template by ID\"\"\"\n",
        "        return self.templates.get(template_id)\n",
        "    \n",
        "    def render_prompt(self, template_id: str, variables: Dict[str, Any]) -> str:\n",
        "        \"\"\"Render template with variables using Jinja2\"\"\"\n",
        "        template = self.get_template(template_id)\n",
        "        if not template:\n",
        "            raise ValueError(f\"Template {template_id} not found\")\n",
        "        \n",
        "        # Validate required variables\n",
        "        missing_vars = set(template.variables) - set(variables.keys())\n",
        "        if missing_vars:\n",
        "            raise ValueError(f\"Missing required variables: {missing_vars}\")\n",
        "        \n",
        "        jinja_template = Template(template.template)\n",
        "        return jinja_template.render(**variables)\n",
        "    \n",
        "    # TODO: Implement validate_template() function\n",
        "    # This function should:\n",
        "    # - Check required fields are present\n",
        "    # - Validate Jinja2 template syntax\n",
        "    # - Verify variable consistency between template and variables list\n",
        "    # - Validate examples match template variables\n",
        "    # - Return list of validation errors\n",
        "    \n",
        "    def save_template(self, template: PromptTemplate):\n",
        "        \"\"\"Save template to disk as YAML\"\"\"\n",
        "        file_path = self.library_path / f\"{template.id}.yaml\"\n",
        "        template_dict = template.dict()\n",
        "        with open(file_path, 'w') as f:\n",
        "            yaml.dump(template_dict, f, default_flow_style=False)\n",
        "    \n",
        "    # TODO: Implement execute_template() function\n",
        "    # This function should:\n",
        "    # - Render the template with provided variables\n",
        "    # - Use client.query() to get AI response\n",
        "    # - Track execution time, tokens, and cost\n",
        "    # - Store execution record in self.execution_log\n",
        "    # - Return PromptExecution object\n",
        "\n",
        "# Initialize library\n",
        "library = PromptLibrary()\n",
        "console.print(f\"üìö Prompt library initialized with {len(library.templates)} templates\")\n",
        "console.print(\"‚ö†Ô∏è TODO: Complete validate_template() and execute_template() functions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Build Template Browser and Search\n",
        "\n",
        "**TODO:** Create tools to browse, search, and discover templates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Build Template Browser and Search\n",
        "#\n",
        "# Your task:\n",
        "# 1. Create browse_templates() function with rich table display\n",
        "# 2. Implement search_templates() with multi-field search\n",
        "# 3. Build show_template_details() for detailed template view\n",
        "# 4. Create create_template_tree() for hierarchical category view\n",
        "# 5. Add filtering by category, tags, and performance metrics\n",
        "#\n",
        "# Features to implement:\n",
        "# - Rich table display with ID, name, category, variables, tags\n",
        "# - Search across name, description, tags, and content\n",
        "# - Detailed template panels with examples and metadata\n",
        "# - Tree view organized by categories\n",
        "# - Performance-based recommendations\n",
        "# - Fuzzy matching for better search results\n",
        "#\n",
        "# Integration with AskSage:\n",
        "# - Preview template execution with sample data\n",
        "# - Show estimated costs for template usage\n",
        "# - Display performance metrics from previous runs\n",
        "\n",
        "print(\"‚ö†Ô∏è TODO: Implement template browser and search functionality\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Create Template Testing Framework\n",
        "\n",
        "**TODO:** Build a system to test and validate prompt templates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PromptTester:\n",
        "    \"\"\"Test prompt templates for quality and performance\"\"\"\n",
        "    \n",
        "    def __init__(self, library: PromptLibrary):\n",
        "        self.library = library\n",
        "        self.setup_client()\n",
        "    \n",
        "    def setup_client(self):\n",
        "        \"\"\"Setup API client\"\"\"\n",
        "        self.has_api = os.getenv('OPENAI_API_KEY') is not None\n",
        "        if self.has_api:\n",
        "            import openai\n",
        "            self.client = openai.OpenAI()\n",
        "            console.print(\"‚úÖ API client configured\")\n",
        "        else:\n",
        "            console.print(\"üí° Using mock responses for testing\")\n",
        "    \n",
        "    def test_template(self, template_id: str, test_variables: Dict[str, Any]) -> PromptExecution:\n",
        "        \"\"\"TODO: Test a template with given variables\"\"\"\n",
        "        template = self.library.get_template(template_id)\n",
        "        if not template:\n",
        "            raise ValueError(f\"Template {template_id} not found\")\n",
        "        \n",
        "        # TODO: Render prompt with test variables\n",
        "        # TODO: Execute prompt via API or mock\n",
        "        # TODO: Measure performance metrics\n",
        "        # TODO: Return execution record\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        rendered_prompt = self.library.render_prompt(template_id, test_variables)\n",
        "        \n",
        "        if self.has_api:\n",
        "            # TODO: Make actual API call\n",
        "            response = \"API response here\"\n",
        "            token_count = 50\n",
        "        else:\n",
        "            # Mock response\n",
        "            response = f\"Mock response for {template_id} with variables: {test_variables}\"\n",
        "            token_count = len(response.split())\n",
        "        \n",
        "        execution = PromptExecution(\n",
        "            template_id=template_id,\n",
        "            variables=test_variables,\n",
        "            rendered_prompt=rendered_prompt,\n",
        "            response=response,\n",
        "            success=True,\n",
        "            response_time=time.time() - start_time,\n",
        "            token_count=token_count,\n",
        "            timestamp=datetime.now().isoformat()\n",
        "        )\n",
        "        \n",
        "        self.library.execution_log.append(execution)\n",
        "        return execution\n",
        "    \n",
        "    def run_template_tests(self, template_id: str) -> List[PromptExecution]:\n",
        "        \"\"\"TODO: Run all example tests for a template\"\"\"\n",
        "        template = self.library.get_template(template_id)\n",
        "        if not template:\n",
        "            raise ValueError(f\"Template {template_id} not found\")\n",
        "        \n",
        "        results = []\n",
        "        \n",
        "        # TODO: Run tests using template examples\n",
        "        # TODO: Validate outputs meet expectations\n",
        "        # TODO: Generate test report\n",
        "        \n",
        "        for example in template.examples:\n",
        "            try:\n",
        "                result = self.test_template(template_id, example)\n",
        "                results.append(result)\n",
        "            except Exception as e:\n",
        "                console.print(f\"[red]Test failed: {e}[/red]\")\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def benchmark_template(self, template_id: str, iterations: int = 5) -> Dict[str, float]:\n",
        "        \"\"\"TODO: Benchmark template performance\"\"\"\n",
        "        # TODO: Run template multiple times\n",
        "        # TODO: Calculate average metrics\n",
        "        # TODO: Return performance statistics\n",
        "        \n",
        "        metrics = {\n",
        "            \"avg_response_time\": 0.0,\n",
        "            \"avg_token_count\": 0.0,\n",
        "            \"success_rate\": 0.0,\n",
        "            \"consistency_score\": 0.0\n",
        "        }\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    def validate_template_quality(self, template_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"TODO: Assess template quality across multiple dimensions\"\"\"\n",
        "        quality_report = {\n",
        "            \"clarity_score\": 0.0,        # How clear are the instructions?\n",
        "            \"completeness_score\": 0.0,   # Are all necessary elements present?\n",
        "            \"consistency_score\": 0.0,    # Does it produce consistent outputs?\n",
        "            \"efficiency_score\": 0.0,     # Token usage efficiency\n",
        "            \"overall_score\": 0.0,\n",
        "            \"recommendations\": []\n",
        "        }\n",
        "        \n",
        "        # TODO: Implement quality scoring algorithms\n",
        "        # TODO: Analyze template structure and content\n",
        "        # TODO: Generate improvement recommendations\n",
        "        \n",
        "        return quality_report\n",
        "\n",
        "# Initialize tester\n",
        "tester = PromptTester(library)\n",
        "print(\"üß™ Template tester ready!\")\n",
        "print(\"‚ö†Ô∏è TODO: Complete the testing and validation methods above\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4: Demonstrate Library Usage\n",
        "\n",
        "**TODO:** Show how to use your prompt library system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Demonstrate library usage\n",
        "\n",
        "console.print(\"\\nüìö [bold blue]Prompt Library Demonstration[/bold blue]\")\n",
        "\n",
        "# 1. Browse available templates\n",
        "console.print(\"\\n[yellow]1. Available Templates:[/yellow]\")\n",
        "console.print(browser.list_templates())\n",
        "\n",
        "# 2. Show template details\n",
        "console.print(\"\\n[yellow]2. Template Details:[/yellow]\")\n",
        "# TODO: Show details for an existing template\n",
        "if \"text_summarizer\" in library.templates:\n",
        "    browser.show_template_details(\"text_summarizer\")\n",
        "\n",
        "# 3. Test a template\n",
        "console.print(\"\\n[yellow]3. Testing Template:[/yellow]\")\n",
        "# TODO: Test the template with sample data\n",
        "test_vars = {\n",
        "    \"text\": \"Artificial intelligence is rapidly transforming industries...\",\n",
        "    \"max_words\": \"30\",\n",
        "    \"style\": \"professional\",\n",
        "    \"focus_areas\": \"business impact\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    result = tester.test_template(\"text_summarizer\", test_vars)\n",
        "    console.print(f\"[green]‚úÖ Test successful![/green]\")\n",
        "    console.print(Panel(result.response, title=\"Generated Response\", border_style=\"green\"))\n",
        "    console.print(f\"Response time: {result.response_time:.2f}s, Tokens: {result.token_count}\")\n",
        "except Exception as e:\n",
        "    console.print(f\"[red]‚ùå Test failed: {e}[/red]\")\n",
        "\n",
        "print(\"\\nüìä Library demonstration complete!\")\n",
        "print(\"‚ö†Ô∏è TODO: Add more templates and improve the demonstration\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 5: Create Your Custom Templates\n",
        "\n",
        "**TODO:** Design and add 3-5 custom templates for different use cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create custom templates for your prompt library\n",
        "\n",
        "def create_custom_templates():\n",
        "    \"\"\"TODO: Design and add custom prompt templates\"\"\"\n",
        "    \n",
        "    # TODO: Create templates for:\n",
        "    # 1. Code review and feedback\n",
        "    # 2. Meeting notes extraction\n",
        "    # 3. Creative story generation\n",
        "    # 4. Technical documentation\n",
        "    # 5. Email response drafting\n",
        "    \n",
        "    custom_templates = [\n",
        "        # TODO: Define your custom templates here\n",
        "        # Use the same structure as the starter templates\n",
        "        {\n",
        "            \"id\": \"code_reviewer\",\n",
        "            \"name\": \"Code Review Assistant\",\n",
        "            \"description\": \"TODO: Add description\",\n",
        "            \"category\": \"development\",\n",
        "            \"template\": \"\"\"TODO: Design your code review template\n",
        "            \n",
        "            Should include:\n",
        "            - Code quality assessment\n",
        "            - Security considerations\n",
        "            - Performance suggestions\n",
        "            - Best practice recommendations\n",
        "            \"\"\",\n",
        "            \"variables\": [\"code\", \"language\", \"review_focus\"],\n",
        "            \"examples\": [\n",
        "                # TODO: Add example usage\n",
        "            ],\n",
        "            \"tags\": [\"code_review\", \"development\"]\n",
        "        },\n",
        "        # TODO: Add more custom templates\n",
        "    ]\n",
        "    \n",
        "    # TODO: Add templates to library\n",
        "    for template_data in custom_templates:\n",
        "        # library.add_template(template_data)\n",
        "        pass\n",
        "    \n",
        "    console.print(f\"[green]Added {len(custom_templates)} custom templates to library[/green]\")\n",
        "\n",
        "# TODO: Run the function to add your templates\n",
        "# create_custom_templates()\n",
        "\n",
        "print(\"üé® Custom template creation ready!\")\n",
        "print(\"‚ö†Ô∏è TODO: Design and implement your custom prompt templates\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exit Ticket\n",
        "\n",
        "Before completing this lab, make sure you can answer:\n",
        "\n",
        "### ‚úÖ Deliverables Checklist\n",
        "\n",
        "- [ ] **Built template management system**: Add, store, and retrieve prompt templates\n",
        "- [ ] **Implemented template browser**: Search and discover templates by category/tags\n",
        "- [ ] **Created testing framework**: Validate templates with examples and benchmarks\n",
        "- [ ] **Added 3+ custom templates**: Templates for different domains/use cases\n",
        "- [ ] **Demonstrated end-to-end workflow**: From template creation to testing and usage\n",
        "\n",
        "### üß† Knowledge Check\n",
        "\n",
        "1. **How do you ensure template quality?** What validation should you implement?\n",
        "\n",
        "2. **When would you version a template?** What changes require a new version?\n",
        "\n",
        "3. **How do you organize templates for a team?** What metadata is most important?\n",
        "\n",
        "4. **What makes a good template?** Balance between flexibility and specificity?\n",
        "\n",
        "### üöÄ Extensions (Optional)\n",
        "\n",
        "- **Template inheritance**: Base templates that others can extend\n",
        "- **A/B testing**: Compare template versions automatically\n",
        "- **Performance analytics**: Track usage patterns and success rates\n",
        "- **Team collaboration**: Sharing and reviewing templates\n",
        "- **Template marketplace**: Import templates from external sources\n",
        "\n",
        "### üìä Success Metrics\n",
        "\n",
        "- Built working prompt library with 5+ templates\n",
        "- Implemented search and browsing capabilities\n",
        "- Created validation and testing framework\n",
        "- Designed templates covering multiple domains\n",
        "- Demonstrated template reuse and customization\n",
        "\n",
        "**Time Check:** This lab should take about 60 minutes. Focus on getting core functionality working before adding advanced features.\n",
        "\n",
        "Ready for Lab 7: Structured Output? Let's build reliable JSON pipelines! üîß"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}