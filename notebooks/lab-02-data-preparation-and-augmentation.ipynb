{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "a6cae1ec9267461192a2ff68228e63e4",
      "metadata": {},
      "source": [
        "# Lab 02: Data Preparation and Augmentation for Fine-Tuning\n",
        "\n",
        "## Learning Objectives\n",
        "- Format datasets for different fine-tuning tasks (e.g., instruction-following, chat)\n",
        "- Implement data cleaning techniques to improve data quality\n",
        "- Apply data augmentation strategies to increase dataset size and diversity\n",
        "- Understand how to handle class imbalance in classification tasks\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf71c9e97a7469fb6cc5ec78ea0c9e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import random\n",
        "from typing import List, Dict, Any\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a79031031176496cb17dc2b4915c2feb",
      "metadata": {},
      "source": [
        "## Part 1: Data Formatting\n",
        "\n",
        "The format of your training data must match the task. Different tasks require different structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e06df14b157d4dbaaeaf9503fbd40fcb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instruction-following format (e.g., Alpaca style)\n",
        "def format_instruction(instruction: str, input_text: str, output: str) -> Dict[str, str]:\n",
        "    template = (\n",
        "        f\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "        f\"Write a response that appropriately completes the request.\\\n",
        "\\\n",
        "\"\n",
        "        f\"### Instruction:\\\n",
        "{instruction}\\\n",
        "\\\n",
        "\"\n",
        "        f\"### Input:\\\n",
        "{input_text}\\\n",
        "\\\n",
        "\"\n",
        "        f\"### Response:\\\n",
        "{output}\"\n",
        "    )\n",
        "    return {\"text\": template.format(instruction=instruction, input_text=input_text, output=output)}\n",
        "instruction_example = format_instruction(\n",
        "    instruction=\"Translate the following English text to French.\",\n",
        "    input_text=\"Hello, how are you?\",\n",
        "    output=\"Bonjour, comment Ã§a va?\"\n",
        ")\n",
        "print(\"--- Instruction-Following Format ---\")\n",
        "print(instruction_example['text'])\n",
        "\n",
        "# Chat format (e.g., OpenAI's format)\n",
        "def format_chat(messages: List[Dict[str, str]]) -> Dict[str, List[Dict[str, str]]]:\n",
        "    return {\"messages\": messages}\n",
        "\n",
        "chat_example = format_chat([\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"}\n",
        "])\n",
        "print(\"\n",
        "--- Chat Format ---\")\n",
        "print(json.dumps(chat_example, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a4118e7c6040a4b520303b7be91d7b",
      "metadata": {},
      "source": [
        "## Part 2: Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ad541b7397742e4bd7329867829a0ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample of messy data\n",
        "messy_data = [\n",
        "    {\"prompt\": \"  What is 2+2?  \", \"completion\": \"4.  \"},\n",
        "    {\"prompt\": \"who is the first president of the USA?\", \"completion\": \"george washington\"},\n",
        "    {\"prompt\": \"Remove this part [REMOVE] and this\", \"completion\": \"This is good\"},\n",
        "    {\"prompt\": \"\", \"completion\": \"Empty prompt is bad\"},\n",
        "]\n",
        "\n",
        "def clean_data(dataset: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
        "    cleaned = []\n",
        "    for item in dataset:\n",
        "        prompt = item['prompt'].strip()\n",
        "        completion = item['completion'].strip()\n",
        "        \n",
        "        # Rule 1: Remove empty prompts or completions\n",
        "        if not prompt or not completion:\n",
        "            continue\n",
        "            \n",
        "        # Rule 2: Normalize case (example: capitalize completions)\n",
        "        if 'president' in prompt:\n",
        "            completion = completion.title()\n",
        "            \n",
        "        # Rule 3: Remove unwanted artifacts\n",
        "        prompt = re.sub(r'[REMOVE].*', '', prompt).strip()\n",
        "        \n",
        "        cleaned.append({\"prompt\": prompt, \"completion\": completion})\n",
        "    return cleaned\n",
        "\n",
        "cleaned_dataset = clean_data(messy_data)\n",
        "print(\"--- Cleaned Dataset ---\")\n",
        "print(json.dumps(cleaned_dataset, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5129b347ffb2458bae5d9cca254073c9",
      "metadata": {},
      "source": [
        "## Part 3: Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1575d53426144659e39317042a4e30c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Augmentation technique: Paraphrasing (mocked)\n",
        "def paraphrase(text: str) -> str:\n",
        "    # In a real system, you would use a model for this.\n",
        "    # Here, we'll just add a synonym or rephrase slightly.\n",
        "    paraphrases = {\n",
        "        \"What is the capital of France?\": \"Which city is the capital of France?\",\n",
        "        \"Tell me about photosynthesis.\": \"Explain the process of photosynthesis.\"\n",
        "    }\n",
        "    return paraphrases.get(text, text) # Return original if no paraphrase is defined\n",
        "\n",
        "# Augmentation technique: Back-Translation (mocked)\n",
        "def back_translate(text: str, lang_a='en', lang_b='fr') -> str:\n",
        "    # Mock translation: en -> fr -> en\n",
        "    # This simulates using a translation service to get a paraphrased version.\n",
        "    mock_fr = {\"Hello world\": \"Bonjour le monde\"}\n",
        "    mock_en = {\"Bonjour le monde\": \"Hi Earth\"}\n",
        "    translated = mock_fr.get(text, text)\n",
        "    back_translated = mock_en.get(translated, text)\n",
        "    return back_translated\n",
        "\n",
        "original_prompts = [\n",
        "    {\"prompt\": \"What is the capital of France?\", \"completion\": \"Paris\"},\n",
        "    {\"prompt\": \"Hello world\", \"completion\": \"Hi!\"}\n",
        "]\n",
        "\n",
        "augmented_data = []\n",
        "for item in original_prompts:\n",
        "    augmented_data.append(item) # Add original\n",
        "    # Add paraphrased version\n",
        "    augmented_data.append({\"prompt\": paraphrase(item['prompt']), \"completion\": item['completion']})\n",
        "    # Add back-translated version\n",
        "    augmented_data.append({\"prompt\": back_translate(item['prompt']), \"completion\": item['completion']})\n",
        "\n",
        "print(\"--- Augmented Dataset ---\")\n",
        "print(json.dumps(augmented_data, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d804b996b5384759bffe8bb9fdcf70d1",
      "metadata": {},
      "source": [
        "## Part 4: Handling Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e9e3dcb93fe4a12853bf14628c4e275",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imbalanced dataset for a classification task\n",
        "imbalanced_classification_data = [\n",
        "    {\"text\": \"This movie was amazing!\", \"label\": \"positive\"}, # 10 positive\n",
        "    {\"text\": \"I loved it.\", \"label\": \"positive\"},\n",
        "    {\"text\": \"Best film ever.\", \"label\": \"positive\"},\n",
        "    {\"text\": \"So good.\", \"label\": \"positive\"},\n",
        "    {\"text\": \"Incredible.\", \"label\": \"positive\"},\n",
        "    {\"text\": \"Fantastic.\", \"label\": \"positive\"},\n",
        "    {\"text\": \"A masterpiece.\", \"label\": \"positive\"},\n",
        "    {\"text\": \"Highly recommended.\", \"label\": \"positive\"},\n",
        "    {\"text\": \"Superb.\", \"label\": \"positive\"},\n",
        "    {\"text\": \"Brilliant.\", \"label\": \"positive\"},\n",
        "    {\"text\": \"This was terrible.\", \"label\": \"negative\"}, # 2 negative\n",
        "    {\"text\": \"I hated it.\", \"label\": \"negative\"}\n",
        "]\n",
        "\n",
        "def balance_dataset(dataset: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Balances a dataset using over-sampling.\"\"\"\n",
        "    label_counts = Counter(item['label'] for item in dataset)\n",
        "    max_count = max(label_counts.values())\n",
        "    \n",
        "    balanced_data = []\n",
        "    for label, count in label_counts.items():\n",
        "        if count < max_count:\n",
        "            # Get all items for this label\n",
        "            items_for_label = [item for item in dataset if item['label'] == label]\n",
        "            # Oversample by choosing with replacement\n",
        "            oversampled_items = random.choices(items_for_label, k=max_count - count)\n",
        "            balanced_data.extend(oversampled_items)\n",
        "            \n",
        "    balanced_data.extend(dataset)\n",
        "    random.shuffle(balanced_data)\n",
        "    return balanced_data\n",
        "\n",
        "balanced_data = balance_dataset(imbalanced_classification_data)\n",
        "\n",
        "print(\"--- Class Imbalance Handling ---\")\n",
        "print(f'Original counts: {Counter(item['label'] for item in imbalanced_classification_data)}')\n",
        "print(f'Balanced counts: {Counter(item['label'] for item in balanced_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fefa99bc8db4013949693a5aaf60e9f",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "1. **Create a New Data Formatter**: Write a function to format data for a summarization task, with `{\"text\": \"<document>\", \"summary\": \"<summary>\"}` fields.\n",
        "2. **Add More Cleaning Rules**: Extend the `clean_data` function to handle other issues, such as removing URLs or standardizing punctuation.\n",
        "3. **Implement Under-sampling**: Write a function to balance the dataset by under-sampling the majority class instead of over-sampling the minority class. What are the pros and cons of this approach?\n",
        "\n",
        "## Summary\n",
        "\n",
        "You learned:\n",
        "- How to format data for common fine-tuning tasks.\n",
        "- The importance of cleaning data to remove noise and inconsistencies.\n",
        "- How to augment your dataset to improve model generalization.\n",
        "- A simple technique to handle class imbalance in classification datasets."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}