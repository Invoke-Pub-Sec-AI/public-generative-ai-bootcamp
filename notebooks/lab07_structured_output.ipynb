{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 7: Structured Output Pipeline\n",
        "\n",
        "## Learning Objectives\n",
        "- Build reliable JSON schema-based output pipelines\n",
        "- Implement robust error handling and retry logic\n",
        "- Create validation layers for structured data\n",
        "- Design production-ready data processing workflows\n",
        "\n",
        "## Lab Overview\n",
        "You'll build a complete structured output pipeline that extracts, validates, and processes data from unstructured text using AI models with guaranteed JSON output.\n",
        "\n",
        "**Estimated Time:** 60 minutes\n",
        "\n",
        "## Your Mission\n",
        "Create a resume parser that extracts structured information from job applications with validation and error recovery."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "!pip install asksageclient pip_system_certs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import tiktoken\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# Import our AskSage client\n",
        "from asksageclient import AskSageClient\n",
        "\n",
        "# Get API credentials from Google Colab secrets\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('ASKSAGE_API_KEY')\n",
        "email = userdata.get('ASKSAGE_EMAIL')\n",
        "\n",
        "# Initialize client and tokenizer\n",
        "client = AskSageClient(api_key=api_key, email=email)\n",
        "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "print(\"AskSage client initialized successfully\")\n",
        "print(\"Ready to showcase AI capabilities...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, time, csv\n",
        "from typing import Optional, Dict\n",
        "import tiktoken\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "ASKSAGE_API_KEY = userdata.get(\"ASKSAGE_API_KEY\")\n",
        "ASKSAGE_BASE_URL = userdata.get(\"ASKSAGE_BASE_URL\")\n",
        "ASKSAGE_EMAIL = userdata.get(\"ASKSAGE_EMAIL\")\n",
        "\n",
        "assert ASKSAGE_API_KEY, \"ASKSAGE_API_KEY not provided.\"\n",
        "assert ASKSAGE_EMAIL, \"ASKSAGE_EMAIL not provided.\"\n",
        "\n",
        "print(\"✓ Secrets loaded\")\n",
        "print(\"  • EMAIL:\", ASKSAGE_EMAIL)\n",
        "print(\"  • BASE URL:\", ASKSAGE_BASE_URL or \"(default)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Build Extraction Pipeline\n",
        "\n",
        "**TODO:** Create the core extraction pipeline with retry logic and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StructuredExtractor:\n",
        "    \"\"\"Extract structured data from unstructured text\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.setup_client()\n",
        "        self.extraction_stats = {\n",
        "            'total_attempts': 0,\n",
        "            'successful_extractions': 0,\n",
        "            'validation_errors': 0,\n",
        "            'parsing_errors': 0\n",
        "        }\n",
        "    \n",
        "    def setup_client(self):\n",
        "        \"\"\"Setup API client\"\"\"\n",
        "        self.has_api = os.getenv('OPENAI_API_KEY') is not None\n",
        "        if self.has_api:\n",
        "            import openai\n",
        "            self.client = openai.OpenAI()\n",
        "            console.print(\"✅ API client ready\")\n",
        "        else:\n",
        "            console.print(\"💡 Using mock responses\")\n",
        "    \n",
        "    def create_extraction_prompt(self, resume_text: str) -> str:\n",
        "        \"\"\"TODO: Create comprehensive extraction prompt\"\"\"\n",
        "        \n",
        "        # TODO: Design prompt that:\n",
        "        # 1. Clearly explains the task\n",
        "        # 2. Provides the JSON schema\n",
        "        # 3. Gives examples of expected output\n",
        "        # 4. Handles edge cases and missing data\n",
        "        \n",
        "        schema_example = ResumeData.model_json_schema()\n",
        "        \n",
        "        prompt = f\"\"\"TODO: Write comprehensive extraction prompt\n",
        "        \n",
        "        # Should include:\n",
        "        # - Clear task description\n",
        "        # - JSON schema specification\n",
        "        # - Instructions for handling missing data\n",
        "        # - Format requirements\n",
        "        \n",
        "        Resume text:\n",
        "        {resume_text}\n",
        "        \n",
        "        Extract as JSON:\n",
        "        \"\"\"\n",
        "        \n",
        "        return prompt\n",
        "    \n",
        "    @retry(\n",
        "        stop=stop_after_attempt(3),\n",
        "        wait=wait_exponential(multiplier=1, min=1, max=10)\n",
        "    )\n",
        "    def extract_with_retry(self, resume_text: str) -> Dict[str, Any]:\n",
        "        \"\"\"TODO: Extract data with automatic retry on failures\"\"\"\n",
        "        \n",
        "        self.extraction_stats['total_attempts'] += 1\n",
        "        \n",
        "        prompt = self.create_extraction_prompt(resume_text)\n",
        "        \n",
        "        if self.has_api:\n",
        "            # TODO: Make API call with structured output\n",
        "            response = \"{}\"  # Placeholder\n",
        "        else:\n",
        "            # Mock response with realistic resume data\n",
        "            response = '''{\n",
        "              \"contact_info\": {\n",
        "                \"name\": \"Sarah Johnson\",\n",
        "                \"email\": \"sarah.johnson@email.com\",\n",
        "                \"phone\": \"(555) 123-4567\",\n",
        "                \"location\": \"San Francisco, CA\",\n",
        "                \"linkedin\": \"linkedin.com/in/sarahjohnson\"\n",
        "              },\n",
        "              \"summary\": \"Senior software engineer with 5 years experience\",\n",
        "              \"work_experience\": [\n",
        "                {\n",
        "                  \"company\": \"Tech Corp\",\n",
        "                  \"position\": \"Senior Software Engineer\",\n",
        "                  \"start_date\": \"2021-03\",\n",
        "                  \"current\": true,\n",
        "                  \"responsibilities\": [\"Led team of 4 engineers\", \"Built microservices\"]\n",
        "                }\n",
        "              ]\n",
        "            }'''\n",
        "        \n",
        "        # TODO: Parse and validate JSON response\n",
        "        try:\n",
        "            data = json.loads(response)\n",
        "            return data\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.extraction_stats['parsing_errors'] += 1\n",
        "            raise\n",
        "    \n",
        "    def validate_extraction(self, data: Dict[str, Any]) -> ResumeData:\n",
        "        \"\"\"TODO: Validate extracted data against schema\"\"\"\n",
        "        try:\n",
        "            # TODO: Use Pydantic to validate and clean data\n",
        "            validated_data = ResumeData(**data)\n",
        "            self.extraction_stats['successful_extractions'] += 1\n",
        "            return validated_data\n",
        "        except ValidationError as e:\n",
        "            self.extraction_stats['validation_errors'] += 1\n",
        "            console.print(f\"[red]Validation error: {e}[/red]\")\n",
        "            raise\n",
        "    \n",
        "    def extract_resume_data(self, resume_text: str) -> ExtractionResult:\n",
        "        \"\"\"TODO: Main extraction method with full error handling\"\"\"\n",
        "        start_time = time.time()\n",
        "        errors = []\n",
        "        retry_count = 0\n",
        "        \n",
        "        try:\n",
        "            # TODO: Attempt extraction with retry\n",
        "            raw_data = self.extract_with_retry(resume_text)\n",
        "            \n",
        "            # TODO: Validate extracted data\n",
        "            validated_data = self.validate_extraction(raw_data)\n",
        "            \n",
        "            # TODO: Calculate confidence score\n",
        "            confidence = self.calculate_confidence_score(validated_data, resume_text)\n",
        "            \n",
        "            return ExtractionResult(\n",
        "                success=True,\n",
        "                data=validated_data,\n",
        "                errors=errors,\n",
        "                confidence_score=confidence,\n",
        "                processing_time=time.time() - start_time,\n",
        "                retry_count=retry_count\n",
        "            )\n",
        "            \n",
        "        except Exception as e:\n",
        "            return ExtractionResult(\n",
        "                success=False,\n",
        "                data=None,\n",
        "                errors=[str(e)],\n",
        "                confidence_score=0.0,\n",
        "                processing_time=time.time() - start_time,\n",
        "                retry_count=retry_count\n",
        "            )\n",
        "    \n",
        "    def calculate_confidence_score(self, data: ResumeData, original_text: str) -> float:\n",
        "        \"\"\"TODO: Calculate confidence score for extraction quality\"\"\"\n",
        "        # TODO: Implement scoring based on:\n",
        "        # - Completeness of extracted data\n",
        "        # - Consistency with original text\n",
        "        # - Presence of key information\n",
        "        \n",
        "        score = 0.8  # Placeholder\n",
        "        return score\n",
        "    \n",
        "    def get_extraction_stats(self) -> Table:\n",
        "        \"\"\"Get extraction statistics\"\"\"\n",
        "        table = Table(title=\"Extraction Statistics\")\n",
        "        table.add_column(\"Metric\")\n",
        "        table.add_column(\"Count\")\n",
        "        table.add_column(\"Rate\")\n",
        "        \n",
        "        total = self.extraction_stats['total_attempts']\n",
        "        if total > 0:\n",
        "            for metric, count in self.extraction_stats.items():\n",
        "                rate = f\"{count/total*100:.1f}%\" if total > 0 else \"0%\"\n",
        "                table.add_row(metric.replace('_', ' ').title(), str(count), rate)\n",
        "        \n",
        "        return table\n",
        "\n",
        "# Initialize extractor\n",
        "extractor = StructuredExtractor()\n",
        "print(\"⚙️ Extraction pipeline ready!\")\n",
        "print(\"⚠️ TODO: Complete the extraction and validation methods above\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Test with Sample Resumes\n",
        "\n",
        "**TODO:** Test your pipeline with various resume formats and edge cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create diverse test resume samples\n",
        "\n",
        "sample_resumes = {\n",
        "    \"complete_resume\": \"\"\"Sarah Johnson\n",
        "Software Engineer | sarah.johnson@email.com | (555) 123-4567\n",
        "LinkedIn: linkedin.com/in/sarahjohnson | GitHub: github.com/sarahj\n",
        "San Francisco, CA\n",
        "\n",
        "SUMMARY\n",
        "Senior software engineer with 5+ years of experience in full-stack development.\n",
        "Expertise in Python, JavaScript, and cloud technologies.\n",
        "\n",
        "EXPERIENCE\n",
        "Senior Software Engineer | Tech Corp | March 2021 - Present | San Francisco, CA\n",
        "• Led development team of 4 engineers on microservices architecture\n",
        "• Improved system performance by 40% through optimization\n",
        "• Implemented CI/CD pipeline reducing deployment time by 60%\n",
        "\n",
        "Software Engineer | StartupXYZ | June 2019 - February 2021 | Remote\n",
        "• Built REST APIs serving 1M+ requests daily\n",
        "• Developed React frontend components for customer dashboard\n",
        "\n",
        "EDUCATION\n",
        "B.S. Computer Science | Stanford University | 2019 | GPA: 3.8\n",
        "\n",
        "SKILLS\n",
        "Languages: Python, JavaScript, Java, Go\n",
        "Frameworks: Django, React, Node.js, Flask\n",
        "Tools: Docker, Kubernetes, AWS, PostgreSQL\n",
        "\"\"\",\n",
        "    \n",
        "    \"minimal_resume\": \"\"\"John Doe\n",
        "john@example.com\n",
        "\n",
        "Work: Software Developer at ABC Company (2020-2023)\n",
        "Education: Computer Science Degree, 2020\n",
        "Skills: Python, SQL\n",
        "\"\"\",\n",
        "    \n",
        "    \"messy_format\": \"\"\"ALEX CHEN | alex.chen@tech.com | Phone: 415-555-9876\n",
        "    \n",
        "    === WORK HISTORY ===\n",
        "    * Data Scientist @ BigTech Inc (Jan 2022 -> now)\n",
        "      - Machine learning model development\n",
        "      - Data pipeline automation\n",
        "    * Junior Analyst @ DataCorp (2020-2021)\n",
        "      \n",
        "    EDUCATION: Masters in Data Science, UC Berkeley 2020\n",
        "    \n",
        "    Technical Skills: Python • R • SQL • TensorFlow • AWS\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "def test_extraction_pipeline():\n",
        "    \"\"\"TODO: Test pipeline with different resume formats\"\"\"\n",
        "    \n",
        "    console.print(\"\\n🧪 [bold blue]Testing Structured Extraction Pipeline[/bold blue]\\n\")\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for name, resume_text in sample_resumes.items():\n",
        "        console.print(f\"[yellow]Testing: {name}[/yellow]\")\n",
        "        console.print(f\"Resume length: {len(resume_text)} characters\\n\")\n",
        "        \n",
        "        # TODO: Extract data and analyze results\n",
        "        result = extractor.extract_resume_data(resume_text)\n",
        "        results.append((name, result))\n",
        "        \n",
        "        # TODO: Display results\n",
        "        if result.success:\n",
        "            console.print(\"[green]✅ Extraction successful![/green]\")\n",
        "            console.print(f\"Confidence: {result.confidence_score:.2f}\")\n",
        "            console.print(f\"Processing time: {result.processing_time:.2f}s\")\n",
        "            \n",
        "            # Show extracted contact info\n",
        "            if result.data:\n",
        "                contact = result.data.contact_info\n",
        "                console.print(f\"[cyan]Name:[/cyan] {contact.name}\")\n",
        "                console.print(f\"[cyan]Email:[/cyan] {contact.email}\")\n",
        "                console.print(f\"[cyan]Experience entries:[/cyan] {len(result.data.work_experience)}\")\n",
        "                \n",
        "                # TODO: Display more structured data\n",
        "                \n",
        "        else:\n",
        "            console.print(\"[red]❌ Extraction failed![/red]\")\n",
        "            for error in result.errors:\n",
        "                console.print(f\"[red]Error: {error}[/red]\")\n",
        "        \n",
        "        console.print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "    \n",
        "    # TODO: Show overall statistics\n",
        "    console.print(extractor.get_extraction_stats())\n",
        "    \n",
        "    return results\n",
        "\n",
        "# TODO: Run the tests\n",
        "# test_results = test_extraction_pipeline()\n",
        "\n",
        "print(\"📊 Test framework ready!\")\n",
        "print(\"⚠️ TODO: Uncomment the test execution and complete the test analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Build Data Quality Assessment\n",
        "\n",
        "**TODO:** Create tools to assess and improve extraction quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class QualityAssessor:\n",
        "    \"\"\"Assess quality of extracted structured data\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.quality_metrics = {}\n",
        "    \n",
        "    def assess_completeness(self, data: ResumeData) -> float:\n",
        "        \"\"\"TODO: Score data completeness (0-1)\"\"\"\n",
        "        # TODO: Check presence of key fields\n",
        "        # TODO: Weight different sections by importance\n",
        "        # TODO: Return completeness score\n",
        "        \n",
        "        score = 0.0\n",
        "        max_score = 0.0\n",
        "        \n",
        "        # TODO: Implement scoring logic\n",
        "        \n",
        "        return score / max_score if max_score > 0 else 0.0\n",
        "    \n",
        "    def assess_accuracy(self, data: ResumeData, original_text: str) -> float:\n",
        "        \"\"\"TODO: Score extraction accuracy by comparing with source\"\"\"\n",
        "        # TODO: Check if extracted info matches source text\n",
        "        # TODO: Validate email format, phone format, dates\n",
        "        # TODO: Check for hallucinated information\n",
        "        \n",
        "        accuracy_score = 0.8  # Placeholder\n",
        "        return accuracy_score\n",
        "    \n",
        "    def assess_consistency(self, data: ResumeData) -> float:\n",
        "        \"\"\"TODO: Check internal consistency of extracted data\"\"\"\n",
        "        # TODO: Check date ordering in work experience\n",
        "        # TODO: Verify education dates vs work dates\n",
        "        # TODO: Check for duplicate or conflicting information\n",
        "        \n",
        "        consistency_score = 0.9  # Placeholder\n",
        "        return consistency_score\n",
        "    \n",
        "    def generate_quality_report(self, data: ResumeData, original_text: str) -> Dict[str, Any]:\n",
        "        \"\"\"TODO: Generate comprehensive quality report\"\"\"\n",
        "        \n",
        "        completeness = self.assess_completeness(data)\n",
        "        accuracy = self.assess_accuracy(data, original_text)\n",
        "        consistency = self.assess_consistency(data)\n",
        "        \n",
        "        # TODO: Calculate overall quality score\n",
        "        overall_score = (completeness + accuracy + consistency) / 3\n",
        "        \n",
        "        report = {\n",
        "            \"completeness_score\": completeness,\n",
        "            \"accuracy_score\": accuracy,\n",
        "            \"consistency_score\": consistency,\n",
        "            \"overall_quality\": overall_score,\n",
        "            \"issues_found\": [],  # TODO: Collect specific issues\n",
        "            \"recommendations\": []  # TODO: Generate improvement suggestions\n",
        "        }\n",
        "        \n",
        "        # TODO: Add specific recommendations based on scores\n",
        "        \n",
        "        return report\n",
        "    \n",
        "    def suggest_improvements(self, report: Dict[str, Any]) -> List[str]:\n",
        "        \"\"\"TODO: Generate specific improvement suggestions\"\"\"\n",
        "        suggestions = []\n",
        "        \n",
        "        # TODO: Analyze report and generate targeted suggestions\n",
        "        # Examples:\n",
        "        # - \"Add validation for email format\"\n",
        "        # - \"Improve date parsing for work experience\"\n",
        "        # - \"Extract missing skills section\"\n",
        "        \n",
        "        return suggestions\n",
        "    \n",
        "    def create_quality_dashboard(self, results: List[ExtractionResult]) -> Table:\n",
        "        \"\"\"TODO: Create quality metrics dashboard\"\"\"\n",
        "        table = Table(title=\"Data Quality Dashboard\")\n",
        "        table.add_column(\"Metric\")\n",
        "        table.add_column(\"Average Score\")\n",
        "        table.add_column(\"Min\")\n",
        "        table.add_column(\"Max\")\n",
        "        table.add_column(\"Status\")\n",
        "        \n",
        "        # TODO: Calculate aggregate quality metrics\n",
        "        # TODO: Add rows for different quality dimensions\n",
        "        \n",
        "        return table\n",
        "\n",
        "# Initialize quality assessor\n",
        "assessor = QualityAssessor()\n",
        "print(\"📊 Quality assessment tools ready!\")\n",
        "print(\"⚠️ TODO: Complete the quality assessment methods above\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Exit Ticket\n",
        "\n",
        "Before completing this lab, make sure you can answer:\n",
        "\n",
        "### ✅ Deliverables Checklist\n",
        "\n",
        "- [ ] **Defined comprehensive schemas**: Pydantic models for resume data with validation\n",
        "- [ ] **Built extraction pipeline**: Retry logic, error handling, and structured output\n",
        "- [ ] **Tested with diverse inputs**: Different resume formats and edge cases\n",
        "- [ ] **Implemented quality assessment**: Completeness, accuracy, and consistency metrics\n",
        "- [ ] **Created monitoring dashboard**: Track extraction performance and quality\n",
        "\n",
        "### 🧠 Knowledge Check\n",
        "\n",
        "1. **How do you handle schema validation errors?** What recovery strategies work best?\n",
        "\n",
        "2. **What makes a good confidence score?** How do you measure extraction quality?\n",
        "\n",
        "3. **When should you retry vs fail fast?** How do you balance reliability and speed?\n",
        "\n",
        "4. **How do you handle missing or optional data?** What defaults make sense?\n",
        "\n",
        "### 🚀 Extensions (Optional)\n",
        "\n",
        "- **Multi-model comparison**: Test extraction across different LLMs\n",
        "- **Active learning**: Improve schemas based on failure patterns\n",
        "- **Batch processing**: Handle multiple resumes efficiently\n",
        "- **Export formats**: Generate structured data in multiple formats\n",
        "- **Integration testing**: Connect to databases or APIs\n",
        "\n",
        "### 📊 Success Metrics\n",
        "\n",
        "- Built working structured extraction pipeline\n",
        "- Achieved >85% extraction accuracy on test cases\n",
        "- Implemented robust error handling and retry logic\n",
        "- Created comprehensive data validation\n",
        "- Generated useful quality metrics and dashboards\n",
        "\n",
        "**Time Check:** This lab should take about 60 minutes. Focus on getting basic extraction working before adding advanced quality features.\n",
        "\n",
        "Ready for Lab 8: JSONL Dashboard? Let's build monitoring and analytics! 📈"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
