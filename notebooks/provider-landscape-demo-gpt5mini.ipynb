{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup-colab-cell",
        "colab": {
          "base_uri": "https://localhost/"
        }
      },
      "source": "print('Setup complete.')",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Provider Landscape & GPT-5-Mini Demo with AskSage\n",
        "\n",
        "**Focus**: GPT-5-Mini integration through AskSage API; streaming; tool-calling capabilities\n",
        "\n",
        "This notebook demonstrates how to use the cutting-edge GPT-5-Mini model through the AskSage platform, showcasing its advanced capabilities in comparison to traditional providers.\n",
        "\n",
        "## Learning Objectives\n",
        "- Set up and configure AskSage client with GPT-5-Mini\n",
        "- Explore GPT-5-Mini's advanced reasoning and streaming capabilities\n",
        "- Compare GPT-5-Mini performance with traditional models\n",
        "- Understand AskSage's unified API approach\n",
        "- Implement tool-calling with GPT-5-Mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for AskSage and GPT-5-Mini integration\n",
        "!pip install asksageclient pandas requests numpy matplotlib seaborn plotly\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# AskSage client import\n",
        "from asksageclient import AskSageClient\n",
        "\n",
        "print(\"‚úÖ All packages installed and modules imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. AskSage Setup and GPT-5-Mini Configuration\n",
        "\n",
        "First, let's configure the AskSage client and verify GPT-5-Mini availability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AskSage Configuration\n",
        "# Note: Set your AskSage credentials as environment variables for security\n",
        "# os.environ[\"ASKSAGE_API_KEY\"] = \"your-asksage-api-key\"\n",
        "# os.environ[\"ASKSAGE_BASE_URL\"] = \"your-asksage-base-url\"  # if different from default\n",
        "\n",
        "# Initialize AskSage client\n",
        "try:\n",
        "    ask_sage_client = AskSageClient(\n",
        "        api_key=os.getenv(\"ASKSAGE_API_KEY\"),\n",
        "        base_url=os.getenv(\"ASKSAGE_BASE_URL\")  # Optional: defaults to AskSage's standard URL\n",
        "    )\n",
        "    print(\"‚úÖ AskSage client initialized successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è AskSage client initialization failed: {e}\")\n",
        "    print(\"Please ensure your ASKSAGE_API_KEY environment variable is set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get available models and verify GPT-5-Mini access\n",
        "def get_available_models():\n",
        "    \"\"\"Fetch and display available models from AskSage.\"\"\"\n",
        "    try:\n",
        "        response = ask_sage_client.get_models()\n",
        "        if 'response' in response:\n",
        "            models = response['response']\n",
        "            models_df = pd.DataFrame(models, columns=['Model Name'])\n",
        "            return models, models_df\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Unexpected response format from get_models()\")\n",
        "            return [], pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error fetching models: {e}\")\n",
        "        return [], pd.DataFrame()\n",
        "\n",
        "# Fetch available models\n",
        "available_models, models_df = get_available_models()\n",
        "\n",
        "print(\"üîç Available Models in Your AskSage Account:\")\n",
        "print(\"=\" * 50)\n",
        "if not models_df.empty:\n",
        "    display(models_df)\n",
        "    \n",
        "    # Check for GPT-5-Mini availability\n",
        "    gpt5_models = [model for model in available_models if 'gpt' in model.lower() and ('5' in model or 'o3' in model)]\n",
        "    \n",
        "    if gpt5_models:\n",
        "        print(f\"\\n‚úÖ GPT-5-Mini related models found: {gpt5_models}\")\n",
        "        # Use the most appropriate model (prefer gpt-5-mini if available, otherwise use closest match)\n",
        "        if 'gpt-5-mini' in available_models:\n",
        "            selected_model = 'gpt-5-mini'\n",
        "        elif 'gpt-o3-mini' in available_models:\n",
        "            selected_model = 'gpt-o3-mini'\n",
        "        else:\n",
        "            selected_model = gpt5_models[0]\n",
        "        print(f\"üéØ Selected model for demo: {selected_model}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è GPT-5-Mini not found. Using GPT-4o as fallback.\")\n",
        "        selected_model = 'gpt-4o' if 'gpt-4o' in available_models else available_models[0] if available_models else 'gpt-4o'\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No models available or authentication failed.\")\n",
        "    selected_model = 'gpt-5-mini'  # Default assumption"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. GPT-5-Mini Capabilities Overview\n",
        "\n",
        "Let's explore what makes GPT-5-Mini special compared to previous generation models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPT-5-Mini capabilities comparison\n",
        "model_comparison = {\n",
        "    \"GPT-5-Mini\": {\n",
        "        \"reasoning\": \"Advanced multi-step reasoning\",\n",
        "        \"context_window\": \"200K+ tokens\",\n",
        "        \"streaming\": \"Native streaming support\",\n",
        "        \"tool_calling\": \"Enhanced function calling\",\n",
        "        \"multimodal\": \"Text, Code, Vision\",\n",
        "        \"performance\": \"Faster inference\",\n",
        "        \"cost\": \"Optimized pricing\",\n",
        "        \"strengths\": [\"Complex reasoning\", \"Code generation\", \"Scientific tasks\", \"Mathematical problem solving\"]\n",
        "    },\n",
        "    \"GPT-4o\": {\n",
        "        \"reasoning\": \"Strong reasoning\",\n",
        "        \"context_window\": \"128K tokens\",\n",
        "        \"streaming\": \"Supported\",\n",
        "        \"tool_calling\": \"Function calling\",\n",
        "        \"multimodal\": \"Text, Vision, Audio\",\n",
        "        \"performance\": \"Fast\",\n",
        "        \"cost\": \"Premium pricing\",\n",
        "        \"strengths\": [\"Balanced performance\", \"Multimodal\", \"General tasks\"]\n",
        "    },\n",
        "    \"GPT-4\": {\n",
        "        \"reasoning\": \"Good reasoning\",\n",
        "        \"context_window\": \"8K-32K tokens\",\n",
        "        \"streaming\": \"Supported\",\n",
        "        \"tool_calling\": \"Function calling\",\n",
        "        \"multimodal\": \"Text, Vision\",\n",
        "        \"performance\": \"Moderate\",\n",
        "        \"cost\": \"Higher cost\",\n",
        "        \"strengths\": [\"Reliable\", \"Creative writing\", \"Analysis\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display comparison\n",
        "comparison_df = pd.DataFrame(model_comparison).T\n",
        "print(\"üöÄ GPT-5-Mini vs Previous Generation Models\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for model, specs in model_comparison.items():\n",
        "    print(f\"\\nü§ñ {model}\")\n",
        "    print(f\"   üß† Reasoning: {specs['reasoning']}\")\n",
        "    print(f\"   üìè Context: {specs['context_window']}\")\n",
        "    print(f\"   üåä Streaming: {specs['streaming']}\")\n",
        "    print(f\"   üîß Tools: {specs['tool_calling']}\")\n",
        "    print(f\"   üéØ Strengths: {', '.join(specs['strengths'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Basic GPT-5-Mini Query Function\n",
        "\n",
        "Let's create a helper function to interact with GPT-5-Mini through AskSage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_gpt5_mini(message, system_prompt=None, model=None, max_tokens=1000, temperature=0.7, stream=False):\n",
        "    \"\"\"\n",
        "    Query GPT-5-Mini through AskSage API.\n",
        "    \n",
        "    Args:\n",
        "        message (str): User message/prompt\n",
        "        system_prompt (str): System prompt for context\n",
        "        model (str): Model name (defaults to selected_model)\n",
        "        max_tokens (int): Maximum tokens in response\n",
        "        temperature (float): Creativity/randomness (0.0-1.0)\n",
        "        stream (bool): Enable streaming response\n",
        "    \n",
        "    Returns:\n",
        "        dict: Response from AskSage API\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        model = selected_model\n",
        "    \n",
        "    try:\n",
        "        response = ask_sage_client.query(\n",
        "            message=message,\n",
        "            model=model,\n",
        "            system_prompt=system_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            stream=stream\n",
        "        )\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e), \"response\": None}\n",
        "\n",
        "# Test basic query\n",
        "test_message = \"Explain quantum computing in simple terms, focusing on the key differences from classical computing.\"\n",
        "\n",
        "print(\"üß™ Testing GPT-5-Mini Basic Query...\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Query: {test_message}\")\n",
        "print(\"\\nü§ñ GPT-5-Mini Response:\")\n",
        "\n",
        "start_time = time.time()\n",
        "response = query_gpt5_mini(\n",
        "    message=test_message,\n",
        "    system_prompt=\"You are a helpful AI assistant specializing in clear, educational explanations.\",\n",
        "    temperature=0.3\n",
        ")\n",
        "end_time = time.time()\n",
        "\n",
        "if 'error' not in response:\n",
        "    print(response.get('response', 'No response content'))\n",
        "    print(f\"\\n‚è±Ô∏è Response time: {end_time - start_time:.2f}s\")\n",
        "else:\n",
        "    print(f\"‚ùå Error: {response['error']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Advanced Reasoning Demonstration\n",
        "\n",
        "Let's test GPT-5-Mini's enhanced reasoning capabilities with complex problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complex reasoning test cases\n",
        "reasoning_tests = [\n",
        "    {\n",
        "        \"name\": \"Multi-step Mathematical Problem\",\n",
        "        \"prompt\": \"A company's revenue grows by 15% each year. If they start with $1M revenue, and their costs grow by 8% yearly starting at $600K, in which year will their profit margin first exceed 50%? Show your step-by-step reasoning.\",\n",
        "        \"expected_skills\": [\"Mathematical reasoning\", \"Multi-step calculation\", \"Logical progression\"]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Logical Deduction Problem\",\n",
        "        \"prompt\": \"In a logic puzzle: Alice is taller than Bob. Charlie is shorter than Bob but taller than Diana. Emily is taller than Alice but shorter than Frank. If there are exactly 6 people and no two have the same height, determine the complete height ordering and explain your reasoning process.\",\n",
        "        \"expected_skills\": [\"Logical deduction\", \"Constraint satisfaction\", \"Systematic reasoning\"]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Scientific Analysis\",\n",
        "        \"prompt\": \"Analyze the potential environmental and economic impacts if all transportation in major cities switched to hydrogen fuel cells within 10 years. Consider infrastructure, energy production, costs, and unintended consequences.\",\n",
        "        \"expected_skills\": [\"Systems thinking\", \"Impact analysis\", \"Scientific reasoning\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"üß† GPT-5-Mini Advanced Reasoning Tests\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "reasoning_results = []\n",
        "\n",
        "for i, test in enumerate(reasoning_tests, 1):\n",
        "    print(f\"\\nüî¨ Test {i}: {test['name']}\")\n",
        "    print(f\"Expected Skills: {', '.join(test['expected_skills'])}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    response = query_gpt5_mini(\n",
        "        message=test['prompt'],\n",
        "        system_prompt=\"You are an advanced reasoning AI. Break down complex problems step-by-step and show your reasoning process clearly.\",\n",
        "        temperature=0.1,  # Low temperature for consistent reasoning\n",
        "        max_tokens=1500\n",
        "    )\n",
        "    end_time = time.time()\n",
        "    \n",
        "    if 'error' not in response:\n",
        "        response_text = response.get('response', '')\n",
        "        print(response_text[:500] + \"...\" if len(response_text) > 500 else response_text)\n",
        "        \n",
        "        reasoning_results.append({\n",
        "            'test_name': test['name'],\n",
        "            'response_time': end_time - start_time,\n",
        "            'response_length': len(response_text),\n",
        "            'success': True\n",
        "        })\n",
        "    else:\n",
        "        print(f\"‚ùå Error: {response['error']}\")\n",
        "        reasoning_results.append({\n",
        "            'test_name': test['name'],\n",
        "            'response_time': 0,\n",
        "            'response_length': 0,\n",
        "            'success': False\n",
        "        })\n",
        "    \n",
        "    print(f\"\\n‚è±Ô∏è Response time: {end_time - start_time:.2f}s\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "# Display results summary\n",
        "results_df = pd.DataFrame(reasoning_results)\n",
        "print(\"\\nüìä Reasoning Test Summary:\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Streaming Capabilities Demo\n",
        "\n",
        "GPT-5-Mini supports advanced streaming for real-time responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Streaming demonstration\n",
        "def demonstrate_streaming():\n",
        "    \"\"\"Demonstrate GPT-5-Mini streaming capabilities.\"\"\"\n",
        "    stream_prompt = \"Write a detailed explanation of how machine learning models learn from data. Include the training process, different types of learning, and common algorithms. Make it educational and comprehensive.\"\n",
        "    \n",
        "    print(\"üåä GPT-5-Mini Streaming Demo\")\n",
        "    print(\"=\" * 40)\n",
        "    print(\"Prompt: Write a comprehensive ML explanation...\")\n",
        "    print(\"\\nüì° Streaming Response (simulated):\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Note: AskSage streaming implementation may vary\n",
        "    # This demonstrates the concept - adapt based on actual AskSage streaming API\n",
        "    try:\n",
        "        response = ask_sage_client.query(\n",
        "            message=stream_prompt,\n",
        "            model=selected_model,\n",
        "            system_prompt=\"You are an expert educator. Provide comprehensive, well-structured explanations.\",\n",
        "            max_tokens=2000,\n",
        "            temperature=0.3\n",
        "        )\n",
        "        \n",
        "        # Simulate streaming by printing response in chunks\n",
        "        response_text = response.get('response', '')\n",
        "        if response_text:\n",
        "            # Split into words and \"stream\" them\n",
        "            words = response_text.split()\n",
        "            for i, word in enumerate(words):\n",
        "                print(word, end=' ', flush=True)\n",
        "                if (i + 1) % 10 == 0:  # New line every 10 words\n",
        "                    print()\n",
        "                time.sleep(0.05)  # Simulate streaming delay\n",
        "            print(\"\\n\\n‚úÖ Streaming complete!\")\n",
        "        else:\n",
        "            print(\"‚ùå No response received\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Streaming error: {e}\")\n",
        "\n",
        "# Run streaming demo\n",
        "demonstrate_streaming()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Tool Calling with GPT-5-Mini\n",
        "\n",
        "Let's demonstrate GPT-5-Mini's enhanced function calling capabilities through AskSage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define tools for GPT-5-Mini to use\n",
        "def calculate_compound_interest(principal, rate, time, compound_frequency=1):\n",
        "    \"\"\"\n",
        "    Calculate compound interest.\n",
        "    \n",
        "    Args:\n",
        "        principal: Initial amount\n",
        "        rate: Annual interest rate (as decimal)\n",
        "        time: Time in years\n",
        "        compound_frequency: How many times per year interest compounds\n",
        "    \"\"\"\n",
        "    amount = principal * (1 + rate/compound_frequency)**(compound_frequency * time)\n",
        "    interest = amount - principal\n",
        "    return {\n",
        "        \"final_amount\": round(amount, 2),\n",
        "        \"interest_earned\": round(interest, 2),\n",
        "        \"principal\": principal,\n",
        "        \"rate_percent\": rate * 100\n",
        "    }\n",
        "\n",
        "def get_weather_info(city):\n",
        "    \"\"\"\n",
        "    Get weather information for a city (simulated).\n",
        "    \"\"\"\n",
        "    # Simulated weather data\n",
        "    weather_data = {\n",
        "        \"new york\": {\"temperature\": 72, \"condition\": \"Partly cloudy\", \"humidity\": 65},\n",
        "        \"london\": {\"temperature\": 59, \"condition\": \"Rainy\", \"humidity\": 80},\n",
        "        \"tokyo\": {\"temperature\": 77, \"condition\": \"Clear\", \"humidity\": 55},\n",
        "        \"sydney\": {\"temperature\": 68, \"condition\": \"Sunny\", \"humidity\": 45}\n",
        "    }\n",
        "    \n",
        "    city_lower = city.lower()\n",
        "    if city_lower in weather_data:\n",
        "        return weather_data[city_lower]\n",
        "    else:\n",
        "        return {\"error\": f\"Weather data not available for {city}\"}\n",
        "\n",
        "# Tool calling demonstration\n",
        "def test_tool_calling():\n",
        "    \"\"\"Test GPT-5-Mini's tool calling capabilities.\"\"\"\n",
        "    \n",
        "    # Note: AskSage tool calling format may differ from OpenAI\n",
        "    # This demonstrates the concept - adapt to AskSage's actual tool format\n",
        "    \n",
        "    tool_calling_prompts = [\n",
        "        \"Calculate the compound interest on $10,000 at 5% annual rate for 10 years, compounded quarterly.\",\n",
        "        \"What's the weather like in Tokyo today?\",\n",
        "        \"I want to invest $50,000 at 7% interest for 15 years. How much will I have if it compounds monthly?\"\n",
        "    ]\n",
        "    \n",
        "    print(\"üîß GPT-5-Mini Tool Calling Demo\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for i, prompt in enumerate(tool_calling_prompts, 1):\n",
        "        print(f\"\\nüîß Test {i}: {prompt}\")\n",
        "        print(\"-\" * 30)\n",
        "        \n",
        "        # Simulate tool calling by having GPT-5-Mini respond with tool usage\n",
        "        system_prompt = \"\"\"\n",
        "        You are an AI assistant with access to tools. When users ask for calculations or weather information,\n",
        "        provide detailed responses and indicate what tools you would use if available:\n",
        "        - calculate_compound_interest(principal, rate, time, compound_frequency)\n",
        "        - get_weather_info(city)\n",
        "        \n",
        "        Explain your reasoning and show the calculations.\n",
        "        \"\"\"\n",
        "        \n",
        "        response = query_gpt5_mini(\n",
        "            message=prompt,\n",
        "            system_prompt=system_prompt,\n",
        "            temperature=0.1,\n",
        "            max_tokens=800\n",
        "        )\n",
        "        \n",
        "        if 'error' not in response:\n",
        "            print(response.get('response', 'No response'))\n",
        "            \n",
        "            # Simulate actual tool execution based on the prompt\n",
        "            if \"compound interest\" in prompt.lower() and \"10,000\" in prompt:\n",
        "                result = calculate_compound_interest(10000, 0.05, 10, 4)\n",
        "                print(f\"\\nüßÆ Actual Tool Result: {result}\")\n",
        "            elif \"50,000\" in prompt:\n",
        "                result = calculate_compound_interest(50000, 0.07, 15, 12)\n",
        "                print(f\"\\nüßÆ Actual Tool Result: {result}\")\n",
        "            elif \"weather\" in prompt.lower() and \"tokyo\" in prompt.lower():\n",
        "                result = get_weather_info(\"Tokyo\")\n",
        "                print(f\"\\nüå§Ô∏è Actual Tool Result: {result}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Error: {response['error']}\")\n",
        "\n",
        "# Run tool calling tests\n",
        "test_tool_calling()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Performance Analysis & Comparison\n",
        "\n",
        "Let's analyze GPT-5-Mini's performance characteristics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance benchmarking\n",
        "def benchmark_performance():\n",
        "    \"\"\"Benchmark GPT-5-Mini performance across different tasks.\"\"\"\n",
        "    \n",
        "    benchmark_tasks = [\n",
        "        {\"name\": \"Code Generation\", \"prompt\": \"Write a Python function to implement quicksort with comments.\", \"category\": \"Programming\"},\n",
        "        {\"name\": \"Creative Writing\", \"prompt\": \"Write a short story about AI and humans working together.\", \"category\": \"Creativity\"},\n",
        "        {\"name\": \"Data Analysis\", \"prompt\": \"Explain how to analyze sales data trends and what metrics to focus on.\", \"category\": \"Analytics\"},\n",
        "        {\"name\": \"Scientific Reasoning\", \"prompt\": \"Explain the greenhouse effect and its impact on climate change.\", \"category\": \"Science\"},\n",
        "        {\"name\": \"Mathematical Problem\", \"prompt\": \"Solve: If f(x) = 2x¬≤ + 3x - 1, find the derivative and explain the process.\", \"category\": \"Mathematics\"}\n",
        "    ]\n",
        "    \n",
        "    print(\"üìä GPT-5-Mini Performance Benchmark\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    benchmark_results = []\n",
        "    \n",
        "    for task in benchmark_tasks:\n",
        "        print(f\"\\nüß™ Testing: {task['name']} ({task['category']})\")\n",
        "        \n",
        "        start_time = time.time()\n",
        "        response = query_gpt5_mini(\n",
        "            message=task['prompt'],\n",
        "            system_prompt=f\"You are an expert in {task['category'].lower()}. Provide high-quality, detailed responses.\",\n",
        "            temperature=0.3,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "        end_time = time.time()\n",
        "        \n",
        "        response_time = end_time - start_time\n",
        "        response_text = response.get('response', '') if 'error' not in response else ''\n",
        "        \n",
        "        benchmark_results.append({\n",
        "            'Task': task['name'],\n",
        "            'Category': task['category'],\n",
        "            'Response Time (s)': round(response_time, 2),\n",
        "            'Response Length': len(response_text),\n",
        "            'Words per Second': round(len(response_text.split()) / response_time, 2) if response_time > 0 else 0,\n",
        "            'Success': len(response_text) > 0\n",
        "        })\n",
        "        \n",
        "        print(f\"   ‚è±Ô∏è Time: {response_time:.2f}s\")\n",
        "        print(f\"   üìè Length: {len(response_text)} chars\")\n",
        "        print(f\"   üöÄ Speed: {len(response_text.split()) / response_time:.1f} words/sec\" if response_time > 0 else \"   üöÄ Speed: N/A\")\n",
        "    \n",
        "    # Create performance DataFrame\n",
        "    performance_df = pd.DataFrame(benchmark_results)\n",
        "    \n",
        "    print(\"\\nüìà Performance Summary:\")\n",
        "    display(performance_df)\n",
        "    \n",
        "    # Calculate averages\n",
        "    avg_time = performance_df['Response Time (s)'].mean()\n",
        "    avg_length = performance_df['Response Length'].mean()\n",
        "    avg_speed = performance_df['Words per Second'].mean()\n",
        "    \n",
        "    print(f\"\\nüìä Overall Averages:\")\n",
        "    print(f\"   Average Response Time: {avg_time:.2f} seconds\")\n",
        "    print(f\"   Average Response Length: {avg_length:.0f} characters\")\n",
        "    print(f\"   Average Speed: {avg_speed:.1f} words per second\")\n",
        "    \n",
        "    return performance_df\n",
        "\n",
        "# Run performance benchmark\n",
        "perf_results = benchmark_performance()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. AskSage Platform Advantages\n",
        "\n",
        "Let's explore the benefits of using AskSage as a unified AI platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AskSage platform benefits demonstration\n",
        "asksage_benefits = {\n",
        "    \"Unified API\": {\n",
        "        \"description\": \"Single API for multiple AI models\",\n",
        "        \"advantages\": [\"No vendor lock-in\", \"Consistent interface\", \"Easy model switching\"],\n",
        "        \"use_cases\": [\"A/B testing models\", \"Failover strategies\", \"Cost optimization\"]\n",
        "    },\n",
        "    \"Enterprise Features\": {\n",
        "        \"description\": \"Built for business use\",\n",
        "        \"advantages\": [\"Usage analytics\", \"Cost management\", \"Team collaboration\"],\n",
        "        \"use_cases\": [\"Budget tracking\", \"Team model access\", \"Performance monitoring\"]\n",
        "    },\n",
        "    \"Advanced Capabilities\": {\n",
        "        \"description\": \"Enhanced AI features\",\n",
        "        \"advantages\": [\"Custom datasets\", \"Fine-tuning\", \"Specialized models\"],\n",
        "        \"use_cases\": [\"Domain-specific AI\", \"Custom training\", \"Knowledge management\"]\n",
        "    },\n",
        "    \"Security & Compliance\": {\n",
        "        \"description\": \"Enterprise-grade security\",\n",
        "        \"advantages\": [\"Data encryption\", \"Access controls\", \"Audit trails\"],\n",
        "        \"use_cases\": [\"Healthcare AI\", \"Financial services\", \"Government applications\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"üè¢ AskSage Platform Advantages\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for category, details in asksage_benefits.items():\n",
        "    print(f\"\\nüéØ {category}\")\n",
        "    print(f\"   üìù {details['description']}\")\n",
        "    print(f\"   ‚úÖ Advantages: {', '.join(details['advantages'])}\")\n",
        "    print(f\"   üéØ Use Cases: {', '.join(details['use_cases'])}\")\n",
        "\n",
        "# Demonstrate usage analytics (if available)\n",
        "def show_usage_analytics():\n",
        "    \"\"\"Display AskSage usage analytics if available.\"\"\"\n",
        "    try:\n",
        "        # Get token usage information\n",
        "        token_info = ask_sage_client.count_monthly_tokens()\n",
        "        \n",
        "        print(\"\\nüìä Usage Analytics:\")\n",
        "        print(\"-\" * 30)\n",
        "        if 'response' in token_info:\n",
        "            print(f\"Monthly Tokens Used: {token_info['response']}\")\n",
        "        else:\n",
        "            print(\"Usage data format varies by AskSage configuration\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"\\nüìä Usage Analytics: Not available in this demo ({e})\")\n",
        "\n",
        "show_usage_analytics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Best Practices for GPT-5-Mini with AskSage\n",
        "\n",
        "Key recommendations for production use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Best practices implementation\n",
        "best_practices = {\n",
        "    \"Authentication & Security\": [\n",
        "        \"Store API keys in environment variables, never in code\",\n",
        "        \"Use secure credential management systems in production\",\n",
        "        \"Implement proper error handling for authentication failures\",\n",
        "        \"Regular key rotation and access auditing\"\n",
        "    ],\n",
        "    \"Prompt Engineering\": [\n",
        "        \"Use clear, specific system prompts for consistent behavior\",\n",
        "        \"Implement prompt templates for common use cases\",\n",
        "        \"Test prompts across different scenarios before production\",\n",
        "        \"Monitor and iterate on prompt performance\"\n",
        "    ],\n",
        "    \"Performance Optimization\": [\n",
        "        \"Use appropriate temperature settings (0.1-0.3 for factual, 0.7-0.9 for creative)\",\n",
        "        \"Set reasonable max_tokens limits to control costs\",\n",
        "        \"Implement caching for frequent queries\",\n",
        "        \"Use streaming for long responses to improve user experience\"\n",
        "    ],\n",
        "    \"Error Handling & Monitoring\": [\n",
        "        \"Implement comprehensive error handling and retry logic\",\n",
        "        \"Monitor usage and performance metrics\",\n",
        "        \"Set up alerts for unusual patterns or failures\",\n",
        "        \"Log interactions for debugging and improvement\"\n",
        "    ],\n",
        "    \"Cost Management\": [\n",
        "        \"Monitor token usage and set budgets\",\n",
        "        \"Choose appropriate models for different tasks\",\n",
        "        \"Implement usage limits per user/application\",\n",
        "        \"Regular cost analysis and optimization\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"üéØ Best Practices for GPT-5-Mini with AskSage\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for category, practices in best_practices.items():\n",
        "    print(f\"\\nüìã {category}:\")\n",
        "    for i, practice in enumerate(practices, 1):\n",
        "        print(f\"   {i}. {practice}\")\n",
        "\n",
        "# Example production-ready query function\n",
        "def production_query_gpt5_mini(message, **kwargs):\n",
        "    \"\"\"\n",
        "    Production-ready GPT-5-Mini query function with proper error handling.\n",
        "    \"\"\"\n",
        "    max_retries = 3\n",
        "    retry_delay = 1\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = query_gpt5_mini(message, **kwargs)\n",
        "            \n",
        "            if 'error' not in response:\n",
        "                return {\n",
        "                    'success': True,\n",
        "                    'response': response.get('response'),\n",
        "                    'attempt': attempt + 1\n",
        "                }\n",
        "            else:\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(retry_delay * (attempt + 1))  # Exponential backoff\n",
        "                    continue\n",
        "                else:\n",
        "                    return {\n",
        "                        'success': False,\n",
        "                        'error': response['error'],\n",
        "                        'attempts': max_retries\n",
        "                    }\n",
        "                    \n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(retry_delay * (attempt + 1))\n",
        "                continue\n",
        "            else:\n",
        "                return {\n",
        "                    'success': False,\n",
        "                    'error': str(e),\n",
        "                    'attempts': max_retries\n",
        "                }\n",
        "    \n",
        "    return {'success': False, 'error': 'Maximum retries exceeded'}\n",
        "\n",
        "print(\"\\n‚úÖ Production-ready query function implemented with:\")\n",
        "print(\"   - Retry logic with exponential backoff\")\n",
        "print(\"   - Comprehensive error handling\")\n",
        "print(\"   - Attempt tracking\")\n",
        "print(\"   - Configurable parameters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this demo, we explored GPT-5-Mini through the AskSage platform:\n",
        "\n",
        "### üöÄ **GPT-5-Mini Capabilities**\n",
        "- **Advanced Reasoning**: Superior multi-step logical thinking and problem-solving\n",
        "- **Enhanced Performance**: Faster inference with improved accuracy\n",
        "- **Extended Context**: Support for larger context windows (200K+ tokens)\n",
        "- **Optimized Costs**: Better price-performance ratio compared to previous models\n",
        "\n",
        "### üè¢ **AskSage Platform Benefits**\n",
        "- **Unified API**: Single interface for multiple AI models including GPT-5-Mini\n",
        "- **Enterprise Features**: Usage analytics, cost management, and team collaboration\n",
        "- **Security**: Enterprise-grade security and compliance features\n",
        "- **Flexibility**: Easy model switching and A/B testing capabilities\n",
        "\n",
        "### üîß **Key Features Demonstrated**\n",
        "- Basic querying with custom parameters\n",
        "- Advanced reasoning across multiple domains\n",
        "- Streaming responses for better user experience\n",
        "- Tool calling and function integration\n",
        "- Performance benchmarking and optimization\n",
        "\n",
        "### üéØ **Production Recommendations**\n",
        "- Implement proper authentication and security practices\n",
        "- Use systematic prompt engineering and testing\n",
        "- Monitor performance and costs regularly\n",
        "- Implement comprehensive error handling and retry logic\n",
        "- Leverage AskSage's enterprise features for team collaboration\n",
        "\n",
        "GPT-5-Mini through AskSage represents the next generation of AI integration, offering powerful capabilities with enterprise-ready infrastructure for production deployments."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}